<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>网页模板 pug 基本语法</title>
    <url>/hexo-pug-notes.html</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>pug 原名 <code>jade</code> ，因版权问题更名为 <code>pug</code> ，即哈巴狗。与 hexo 默认模块 <code>ejs</code> 一样，pug 也是一个模板引擎，可用于快速的网站开发，当然也可以用于静态博客网站的设计。本站点现时所用主题 manupassant 也使用了 <code>pug</code> 。</p>
<p>本文针对 Hexo 中使用 <code>pug</code> 的情况为例，说明其基本语法。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="comment"># common install</span></span><br><span class="line">npm install pug</span><br><span class="line"></span><br><span class="line"><span class="comment"># install for hexo blog</span></span><br><span class="line">npm install hexo-renderer-pug --save</span><br></pre></td></tr></table></figure>

<h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><p>pug 不同于 html ，前者不需要标签的开和闭，如 html 的 <code>&lt;p&gt;Demo&lt;/p&gt;</code> ，在 pug 使用 <code>p Demo</code> 即可。</p>
<h2 id="缩进"><a href="#缩进" class="headerlink" title="缩进"></a>缩进</h2><p>pug 对空格敏感，有点类似 python 对制表符tab敏感。pug 使用空格作为缩进符，当然用 <code>soft tab</code> 也可行。同一级标签需保证左对齐。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">div</span><br><span class="line">    p Hello, world!</span><br><span class="line">    p Hello, pug.</span><br></pre></td></tr></table></figure>

<p>渲染结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Hellow, world!<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">p</span>&gt;</span>Hello, pug.<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p>pug 使用 <code>//-</code> 或 <code>//</code> 对代码进行注释，前者注释内容不出现在渲染后的 html 文件中，后者反之。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- html中不包含此行</span><br><span class="line">// html中会包含此行</span><br></pre></td></tr></table></figure>

<h2 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h2><p>pug 将标签属性存放于括号 <code>()</code> 内，多个属性之间以 <code>逗号</code> 或 <code>空格</code> 分隔。此外，对于标签的 <code>id</code> 和 <code>class</code> ，pug 使用 <code>#</code> 紧跟标签 <code>id</code> ,使用 <code>.</code> 紧跟标签 <code>class</code> ，可以同时设置多个 <code>class</code> 。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">h1#title Test title</span><br><span class="line">img#name.class1.class2(src=&quot;/test.png&quot; alt=&quot;test&quot;)</span><br></pre></td></tr></table></figure>

<p>渲染结果如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">h1</span> <span class="attr">id</span>=<span class="string">&quot;title&quot;</span>&gt;</span>Test title<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">img</span> <span class="attr">id</span>=<span class="string">&quot;name&quot;</span> <span class="attr">class</span>=<span class="string">&quot;class1 class2&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/test.png&quot;</span> <span class="attr">alt</span>=<span class="string">&quot;test&quot;</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="包含"><a href="#包含" class="headerlink" title="包含"></a>包含</h2><p>为了方便代码复用，pug 提供了 <code>include</code> 包含功能，以下代码会将 <code>_partial</code> 目录下的 <code>head.pug</code> 文件内容包含到当前调用的位置。有点 C&#x2F;C++ 中内联函数的意思。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">doctype html</span><br><span class="line">html(lang=&#x27;en&#x27;)</span><br><span class="line">    include _partial/head.pug</span><br></pre></td></tr></table></figure>

<h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>下面是一个简单的 <code>base</code> 模板，通过 <code>block</code> 定义了页面头部 <code>head</code> 和内容 <code>body</code> 。块 <code>block</code> 有点类似 C&#x2F;C++ 的抽象函数，需要在继承者中完成定义，填充具体内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- base.pug</span><br><span class="line">html</span><br><span class="line">    head</span><br><span class="line">        block title</span><br><span class="line">    body</span><br><span class="line">        block content</span><br></pre></td></tr></table></figure>

<p>以下文件使用 <code>extends</code> 继承以上模板，通过 <code>block</code> 覆盖或替换原有块 <code>block</code> 。当然，继承者也可以在原有基础上继续扩展。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- index.pug</span><br><span class="line">extends base.pug</span><br><span class="line"></span><br><span class="line">block title</span><br><span class="line">    title &quot;Test title&quot;</span><br><span class="line"></span><br><span class="line">block content</span><br><span class="line">    h1 Hello world!</span><br><span class="line">    block article</span><br></pre></td></tr></table></figure>

<h2 id="定义变量"><a href="#定义变量" class="headerlink" title="定义变量"></a>定义变量</h2><p>pug中通过 <code>- var name = value</code> 的形式定义变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- var intData = 100</span><br><span class="line">- var boolData = false</span><br><span class="line">- var stringData = &#x27;Test&#x27;</span><br><span class="line">p.int= intData</span><br><span class="line">p.bool= boolData</span><br><span class="line">p.stringData= stringData</span><br></pre></td></tr></table></figure>

<blockquote>
<p>需注意的是，在引用变量时，需要在引用位置加上&#x3D;号，否则会默认将变量名当成普通字符串使用。</p>
</blockquote>
<p>如果想要将变量与其它字符串常量或是变量连接在一起，就不能用等号了，而是应该用 <code>#&#123;&#125;</code> ，该符号会对大括号内的变量进行求值和转义，最终得到渲染输出的内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- var girl = &#x27;Lily&#x27;</span><br><span class="line">- var boy = &#x27;Jack&#x27;</span><br><span class="line">p #&#123;girl&#125; is so beautiful!</span><br><span class="line">p And #&#123;boy&#125; is handsome.</span><br></pre></td></tr></table></figure>

<h2 id="条件结构"><a href="#条件结构" class="headerlink" title="条件结构"></a>条件结构</h2><p>pug 的条件语句与其它语言类似，均是如下这般：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">- var A = &#123;value: &#x27;Test&#x27;&#125;</span><br><span class="line">- var B = true</span><br><span class="line">if A.value</span><br><span class="line">    p= A.value</span><br><span class="line">else if B</span><br><span class="line">    p= B</span><br><span class="line">else</span><br><span class="line">    p nothing</span><br></pre></td></tr></table></figure>

<h2 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h2><p>pug 中使用 <code>each</code> 和 <code>while</code> 实现循环迭代，<code>each</code> 可以返回当前所在项的索引值，默认从 <code>0</code> 开始计数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- each</span><br><span class="line">ol</span><br><span class="line">    each item in [&#x27;Sun&#x27;, &#x27;Mon&#x27;, &#x27;Tus&#x27;, &#x27;Wen&#x27;, &#x27;Thu&#x27;, &#x27;Fri&#x27;, &#x27;Sat&#x27;]</span><br><span class="line">        li= item</span><br><span class="line"></span><br><span class="line">//- get index of each</span><br><span class="line">- var week = [&#x27;Sun&#x27;, &#x27;Mon&#x27;, &#x27;Tus&#x27;, &#x27;Wen&#x27;, &#x27;Thu&#x27;, &#x27;Fri&#x27;, &#x27;Sat&#x27;]</span><br><span class="line">ol</span><br><span class="line">    each item, index in week</span><br><span class="line">        li= index + &#x27;:&#x27; + item</span><br></pre></td></tr></table></figure>
<p>渲染成 html 后：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ol</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Sun<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Mon<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Tus<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Wen<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Thu<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Fri<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>Sat<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ol</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ol</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>0:Sun<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>1:Mon<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>2:Tus<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>3:Wen<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>4:Thu<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>5:Fri<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">li</span>&gt;</span>6:Sat<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ol</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><code>while</code> 调用方式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- while</span><br><span class="line">- var day = 1</span><br><span class="line">ul</span><br><span class="line">    while day &lt; 7</span><br><span class="line">        li= day++</span><br></pre></td></tr></table></figure>

<h2 id="Minix"><a href="#Minix" class="headerlink" title="Minix"></a>Minix</h2><p><code>mixin</code> 名曰混入，类似其它编程语言中的函数，也是为了代码复用，可带参数或不带参数，定义方式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mixin menu-item(href, name)</span><br><span class="line">    li</span><br><span class="line">        span.dot ●</span><br><span class="line">        a(href=href)= name</span><br></pre></td></tr></table></figure>
<p>其中，<code>menu-item</code> 为调用时所用名称，可认为是函数名，<code>href</code> 及 <code>name</code> 是参数。同上定义变量所说，<code>a(href=href)= name</code> 中第二个 <code>=</code> 是为了将后面的 <code>name</code> 当作参数来处理，而不是当作字符串 <code>&quot;name&quot;</code> 来处理。</p>
<p>调用 <code>mixin</code> 定义的代码块，需通过 <code>+</code> 号紧跟 <code>mixin</code> 名称及参数:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">+menu-item(&#x27;/Archives&#x27;,&#x27;Archives&#x27;)</span><br><span class="line">+menu-item(&#x27;/About&#x27;,&#x27;About&#x27;)</span><br></pre></td></tr></table></figure>
<p><code>mixin</code> 之所以称为混入，是因为其语法不局限于函数调用，在 <code>mixin</code> 可以使用块 <code>block</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mixin print(post)</span><br><span class="line">    if block</span><br><span class="line">        block</span><br><span class="line">    else</span><br><span class="line">        p= post</span><br><span class="line"></span><br><span class="line">+print(&quot;no block&quot;)</span><br><span class="line">+print(&quot;&quot;)</span><br><span class="line">    div.box</span><br><span class="line">        p this is the content of block</span><br></pre></td></tr></table></figure>
<p>对应 html 代码：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>no block<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;box&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">p</span>&gt;</span>this is the content of block<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h2><blockquote>
<p>注意以下 <code>pug</code> 语句中第一行的 <code>.</code> 号。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">script(type=&#x27;text/javascript&#x27;).</span><br><span class="line">    var data = &quot;Test&quot;</span><br><span class="line">    var enable = true</span><br><span class="line">    if enable</span><br><span class="line">        console.log(data)</span><br><span class="line">    else</span><br><span class="line">        console.log(&#x27;nothing&#x27;)</span><br></pre></td></tr></table></figure>

<p>对应的 JS 代码如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">&#x27;text/javascript&#x27;</span>&gt;</span><br><span class="line">    <span class="keyword">var</span> data = <span class="string">&quot;Test&quot;</span></span><br><span class="line">    <span class="keyword">var</span> enable = <span class="literal">true</span></span><br><span class="line">    <span class="keyword">if</span> enable</span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(data)</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">&#x27;nothing&#x27;</span>)</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p>对于简单脚本，使用 pug 尚可，复杂的还是单独写到 <code>.js</code> 文件中，然后通过 pug 引用方便一些，引用方式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">script(type=&#x27;text/javascript&#x27;, src=&#x27;/path/to/js&#x27;)</span><br><span class="line"></span><br><span class="line">//- with hexo function url_for</span><br><span class="line">script(type=&#x27;text/javascript&#x27;, src=url_for(theme.js) + &#x27;/ready.js&#x27;)</span><br></pre></td></tr></table></figure>
<h1 id="hexo-相关"><a href="#hexo-相关" class="headerlink" title="hexo 相关"></a>hexo 相关</h1><p>在 hexo 主题中使用 pug 时，可以通过使用 hexo 提供的全局变量 <code>config</code> ， <code>theme</code> 来分别调用博客根目录下 <code>_config.yml</code> 文件中的参数以及主题根目录下 <code>_config.yml</code> 文件中的参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- blog config</span><br><span class="line">p= config.description</span><br><span class="line"></span><br><span class="line">//- theme config</span><br><span class="line">p= theme.title</span><br></pre></td></tr></table></figure>
<p>当然，pug 中可以直接使用 hexo 提供的其它全局变量及辅助函数，使用方法详见 hexo 的文档。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- head.pug</span><br><span class="line">head</span><br><span class="line">    meta(http-equiv=&#x27;content-type&#x27;, content=&#x27;text/html; charset=utf-8&#x27;)</span><br><span class="line">    meta(content=&#x27;width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0&#x27;, name=&#x27;viewport&#x27;)</span><br><span class="line">    meta(content=&#x27;yes&#x27;, name=&#x27;apple-mobile-web-app-capable&#x27;)</span><br><span class="line">    meta(content=&#x27;black-translucent&#x27;, name=&#x27;apple-mobile-web-app-status-bar-style&#x27;)</span><br><span class="line">    meta(content=&#x27;telephone=no&#x27;, name=&#x27;format-detection&#x27;)</span><br><span class="line">    meta(name=&#x27;description&#x27;, content=config.description)</span><br><span class="line">    block title</span><br><span class="line">    link(rel=&#x27;stylesheet&#x27;, type=&#x27;text/css&#x27;, href=url_for(theme.css) + &#x27;/style.css&#x27; + &#x27;?v=&#x27; + theme.version)</span><br><span class="line">    link(rel=&#x27;Shortcut Icon&#x27;, type=&#x27;image/x-icon&#x27;, href=url_for(&#x27;favicon.png&#x27;))</span><br><span class="line">    script(type=&#x27;text/javascript&#x27;, src=&#x27;//cdn.bootcss.com/jquery/3.3.1/jquery.min.js&#x27;)</span><br><span class="line">    block more</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">//- base.pug</span><br><span class="line">doctype html</span><br><span class="line">html(lang=&#x27;en&#x27;)</span><br><span class="line">    include _partial/head.pug</span><br><span class="line">    block more</span><br><span class="line">        link(rel=&#x27;stylesheet&#x27;, type=&#x27;text/css&#x27;, href=url_for(theme.plugins) + &#x27;/prettify/doxy.css&#x27;)</span><br><span class="line">        script(type=&#x27;text/javascript&#x27;, src=url_for(theme.js) + &#x27;/ready.js&#x27; + &#x27;?v=&#x27; + theme.version, async)</span><br><span class="line">    </span><br><span class="line">    //- body</span><br><span class="line">    body: #container.box</span><br><span class="line">        .h-wrapper</span><br><span class="line">            include _partial/nav-menu.pug</span><br><span class="line">        // article content</span><br><span class="line">        block content</span><br><span class="line"></span><br><span class="line">        include _partial/footer.pug</span><br></pre></td></tr></table></figure>
<p>其中:</p>
<ul>
<li><code>theme.*</code> 为主题配置文件 <code>_config.yml</code> 中的参数</li>
<li><code>url_for</code> 为 hexo 提供的用于查找资源路径的函数</li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>pug 提供了 <code>包含</code> ，<code>继承</code> ，<code>Mixin</code> 等多种方式用于代码复用，语法简洁易懂，除了初学时需花费一些时间学习各种标点符号的含义外，其它倒也没有太大困难。</p>
<p>当然啦，pug 还有许多其它特性，但就我目前使用情况而言，以上这些便已足够。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a href="https://pugjs.org/zh-cn/api/getting-started.html">pugjs.org</a></li>
<li><a href="https://hexo.io/zh-cn/docs/">hexo.io&#x2F;zh-cn&#x2F;docs&#x2F;</a></li>
</ol>
<h2 id="原文出处"><a href="#原文出处" class="headerlink" title="原文出处"></a>原文出处</h2><ul>
<li>作者：litreily</li>
<li>链接：<a href="https://juejin.cn/post/6844903668383236104">https://juejin.cn/post/6844903668383236104</a></li>
<li>来源：掘金</li>
<li>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</li>
</ul>
]]></content>
      <categories>
        <category>学编程</category>
      </categories>
      <tags>
        <tag>博客建站</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown高级语法</title>
    <url>/markdown-advance-syntax.html</url>
    <content><![CDATA[<p>只有少数编辑器支持，或者需要安装相应的扩展渲染，使用前请先预览确认。</p>
<span id="more"></span>

<h1 id="定义列表"><a href="#定义列表" class="headerlink" title="定义列表"></a>定义列表</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Term 1</span><br><span class="line">Term 2</span><br><span class="line">:   Definition A</span><br><span class="line">:   Definition B</span><br></pre></td></tr></table></figure>

<p>会被编译成</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;dl&gt;</span><br><span class="line">&lt;dd&gt;Term 1&lt;/dd&gt;</span><br><span class="line">&lt;dd&gt;Term 2&lt;/dd&gt;</span><br><span class="line">&lt;dt&gt;Definition A&lt;dt&gt;</span><br><span class="line">&lt;dt&gt;Definition A&lt;dt&gt;</span><br><span class="line">&lt;/dl&gt;</span><br></pre></td></tr></table></figure>

<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><p>通过<code>[TOC]</code>标记来插入目录。</p>
<p>在编辑器不支持<code>[TOC]</code>标记的情况下可以使用添加id的方法构建目录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## Directory</span><br><span class="line">* [1.Content one](#chapter1)</span><br><span class="line">* [2.Content two](#chapter2)</span><br><span class="line"></span><br><span class="line">## &lt;span id=&quot;chapter1&quot;&gt;1.Content one&lt;/span&gt;</span><br><span class="line">## &lt;span id=&quot;chapter2&quot;&gt;2.Content two&lt;/span&gt;</span><br></pre></td></tr></table></figure>


<h1 id="TeX公式"><a href="#TeX公式" class="headerlink" title="TeX公式"></a>TeX公式</h1><p>内联的TeX公式使用一个美元符号标记。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N$</span><br></pre></td></tr></table></figure>

<p>会被编译成<br>内联（行内）公式：$\Gamma(n) &#x3D; (n-1)!\quad\forall n\in\mathbb N$</p>
<p>TeX公式块用独占一行的两个美元符号来标记。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$$\left \lbrace \sum_&#123;i=0&#125;^n i^3 = \frac&#123;(n^2+n)(n+6)&#125;&#123;9&#125; \right \rbrace$$</span><br></pre></td></tr></table></figure>

<p>会被编译成</p>
<p>$$\left \lbrace \sum_{i&#x3D;0}^n i^3 &#x3D; \frac{(n^2+n)(n+6)}{9} \right \rbrace$$</p>
<p>如果你的编辑器不支持这个功能，可以手动解决。首先引入mathjax脚本：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p>之后，在需要插入公式的地方使用 <code>&lt;script&gt;</code> 标签包裹公式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;script type=&quot;math/tex&quot;&gt;\Gamma(n) = (n-1)!\quad\forall n\in\mathbb N&lt;/script&gt;</span><br><span class="line"></span><br><span class="line">&lt;script type=&quot;math/tex; mode=display&quot;&gt;</span><br><span class="line">\Gamma(z) = \int_0^\infty t^&#123;z-1&#125;e^&#123;-t&#125;dt\,.</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p>以上公式展示效果，在实际显示过程中，根据网络加载速度不同会有不同的解析展示速度，TeX的语法参考请见<a href="http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference">这里</a>。</p>
<h1 id="UML图"><a href="#UML图" class="headerlink" title="UML图"></a>UML图</h1><p>语法为在代码块开始行后面加入语法声明，如 ```mermaid ，然后可以像这样来画uml时序图：</p>
<pre class="mermaid">sequenceDiagram
  Alice->>Bob: Hello Bob,how are you?
  Note right of Bob: Bob thinks
  Bob-->>Alice: I am fine thanks! and U?
  Note left of Alice: SB</pre>

<p>其MarkDown代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\`\`\`mermaid</span><br><span class="line">sequenceDiagram</span><br><span class="line">  Alice-&gt;&gt;Bob: Hello Bob,how are you?</span><br><span class="line">  Note right of Bob: Bob thinks</span><br><span class="line">  Bob--&gt;&gt;Alice: I am fine thanks! and U?</span><br><span class="line">  Note left of Alice: SB</span><br><span class="line">\`\`\` #代码块标识会被解析，实际上写代码块时不用添加转义符“\”</span><br></pre></td></tr></table></figure>

<p>时序图的语法请见 <a href="https://mermaidjs.github.io/sequenceDiagram.html">这里</a> 或 <a href="http://bramp.github.io/js-sequence-diagrams/">这里</a>。</p>
<p>uml流程图：</p>
<pre class="mermaid">  graph LR;
    A-->B & C-->D;</pre>

<p>其实现代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\`\`\`mermaid</span><br><span class="line">graph LR;</span><br><span class="line">  A--&gt;B &amp; C--&gt;D;</span><br><span class="line">\`\`\`</span><br></pre></td></tr></table></figure>

<p>流程图的语法请见 <a href="https://mermaidjs.github.io/flowchart.html">这里</a>， 更复杂点的flowchart可以看 <a href="http://adrai.github.io/flowchart.js/">这里</a> 。</p>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ol>
<li><a href="/how-to-draw-flowchart-with-markdown.html">MarkDown文档中如何画出流程图</a></li>
<li><a href="https://github.com/wizardforcel/markdown-simple-world">https://github.com/wizardforcel/markdown-simple-world</a></li>
<li><a href="http://stevenshi.me/2017/06/26/hexo-insert-formula/">http://stevenshi.me/2017/06/26/hexo-insert-formula/</a></li>
<li><a href="https://blog.csdn.net/u013282174/article/details/80666123">https://blog.csdn.net/u013282174/article/details/80666123</a></li>
<li><a href="https://www.liuyude.com/How_to_make_your_HEXO_blog_support_handwriting_flowchart.html">https://www.liuyude.com/How_to_make_your_HEXO_blog_support_handwriting_flowchart.html</a></li>
<li><a href="https://mermaidjs.github.io/">https://mermaidjs.github.io/</a></li>
</ol>
<script type="text/javascript" async
  src="https://unpkg.com/mermaid@9.1.1/dist/mermaid.min.js">
</script>
]]></content>
      <categories>
        <category>学编程</category>
      </categories>
      <tags>
        <tag>混技能</tag>
      </tags>
  </entry>
  <entry>
    <title>Bert微调及BERT变体</title>
    <url>/Bert%E5%BE%AE%E8%B0%83%E5%8F%8ABERT%E5%8F%98%E4%BD%93.html</url>
    <content><![CDATA[<h1 id="Bert微调及BERT变体"><a href="#Bert微调及BERT变体" class="headerlink" title="Bert微调及BERT变体"></a>Bert微调及BERT变体</h1><p>1、BERT预训练作用</p>
<ol>
<li>学习通用语言表示：通过在大规模无标签语料上进行预训练，BERT可以学习到丰富的、通用的语言表示。这些语言表示可以捕捉到词汇、句法和语义等不同级别的信息，从而能够更好地理解和表示自然语言的含义。</li>
<li>上下文理解：BERT通过双向编码方式对文本进行建模，可以有效地理解上下文中的依赖关系和语义信息。模型的每个位置可以同时考虑其前后文的上下文信息，而不仅仅是局限于当前位置。</li>
<li>词义消歧：BERT预训练模型对于词义消歧具有优势。通过预训练，模型可以学习到多义词的各种上下文语境，进而能够更好地理解和区分同一词在不同上下文中的含义。</li>
<li>迁移学习：预训练的BERT模型具有广泛的语言理解能力，这使得它可以作为下游任务的初始模型进行迁移学习。通过微调预训练模型，可以在特定任务上节省大量的数据和时间，同时获得更好的性能。这对于具有有限数据集的任务和资源受限环境中的应用特别有用。</li>
</ol>
<p>2、什么是微调？</p>
<p>链接：<a href="https://blog.csdn.net/qq_45652492/article/details/123379156">(141条消息) fine-tuning（微调）的理解_好耶OvO的博客-CSDN博客</a></p>
<p>3、什么是冻结层</p>
<p>冻结层指该层不加入网络训练，该层参数不会更新。</p>
<p><a href="https://cloud.tencent.com/developer/article/1912592">怎么固定住某些网络</a></p>
<p>4、BERT变体</p>
<p>BERT的动态掩码机制能够学习到更好的上下文表示和更准确的单词表示，提高对单词的理解能力，增加模型的鲁棒性和泛化能力。NSP（Next Sentence Prediction）任务通过预测下一句子的概率，模型需要学习句子之间的语义关系和连贯性。这使得模型能够更好地理解句子中的上下文信息，从而提高对句子语义的理解和表示能力。这对于某些任务，如文本匹配、推理和问答等需要考虑句子之间关系的任务特别有用。模型可以利用学到的句子级别的语义信息在这些任务中更好地获取句子之间的语义匹配和推理能力。</p>
<p><a href="https://blog.csdn.net/yjw123456/article/details/120499194">(141条消息) 一起来学习BERT常见的几个变体_bert变体_愤怒的可乐的博客-CSDN博客</a></p>
]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>HAN(Hierarchy Attention Network)模型及实现</title>
    <url>/HAN-Hierarchy-Attention-Network-%E6%A8%A1%E5%9E%8B.html</url>
    <content><![CDATA[<h2 id="HAN-Hierarchy-Attention-Network-模型"><a href="#HAN-Hierarchy-Attention-Network-模型" class="headerlink" title="HAN(Hierarchy Attention Network)模型"></a>HAN(Hierarchy Attention Network)模型</h2><p>文本由时序性的sentence组成，而sentence则是由时序性的word组成。我们要想根据文章的语义对一篇文章进行分类，模型分两步来进行，首先从单词层面分析每个句子的语义。总结出每个句子的语义后，再将句子综合起来表征整篇文章的语义，并对其进行分类。</p>
<p>模型的结构就如下图所示，分为上下两个 block，两个 block 的结构完全一致，都是由 Bi-GNN 组成特征抽取器，同时添加了注意力机制。下层的 block 做句子级别的特征抽取，得出句子表示，抽取后的句子特征向量作为上层 block 每一时刻的输入，再由上层 block 进行篇章级别的特征抽取得出文本向量，最后还是使用 Softmax 做最后的分类。</p>
<p><img src="https://s3.bmp.ovh/imgs/2023/07/23/04dd7e2357f80f13.png"></p>
<p>实验结果：</p>
<p><img src="https://s3.bmp.ovh/imgs/2023/07/23/c9f59c476ef7b12c.png"></p>
<h2 id="模型代码-pytorch"><a href="#模型代码-pytorch" class="headerlink" title="模型代码(pytorch)"></a>模型代码(pytorch)</h2><p>[论文链接](<a href="https://www.microsoft.com/en-us/research/uploads/prod/2017/06/Hierarchical-Attention-Networks-for-Document-Classification.pdf">Hierarchical Attention Networks for Document Classification (microsoft.com)</a>)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Attention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, hidden_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(Attention, self).__init__()</span><br><span class="line">        self._hidden_size = hidden_size   <span class="comment">#hidden_size作为输入，它表示输入序列的隐藏状态的大小。</span></span><br><span class="line">        <span class="comment"># Linear layer for the tanh activation (eq. 5 in paper)</span></span><br><span class="line">        <span class="comment">#  (times two because bidirectional)双向线性层</span></span><br><span class="line">        self._layer1 = nn.Linear(<span class="number">2</span> * hidden_size, <span class="number">2</span> * hidden_size) <span class="comment">#两层线性层，layer1和layer2</span></span><br><span class="line">        <span class="comment"># Linear layer for the softmax activation (eq. 6 in paper)</span></span><br><span class="line">        self._layer2 = nn.Linear(<span class="number">2</span> * hidden_size, <span class="number">2</span> * hidden_size, bias = <span class="literal">False</span>)</span><br><span class="line">        <span class="comment">#layer2:该层用于使用softmax激活函数计算注意力权重。它的输入和输出大小为2 * hidden_size。注意权重将决定输入序列中每         #个隐藏状态的关注程度。</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, hidden_states</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        注意力机制的向前传递</span></span><br><span class="line"><span class="string">		param hidden_states:输入序列在时刻T的隐藏状态</span></span><br><span class="line"><span class="string">		return:上下文向量(GRU加权输出)和关注权重</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># (see equation 5)</span></span><br><span class="line">        u = torch.tanh(self._layer1(hidden_states))</span><br><span class="line">        <span class="comment"># (see equation 6)</span></span><br><span class="line">        alphas = F.softmax(self._layer2(u), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># --&gt; current dimensions: X x Y x Z</span></span><br><span class="line">        <span class="comment"># Sentence vectors</span></span><br><span class="line">        <span class="comment"># (see equation 7)</span></span><br><span class="line">        <span class="comment"># Apply the attention weights (alphas) to each hidden state</span></span><br><span class="line">        sentence = torch.<span class="built_in">sum</span>(torch.mul(alphas, hidden_states), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># Return</span></span><br><span class="line">        <span class="keyword">return</span>(sentence, alphas)</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">word_encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_size, hidden_size</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Word encoder. This part takes a minibatch of input sentences, applies a GRU and attention</span></span><br><span class="line"><span class="string">         and returns the sequences.</span></span><br><span class="line"><span class="string">        :param embedding_size: Size of the word embedding</span></span><br><span class="line"><span class="string">        :param hidden_size: number of hidden units in the word-level GRU</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(word_encoder, self).__init__()</span><br><span class="line">        self._hidden_size = hidden_size</span><br><span class="line">        </span><br><span class="line">        self.GRU = nn.GRU(embedding_size, self._hidden_size,</span><br><span class="line">                        bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)       </span><br><span class="line">        self.attention = Attention(self._hidden_size)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs_embedded, hid_state</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param inputs_embedded: word embeddings of the mini batch at time t (sentence x seq_length)</span></span><br><span class="line"><span class="string">        :return: tuple containing:</span></span><br><span class="line"><span class="string">            (1) weighted GRU annotations (GRU output weighted by the attention vector)</span></span><br><span class="line"><span class="string">            (2) [final hidden state of GRU (unweighted), attention weights]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Bidirectional GRU</span></span><br><span class="line">        output_gru, last_hidden_state = self.GRU(inputs_embedded)</span><br><span class="line">        <span class="comment"># Unpack packed sequence</span></span><br><span class="line">        output_padded, output_lengths = pad_packed_sequence(output_gru, batch_first=<span class="literal">True</span>)<span class="comment">#填充序列压紧</span></span><br><span class="line">        <span class="comment"># Attention</span></span><br><span class="line">        output_attention, att_weights = self.attention(output_padded)</span><br><span class="line">        <span class="comment"># Return</span></span><br><span class="line">        <span class="keyword">return</span>(output_attention.unsqueeze(dim=<span class="number">0</span>), [last_hidden_state, att_weights])<span class="comment">#被注意力加权之后的GRU输出</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">sentence_encoder</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, word_hidden_size, hidden_size</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Sentence encoder. This part takes as its input a minibatch of documents which have been created by</span></span><br><span class="line"><span class="string">         the word encoder. It applies a GRU, attention and returns the weighted GRU output.</span></span><br><span class="line"><span class="string">        :param word_hidden_size: The number of hidden units of the word encoder.</span></span><br><span class="line"><span class="string">        :param hidden_size: The number of hidden units used for the sentence encoder.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(sentence_encoder, self).__init__()</span><br><span class="line">        self._hidden_size = hidden_size</span><br><span class="line">        <span class="comment"># Sentence-GRU</span></span><br><span class="line">        self.GRU = nn.GRU(word_hidden_size, self._hidden_size,</span><br><span class="line">                          bidirectional=<span class="literal">True</span>, batch_first=<span class="literal">True</span>)       </span><br><span class="line">        <span class="comment"># Attention</span></span><br><span class="line">        self.attention = Attention(hidden_size)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, encoder_output, hid_state</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param encoder_output: output of the word encoder.</span></span><br><span class="line"><span class="string">        :return: weighted annotations created by the sentence GRU</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Bidirectional GRU</span></span><br><span class="line">        output_gru, last_hidden_state = self.GRU(encoder_output)</span><br><span class="line">        <span class="comment"># Attention</span></span><br><span class="line">        output_attention, att_weights = self.attention(output_gru)</span><br><span class="line">        <span class="comment"># Return</span></span><br><span class="line">        <span class="comment"># (weighted attention vector, hidden states of the sentences)</span></span><br><span class="line">        <span class="keyword">return</span>(output_attention.unsqueeze(dim=<span class="number">0</span>), [last_hidden_state, att_weights])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HAN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, </span></span><br><span class="line"><span class="params">                 vocab_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 embedding_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 hidden_size_words: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 hidden_size_sent: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 batch_size: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 num_classes: <span class="built_in">int</span>, </span></span><br><span class="line"><span class="params">                 device = <span class="string">&quot;cpu&quot;</span>,</span></span><br><span class="line"><span class="params">                 dropout_prop = <span class="number">0</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Implementation of a Hierarchical Attention Network (HAN).</span></span><br><span class="line"><span class="string">        :param vocab_size: Size of the input vocabulary</span></span><br><span class="line"><span class="string">        :param embedding_size: Size of the word embedding</span></span><br><span class="line"><span class="string">        :param hidden_size_words: number of hidden units for the word encoder.</span></span><br><span class="line"><span class="string">        :param hidden_size_sent: number of hidden units for the sentence encoder.</span></span><br><span class="line"><span class="string">        :batch_size: size of the minibatches passed to the HAN.</span></span><br><span class="line"><span class="string">        :num_classes: number of output classes in the classification task.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(HAN, self).__init__()</span><br><span class="line">        self._hidden_size_words = hidden_size_words</span><br><span class="line">        self._hidden_size_sent = hidden_size_sent</span><br><span class="line">        self._embedding_dim = (vocab_size, embedding_size)</span><br><span class="line">        self._num_classes = num_classes</span><br><span class="line">        self._batch_size = batch_size</span><br><span class="line">        self._dropout_prop = dropout_prop</span><br><span class="line">        <span class="comment"># Embedding</span></span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embedding_size)</span><br><span class="line">        <span class="comment"># Set up word encoder</span></span><br><span class="line">        self._word_encoder = word_encoder(self._embedding_dim[<span class="number">1</span>], self._hidden_size_words)</span><br><span class="line">        <span class="comment"># Set up sentence encoder</span></span><br><span class="line">        self._sentence_encoder = sentence_encoder(self._hidden_size_words * <span class="number">2</span>, self._hidden_size_sent)</span><br><span class="line">        <span class="comment"># Set up a linear layer</span></span><br><span class="line">        self._linear1 = nn.Linear(self._hidden_size_sent * <span class="number">2</span>, self._num_classes)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, seqs, seq_lens, hid_state_word, hid_state_sent, return_attention_weights = <span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param batch_in: list of input documents of size batch_size input document with dim (sentence x seq_length)</span></span><br><span class="line"><span class="string">        :param return_attention_weights: if True, return attention weights</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :return: tensor of shape (batch_size, num_classes) and, optionally, the attention vectors for the word and sentence encoders.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># Placeholders</span></span><br><span class="line">        batched_sentences = <span class="literal">None</span></span><br><span class="line">        batch_length = <span class="built_in">len</span>(seqs)</span><br><span class="line">        <span class="comment"># If return attention weights</span></span><br><span class="line">        <span class="keyword">if</span> return_attention_weights:</span><br><span class="line">            word_weights = []</span><br><span class="line">        <span class="comment"># For each, do ...</span></span><br><span class="line">        <span class="keyword">for</span> i, seqdata <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(seqs,seq_lens)):</span><br><span class="line">            <span class="comment"># Unzip</span></span><br><span class="line">            seq, seq_len = seqdata</span><br><span class="line">            <span class="comment"># Embedding</span></span><br><span class="line">            embedded = self.embedding(seq)</span><br><span class="line">            <span class="comment"># Pack sequences</span></span><br><span class="line">            x_packed = pack_padded_sequence(embedded, seq_len, batch_first=<span class="literal">True</span>, </span><br><span class="line">                                            enforce_sorted=<span class="literal">False</span>)</span><br><span class="line">            <span class="comment"># Word encoder</span></span><br><span class="line">            we_out, hid_state = self._word_encoder(x_packed, hid_state_word)</span><br><span class="line">            <span class="comment"># Cat sentences together</span></span><br><span class="line">            <span class="keyword">if</span> batched_sentences <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                batched_sentences = we_out</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                batched_sentences = torch.cat((batched_sentences, we_out), <span class="number">0</span>)</span><br><span class="line">                <span class="comment"># Sentence encoder</span></span><br><span class="line">                out_sent, hid_sent = self._sentence_encoder(batched_sentences.permute(<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>), hid_state_sent)</span><br><span class="line">            <span class="comment"># Cat the attention weights</span></span><br><span class="line">            <span class="keyword">if</span> return_attention_weights:</span><br><span class="line">                word_weights.append(hid_state[<span class="number">1</span>].data)</span><br><span class="line">                <span class="comment"># If last sentence</span></span><br><span class="line">                <span class="keyword">if</span> i == batch_length:</span><br><span class="line">                    sentence_weights = hid_sent[<span class="number">1</span>].data</span><br><span class="line">        <span class="comment"># Apply dropout</span></span><br><span class="line">        out_sent_dropout = F.dropout(out_sent.squeeze(<span class="number">0</span>), p=self._dropout_prop)</span><br><span class="line">        <span class="comment"># Linear layer &amp; softmax</span></span><br><span class="line">        prediction_out = F.softmax(self._linear1(out_sent_dropout), dim = <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># Return</span></span><br><span class="line">        <span class="keyword">if</span> return_attention_weights:</span><br><span class="line">            <span class="comment"># Compute attention weights for words and sentences</span></span><br><span class="line">            <span class="keyword">return</span>(prediction_out, [word_weights, sentence_weights])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span>(prediction_out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden_sent</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> Variable(torch.zeros(<span class="number">2</span>, self._batch_size, self._hidden_size_sent))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden_word</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> Variable(torch.zeros(<span class="number">2</span>, self._batch_size, self._hidden_size_words))</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer-based Models for Long Document Classification论文阅读</title>
    <url>/Revisiting-Transformer-based-Models-for-Long-Document-Classification%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB.html</url>
    <content><![CDATA[<h1 id="Revisiting-Transformer-based-Models-for-Long-Document-Classification论文阅读"><a href="#Revisiting-Transformer-based-Models-for-Long-Document-Classification论文阅读" class="headerlink" title="Revisiting Transformer-based Models for Long Document Classification论文阅读"></a>Revisiting Transformer-based Models for Long Document Classification论文阅读</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>比较了不同的基于transformer的长文档分类(TrLDC)方法，这些方法旨在减轻普通转换器编码更长的文本的计算开销，即稀疏注意和分层编码方法。我们在覆盖不同领域的四个文档分类数据集上研究了稀疏注意(例如，局部注意窗口的大小，全局注意的使用)和分层(例如，文档分割策略)转换的几个方面。我们观察到能够处理较长的文本的明显好处，并且根据我们的结果，我们得出了在长文档分类任务上应用基于transformer的模型的实用建议。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>对于长文档分类来说，截断文本可能会遗漏重要信息，导致分类性能差(图1)。另一个挑战就是每一个token都会关注其他所有token，在多头自注意力的操作中计算开销。使得处理长文本变得非常困难。</p>
<p>对于第二个挑战，长文本的transformer已经出现。但是他们的实验在一个并不好的数据集上。在一些数据集上，BERT的多个变体比基于CNN或rnn的模型表现更差。作者们认为有必要了解基于transformer的模型在对实际较长的文档进行分类时的性能。</p>
<p><strong>贡献</strong>：比较了基于transformer架构的不同长文档分类方法:即稀疏关注和分层方法。一些设计选择(如稀疏注意方法中的局部注意窗口大小)可以在不牺牲有效性的情况下提高效率，而一些选择(如分层方法中的文档分割策略)会极大地影响有效性。基于transformer的模型可以在MIMIC-III数据集上优于以前最先进的基于CNN的模型。</p>
<h2 id="问题陈述和数据集"><a href="#问题陈述和数据集" class="headerlink" title="问题陈述和数据集"></a>问题陈述和数据集</h2><p>我们将文档分类模型分为两个组件:<em>(1)文档编码器，它构建给定文档的向量表示;(2)一个分类器，该分类器预测给定编码向量的单个或多个标签。</em>我们使用基于transformer的编码器来构建文档表示，然后将编码的文档表示作为分类器的输入。我们使用TANH激活的隐藏层，然后是输出层。输出概率通过应用SIGMOID或者SOFTMAX得到。我们主要在MIMIC-III数据集上进行实验</p>
<p>MIMIC-III包含重症监护病房(ICU)出院摘要，每个摘要都使用ICD-9(国际疾病分类，第九次修订版)层次结构用多个标签-诊断和程序进行注释。根据Mullenbach等人(2018)的研究，我们使用前50个频繁标签进行实验</p>
<p>为了解决一般化的问题，我们还使用了来自其他领域的三个数据集:ECtHR来自法律案件，Hyperpartisan 和20 News 均来自新闻文章。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><h3 id="Sparse（稀少的）-Attention-Transformers"><a href="#Sparse（稀少的）-Attention-Transformers" class="headerlink" title="Sparse（稀少的）-Attention Transformers"></a>Sparse（稀少的）-Attention Transformers</h3><p>Beltagy等人(2020)的Longformer由本地(基于窗口的)注意力和全局注意力组成，这降低了模型的计算复杂性，因此可以部署到处理多达4096个令牌。</p>
<p>BigBird是另一个基于稀疏注意力的Transformer，它使用本地、全局和随机注意力的组合，即所有令牌也会在同一邻域中的令牌之上参加许多随机令牌。这两个模型都是从公共RoBERTa检查点热启动的，并进一步对掩码语言建模进行预训练。据报道，在一系列需要长序列建模的任务中，它们的表现优于RoBERTa。</p>
<h3 id="Hierarchical-Transformers"><a href="#Hierarchical-Transformers" class="headerlink" title="Hierarchical Transformers"></a>Hierarchical Transformers</h3><p>文本先被分割成段，每个段应该有少于512个token，每个片段可以使用预训练的transformer编码器，将每个片段第一个token的上下文表示与片段位置嵌入相加作为片段表示。片段编码器transformer分为两部分捕获片段之间的关系和上下文片段表示输出列表。</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络</title>
    <url>/TRIMOON%E5%9F%BA%E4%BA%8E%E4%B8%A4%E8%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C.html</url>
    <content><![CDATA[<h1 id="TRIMOON-基于两轮不一致性的假新闻检测多模态融合网络"><a href="#TRIMOON-基于两轮不一致性的假新闻检测多模态融合网络" class="headerlink" title="TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络"></a>TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络</h1><p>然而，有时新闻文章的文本和图像之间存在不一致。因此，为了判断图像和文本的一致性，Xue等[16]提出了一种<strong>多模态一致性神经网络</strong>(multi-modal consistency neural network, MCNN)，其中包含相似度测量模块，使用余弦距离来测量图像和文本之间的一致性。本实验考虑了多模态数据的一致性，大大增强了对虚假新闻+图像不匹配情况的检测。在基于多模态的假新闻检测方面，该模型比其他基线模型更有效。</p>
<p>综上所述，虽然现有的研究主要集中在图文多模态融合和图文一致性检测两种方法上，也取得了较好的表现，但目前的方法仍然面临以下挑战:(1)多模态特征融合和图文一致性判别是独立进行的，导致最终的融合特征中存在噪声。(2)由于文本是新闻文章的主体，在现有的模式中，文本情态中的信息在表达信息中的主导作用还没有充分体现出来。因此，如何充分考虑图像和文本特征的融合，突出文本在新闻中的主导地位，同时兼顾图像和文本的一致性问题，还有待探索。</p>
<p>为了解决上述挑战，我们提出了一种考虑图像-文本不一致性的多模态融合模型，称为基于两轮不一致性的多模态融合网络(TRIMOON)。</p>
<p>首先，我们在一般的图像-文本共注意融合模块之前构建了语义一致性评分模块，目的是基于一致性程度来控制融合强度。其次，我们进行了文本形态的融合和图像-文本融合表示，以加强文本信息的主导地位。最后，在融合表示的基础上，利用双向长短期记忆(BiLSTM)对文档表示进行编码，并通过全连通层输出分类标签。</p>
<p>本文的主要贡献如下:</p>
<p>本文提出了一种基于图像-文本一致性的多模态融合模块用于假新闻检测（本人想法：还可以融合其他模态比如情感特征、上下文特征）抑制图像和文本不一致时融合表示产生的噪声。</p>
<p>我们为图像-文本信息融合的表征提供了一种二次融合机制，从而加强了文本模式在新闻媒体中的主导作用。</p>
<p>本文的后续章节组织如下。</p>
<p>第2节提供了相关工作的分析，并总结了我们提出的方法与现有方法之间的差异。第3节详细介绍了本文提出的TRIMOON模型。第4节提供了验证实验的设置和实验结果的观察和分析。第5节讨论了建模中需要解决的一些问题。最后一部分是结束语，指出了未来的研究方向。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>Based on traditional machine learning</strong></p>
<p>Castillo等[19]从用户的传播行为角度出发，构建了内容、话题、传播、行为等特征集，并通过SVM[20]、J48[21]等机器学习算法进行验证，最终达到89%的分类准确率。实验验证了引入上述四类特征的有效性。</p>
<p>Ruchansky等[22]提出了一种自动假新闻检测器CSI (Capture, Score, and Integrate)。它由三个模块组成:捕获、评分和集成。检测器通过使用与传入新闻相关的三个特征来预测假新闻:文本、响应和来源。该模型由三个模块组成。第一个算法提取新闻文章的时间表示。第二个模块表示用户的行为并对其进行评分，最后一个模块使用前两个模块的输出并使用它们进行分类。他们的实验表明，CSI的准确性有所提高。Reis等人[23]针对该任务提出了一种新的特征集，并将其应用于现有的自动检测模型，并通过实验验证了新特征集的有效性。此外，假新闻的目的之一是操纵人们的观点，因此在一些工作中，情绪信息[24]也被认为是一个特征[25,26]。</p>
<p>显式特征很容易解释，但不一定是机器学习模型学习的最佳数据。最近，一些研究工作开始探索假新闻的隐含特征。Guo等[27]根据新闻数据，基于用户画像构建特征，纳入用户行为、可信度、可靠性等隐式特征。Wu等[28]提出了新闻话题类型和情感特征，结合消息传播间隔特征，使用随机行走[29]核函数的支持向量机算法进行分类，在微博数据集上取得了很好的效果。</p>
<p><strong>Based on deep learning and multi-modal</strong></p>
<p>随着新闻内容变得越来越复杂，仅仅依靠人工特征是不够的。此外，随着深度学习算法的普及，许多研究人员已经开始使用基于深度神经网络的模型来完成假新闻检测任务。挖掘出比传统机器学习中使用的人工特征更重要、更容易学习的特征。同时，通过深度神经网络将多模态信息引入到假新闻检测中。</p>
<p>Jin等人[32]提出了一种基于注意力的递归神经网络(att-RNN)，该网络融合了来自文本、视觉和社会背景的信息。Wang等[33]提出了一种事件对抗神经网络(Event Adversarial Neural Network, EANN)，将事件分类任务引入到对抗学习中，引导模型学习与事件无关的文本模态和图像模态特征，具有更好的泛化性能。Khatter等[34]提出了一种端到端的多模态变分自编码器(MVAE)网络，该网络由编码器、解码器和假新闻检测模块三个主要组成部分组成，利用编码器-解码器结构构建多模态新闻的特征表达。</p>
<p>以上方法在检测具有多模态信息的假新闻方面是有效的，但由于缺乏足够的事实知识，无法充分理解多模态新闻事件的深层语义。</p>
<p>为了解决这一问题，Zhang等[35]提出了一种新的多模态知识感知事件记忆网络(MKEMN)，该网络利用多模态知识感知网络(MKN)和事件记忆网络(EMN)作为社交媒体谣言检测的构建模块。从外部知识图谱中提取文本实体对应的概念知识，并将其集成到多模态表示中，以获得更高的语义理解能力。</p>
<p>Wang等[36]提出了一种新的知识驱动的多模态图卷积网络(KMGCN)，该网络通过对文本信息的联合建模来建模语义表示，并将知识概念和视觉信息集成到统一的假新闻检测框架中。事实上，图像的可用性也是多模态融合模型中需要考虑的问题。</p>
<p>一些工作考虑将文本与图像中出现的实体对齐，以区分图像和文本之间的不一致，从而提高检测性能[37,38]。随后，Li等人提出了一个以实体为中心的多模态学习框架，该框架通过实体对齐和以实体为中心的特征聚合两个模块学习新的特征表示来训练分类器[39]。Chen等人提出了一种跨模态歧义学习模型，用于单模态和多模态特征的动态融合，歧义大时以单模态特征为主，歧义小时以跨模态特征为主[40]。</p>
<p>本文从图像和文本一致性的角度提出了一种新的多模态融合方法。与实体级一致性不同[37,38]，我们考虑图像与新闻文本的整体语义一致性[16,40]。在我们的方案中，我们突出文本模态作为新闻的主导信息，同时基于不一致性适当融合图像模态信息，而[16]直接将一致性与类标签对齐，[40]从数据集整体层面学习图像和文本模态的一致性表示并在此基础上进行加权融合。在我们的模型中，无论图像信息与文本内容是否一致，都不会取代文本模态特征作为分类的主导特征，这也符合我们人类阅读和判断新闻真假的习惯。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>给定一个集合𝐷&#x3D;{(𝑥𝑖,𝑦𝑖),𝑖&#x3D; 1,…,𝑁}，𝑁新闻条目,每个新闻𝑥𝑖有标签𝑦𝑖∈{0,1}，𝑥𝑖包含𝑥𝑇𝑖和𝑥𝑉𝑖,哪里𝑥𝑇𝑖新闻中的文本,𝑥𝑉𝑖新闻图片。</p>
<p>我们提出的模型将利用训练实例学习一个从特征空间𝑋到标签空间𝑌的映射函数∶𝑋→𝑌，然后利用其特征向量来预测实例的标签向量。我们模型的输入是每个新闻条目的文本和图像。使用BERT和VGG (Visual Geometry Group)网络分别学习文本特征和图像特征。</p>
<p>在我们的工作中，我们认为在检测假新闻时，文本模型是基础，图像信息是辅助。</p>
<p>同时，图像-文本不一致是双模融合中必须考虑的问题。因此，在我们提出的方法中，在每次融合之前，图像信息将经过一个门结构进行信息选择。在多模态特征融合之前，对VGG-19馈送的图像特征进行第一次不一致性度量。然后，我们使用共同关注来捕捉文本特征和过滤后的图像特征之间的关系。在第二次融合中，我们通过另一个不一致性测量门来控制第一次融合后的结果，然后与文本信息重新融合。最后，通过具有全连接层的BiLSTM网络获得预测结果。输出是该新闻的标记(true或false)。所提出的模型整体结构如图2所示。该模型包括: (1)多模态特征提取模块; (2)多模态特征融合模块; (3)分类模块。</p>
<p><strong>The multi-modal feature extraction module</strong></p>
<p>我们使用BERT作为文本编码器。BERT模型的初始输入是一组句子𝑆&#x3D;{𝑠1，𝑠2，…，𝑠𝑚}，𝑠𝑚表示𝑚th句子，其中𝑚∈𝑀;句子𝑠可以表示为一组字符𝑠&#x3D;{𝑤1，𝑤2，…，𝑤N}，𝑤𝑛表示句子中的𝑛th字符。在我们的任务中，𝑆&#x3D;𝑥𝑇𝑖，即𝑖th新闻的文本部分。BERT输入向量由词嵌入向量、段嵌入向量和位置编码向量组成。</p>
<p>词嵌入向量是每个词的向量表示，BERT可以以句子对的形式进行训练，并使用分割的嵌入向量来识别句子。在位置编码向量中，BERT使用学习到的位置编码来识别每个单词的位置信息。然后，BERT模型使用Transformer[44]编码器构建多层双向网络，该网络由多层Transformer编码器堆叠。编码器的每一层由多头自关注子层和前馈神经网络子层组成。</p>
<p><img src="https://picss.sunbangyan.cn/2023/08/31/f9m8ap.png"></p>
<p>𝑇𝑜𝑘𝑒𝑛𝐵𝑒𝑟𝑡是BERT模型的token-level（标记）输出序列。𝑆𝑒𝑛𝑡B𝑒𝑟𝑡为BERT模型的句子级输出; 𝑚𝑡是输出文本特征。</p>
<p>对于新闻分集，提取图像特征的过程可以用方程表示。(4) -(6)。</p>
<p><img src="https://picdl.sunbangyan.cn/2023/08/31/f9ubuz.png"></p>
<p> The inconsistency measurement module不一致性测量模块</p>
<p>该模块通过测量文本和图像之间的语义相似度来评估文本和图像的不一致性。与那些在实体层面衡量一致性的作品不同[37,38]，我们从整体一致性的角度进行思考。</p>
<p>在上一模块中，我们使用BERT和VGG-19学习了文本和图像的特征表示。然后我们在线性层上应用sigmoid函数，其中我们将特征表示连接为输入，以测量它们之间的不一致性。然后，我们采用乘法门来获得加权图像模态表示。在这里，该模块旨在衡量同一新闻的图像和文本的语义一致性，并通过以下门机制进一步控制可以融合的信息程度。可以使用多种方法来度量语义一致性。通过实验比较，我们发现对于我们的数据集，一个简单的线性层是一个更好的选择。</p>
<p><img src="https://picdm.sunbangyan.cn/2023/08/31/fabg5m.png"></p>
<p><strong>特征融合</strong></p>
<p>我们的多模态特征融合主要由两个组件完成:一个由两个并行的共同注意块组成的共同注意层[46]和一个基于门的融合模块。图3给出了共注意块的结构，在Co-Attention块中，它的查询和键(&#x3D;value)来自不同的地方，即，如果查询来自文本，则键(&#x3D;value)来自图像，反之亦然。</p>
<p>对于图像模态，计算过程如下:</p>
<p><img src="https://picdl.sunbangyan.cn/2023/08/31/fasty9.png"></p>
<p>对于文本模态，通过相同的计算过程，我们可以得到文本模态特征。通过将共同注意块A和共同注意块B并行排列，并将它们组合成一个共同注意层。共同关注块A使用文本特征作为查询和图像特征为键，共同关注块B使用图像特征作为查询，文本特征作为键。这样就实现了文本和图像之间信息的交互学习。</p>
<p>基于门的融合模块是第二融合。与已有工作中的共关注叠加分量[47]不同，我们的第二次融合再次基于门机制对特征信息流进行控制，以获得更可靠的特征表示。Wu等[47]在多模态信息重要性相等的前提下，使用了特征信息的迭代融合。但是，我们认为图像模态(及其融合特征)只是辅助信息，其权重需要通过逐步向前融合时的一致性程度来衡量。</p>
<p>融合过程如式所示。(13) -(16)。</p>
<p><img src="https://picst.sunbangyan.cn/2023/08/31/fb1xhg.png"></p>
<p>结论与讨论</p>
<p>通过检测文本模态与图像模态的不一致性，使我们的模型在融合多模态信息时能够学习到更合理的特征表示，从而提高检测性能。此外，在我们的融合模型中，文本形态的主导地位并没有被图像特征所掩盖，就像文本信息是一般新闻的主导信息表示一样。</p>
<p>事实上，当图片与文字不一致时，发布者有可能使用不准确的(挪用的，历史的)图片作为伪造的证据来支持新闻文本中的结论。这是基于不一致信息构造特征融合表示的原因之一。然而，通过对上述实验结果的分析，我们也发现我们的模型对于图像-文本一致性检测仍然处于粗粒度水平，受限于缺乏对图像的语义理解。因此，细粒度图像理解和图像-文本一致性检测仍然是一个挑战。此外，当图像与文本高度一致时，特征失去了多样性，如何更有效地利用或增强文本模态的特征是另一个具有挑战性的问题。</p>
<p>本文提出了一种新的多模态融合方法——基于图像-文本不一致性的两轮多模态融合方法来检测假新闻。首先，分别通过BERT和VGG预训练模型获得文本模态和图像模态的向量表示。然后通过不一致性测量方法计算检测任务的图像模态权重，并进行第一次图像-文本融合以获得融合特征。这些特征不直接输入到分类器中，而是与文本模态的主要特征再次融合，得到最终的特征表示，最后使用分类器进行分类和检测。与其他方法相比，我们的方法有两个明显的优点:(1)在初始融合之前，通过不一致权值对信息进行过滤，从而控制了不真实图像对内容的误导;(2)通过二次融合机制，加强文本模态特征的主导地位，同时兼顾图像模态信息，达到更好的检测性能</p>
<p>在今后的研究中，可以在以下几个方面开展进一步的工作。首先，设计基于视觉语言预训练语言模型的图像文本表示和细粒度一致性检测方案，其次，在标签表示、实体识别和事件识别等辅助方法的基础上，增强基于文本特征和不一致性的多模态融合学习能力。第三，考虑不同粒度的语义不一致度量方法。通过使用上述方法，可以更好地整合图像和文本内容，获得更好的融合特征，实现对假新闻的高效准确检测。</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>bert各层输出</title>
    <url>/bert%E5%90%84%E5%B1%82%E8%BE%93%E5%87%BA.html</url>
    <content><![CDATA[<h1 id="bert各层输出"><a href="#bert各层输出" class="headerlink" title="bert各层输出"></a>bert各层输出</h1><p>在最新的transformers接口中，我们获取bert的各个层输出，需要这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, BertModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line">model = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line"></span><br><span class="line">inputs = tokenizer(<span class="string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">outputs = model(**inputs)</span><br><span class="line"></span><br><span class="line">last_hidden_states = outputs.last_hidden_state  </span><br><span class="line"></span><br><span class="line">last_hidden_state = outputs.last_hidden_state</span><br><span class="line">pooler_output = outputs.pooler_output</span><br><span class="line">hidden_states = outputs.hidden_states</span><br><span class="line">attentions = outputs.attentions</span><br></pre></td></tr></table></figure>

<p><strong>last_hidden_state</strong>：shape是(batch_size, sequence_length, hidden_size)，hidden_size&#x3D;768,它是模型最后一层输出的隐藏状态。（通常用于命名实体识别）<br><strong>pooler_output</strong>：shape是(batch_size, hidden_size)，这是序列的第一个token(classification token)的最后一层的隐藏状态，它是由线性层和Tanh激活函数进一步处理的。（通常用于句子分类，至于是使用这个表示，还是使用整个输入序列的隐藏状态序列的平均化或池化，视情况而定）<br><strong>hidden_states</strong>：这是输出的一个可选项，如果输出，需要指定config.output_hidden_states&#x3D;True,它也是一个元组，它的第一个元素是embedding，其余元素是各层的输出，每个元素的形状是(batch_size, sequence_length, hidden_size)<br><strong>attentions</strong>：这也是输出的一个可选项，如果输出，需要指定config.output_attentions&#x3D;True,它也是一个元组，它的元素是每一层的注意力权重，用于计算self-attention heads的加权平均值。</p>
<p>我们知道bert由12个transformer组成，需要用到这12个transformer块的时候就用hidden_states。使用前的实例化需要配置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">config = BertConfig.from_pretrained( <span class="string">&#x27;bert-base-uncased&#x27;</span>, output_hidden_states=<span class="literal">True</span>, output_attentions=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">bert = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>,config = config)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>代码修改笔记</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/hello-world.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>wine的使用方法</title>
    <url>/ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85windows%E8%BD%AF%E4%BB%B6%E7%9A%84wine%E4%BD%BF%E7%94%A8.html</url>
    <content><![CDATA[<h1 id="wine的使用方法"><a href="#wine的使用方法" class="headerlink" title="wine的使用方法"></a>wine的使用方法</h1><p>1.下载</p>
<p>先安装wine，可以使windows上的程序在linux上运行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo dpkg --add-architecture i386</span><br><span class="line">sudo apt update</span><br><span class="line">sudo apt install wine64 wine32</span><br><span class="line">wine --version</span><br></pre></td></tr></table></figure>

<p>在官网下载绿色版的mobaxterm，解压进入解压后的文件夹，打开终端利用wine安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wine msiexec /i /installer.msi</span><br></pre></td></tr></table></figure>

<p>wine安装的软件需要到home目录下，显示隐藏文件，进入wine文件夹</p>
<p>[<img src="https://z1.ax1x.com/2023/10/28/pie1Dw4.png" alt="pie1Dw4.png"></p>
<p>进入device_c进入program Files(x86)就可以看到下载的windows软件了</p>
<p><a href="https://imgse.com/i/pie16YR"><img src="https://z1.ax1x.com/2023/10/28/pie16YR.png" alt="pie16YR.png"></a></p>
<p>想要打开这个软件需要进入该文件夹，找到exe文件，在终端打开输入</p>
<p>wine xxx.exe</p>
<p><a href="https://imgse.com/i/pie1W6K"><img src="https://z1.ax1x.com/2023/10/28/pie1W6K.png" alt="pie1W6K.png"></a></p>
<p>服务器开启SSH服务，客户机创建SSH会话。</p>
]]></content>
      <categories>
        <category>学编程</category>
      </categories>
      <tags>
        <tag>混技能</tag>
      </tags>
  </entry>
  <entry>
    <title>具有自适应微调策略的分层BERT，用于文档分类</title>
    <url>/%E5%85%B7%E6%9C%89%E8%87%AA%E9%80%82%E5%BA%94%E5%BE%AE%E8%B0%83%E7%AD%96%E7%95%A5%E7%9A%84%E5%88%86%E5%B1%82BERT%EF%BC%8C%E7%94%A8%E4%BA%8E%E6%96%87%E6%A1%A3%E5%88%86%E7%B1%BB.html</url>
    <content><![CDATA[<h1 id="具有自适应微调策略的分层BERT，用于文档分类"><a href="#具有自适应微调策略的分层BERT，用于文档分类" class="headerlink" title="具有自适应微调策略的分层BERT，用于文档分类"></a>具有自适应微调策略的分层BERT，用于文档分类</h1><p>中科院一区</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>预训练语言模型(PLMs)已经取得了令人印象深刻的成果，并已成为各种自然语言处理(NLP)任务的重要工具。然而，当文档长度超过PLM的最大可接受长度时，将这些PLM应用于文档分类存在一个限制，因为在这些模型中会截断多余的部分。如果关键字在截断的部分，则模型的性能下降。为了解决这个问题，本文提出了一种带有自适应微调策略的分层BERT (HAdaBERT)。它由基于bert的局部编码器模型和基于注意力的门控记忆网络作为全局编码器组成。与直接截断文档的现有plm相比，所提出的模型使用文档的一部分作为区域，将输入文档划分到几个容器中。这允许本地编码器提取每个容器中的有用信息，并由全局编码器根据其对分类的贡献进行组合。为了进一步提高模型的性能，本文提出了一种自适应微调策略，该策略动态地决定需要微调的BERT层，而不是对每个输入文本的所有层进行微调。在不同语料库上的实验结果表明，该方法在文档分类方面优于现有的神经网络。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>文件中的重要信息可能会在不同的地方分发。句子之间的语义关系更加复杂和模糊，使得文档分类成为一项具有挑战性的任务。cnn在计算机视觉方面取得了成功，也被用于文档分类。假设文档中的每个token对分类的贡献不相等，自动对齐文本和强调重要token的过程、自注意力、动态路由已经被提出进一步提高cnn、GRU和LSTM网络的性能。此外，还提出了分层关注网络[15]用于文档分类，在句子级和文档级执行语义建模，然而这可能会导致token在句子上下文中的句法依赖性。</p>
<p>最近，预训练语言模型： BERT、ALBERT [17] 、 RoBERTa [18]成功地完成了各种NLP任务。在处理下游任务时，这些plm消除了从头构建模型的需要，并且可以采用transformers，self-attention mechanisms利用迁移学习学习高质量的文本语境表征。通常，首先向plm提供大量未注释的数据，然后通过屏蔽语言模型或下一个句子预测进行训练，以学习各种单词的用法以及该语言的一般编写方式。然后，模型被转移到另一个任务，在那里它们被馈送到另一个较小的任务特定数据集。对于文档分类，输入序列可以很长，但BERT模型的最大输入长度在大多数情况下是有限的[20]。一旦文档超过预设的最大输入长度，这些文档的多余部分将被直接截断。最佳短语和强烈推荐短语中的强烈主观短语将被截断，这可能导致模型的错误分类。</p>
<p>将BERT应用于文档分类的另一个明显问题是计算消耗。也就是说，随着输入序列长度的增加，对计算资源的需求急剧增加，因为微调每个变压器层的时间复杂度相对于输入长度呈指数增长。</p>
<p>本文提出了带自适应微调策略的分层BERT模型 hierarchical BERT model with an adaptive fine-tuning strategy来解决上述问题。HAdaBERT模型由两个主要部分组成，以分层方式对文档表示进行建模，包括局部和全局编码器。考虑到文档具有自然的层次结构，即一个文档包含多个句子，每个句子包含多个单词，我们使用局部编码器学习句子级特征，而全局编码器将这些特征组合为最终表示。与现有的plm直接截断文档到最大输入长度相比，提议的HAdaBERT使用文档的一部分作为区域，而不是使用一个句子作为一个区域。我们引入了一个容器划分策略来获得有效的本地信息，从而保留语法依赖关系。这样，容器中的关键信息和会被提取到局部编码器。全局编码器使用基于注意力的门控记忆网络学习顺序组合容器之间的语法关系。通过在分层体系结构中使用这两种编码器，该模型可以有效地捕获长文档中的本地信息和长期依赖关系。此外，提出了一种针对每个输入样本的自适应微调策略，该策略网络可以自适应地选择最佳的BERT微调层，以提高模型在训练和推理过程中的性能。这种策略是一种自动的通用方法，可以扩展到其他预训练的语言模型。</p>
<p>在多个语料库上进行了实证实验，包括AAPD、Reuters、IMDB和Yelp-2013数据集。对比结果表明，所提出的HAdaBERT模型在文档分类方面优于现有的几种神经网络。此外，该模型可以有效地解决以往文档分类方法的局限性。它也与现有的学习短句表示的模型竞争。另一个观察结果是，自适应微调策略通过动态选择微调层来实现最佳性能改进。</p>
<p>本文的其余部分组织如下。第二节介绍和回顾了文献分类的相关工作。第3节描述了提出的分层BERT模型和自适应微调策略。对比实验在第4节中进行。最后，在第5部分得出结论</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p>文档级分类是自然语言处理中的一项基本任务，也是一项具有挑战性的任务。本节简要回顾现有的文档级分类方法，包括传统的、分层的和预训练的神经网络。</p>
<p>Conventional neural networks传统神经网络</p>
<p>通常用于文档分类任务的深度神经网络模型有cnn[23-25]和rnn[9,26]。这些模型将文档表示为具有语义和语法信息的分布式表示。</p>
<p>rnn中的梯度爆炸&#x2F;消失问题可能导致模型无法捕获长期依赖关系。为了解决这个问题，LSTM[29]和GRU[10]网络使用允许显式内存更新和传递的内存单元。这两种模型都学习上下文信息，这些信息有助于捕获长文本的语义。此外，Tai等[11]提出了一种根据依赖解析树合并语法信息的树- lstm网络。Zhou等人[30]提出了一种循环CNN (RCNN)模型，该模型扩展了现有的卷积层作为循环架构。Yang等人[4]提出了一种序列到序列模型，用于捕获多标签文档分类中多个标签之间的内在关系。此外，记忆网络[31-33]引入了一种类似于LSTM网络的存储单元的外部存储器，能够存储长文本的信息。</p>
<p>引入了注意机制[12]来选择重要信息，从而提高模型的性能。注意机制能够捕获文本的重要信息，从而更好地学习文本表示，并且可以很好地与各种神经编码器配合使用。考虑到这种方法，Zheng等[37]提出了一种基于自交互关注的文档分类机制。注意机制有两个局限性。首先，它无法感知位置信息，导致无法学习句子内的高级语言特征，如表达的转变或递进表达。此外，当上下文中其他不太重要的单词数量增加时，在很长的文档中强调关键字可能会有困难，因为通过注意机制分配的关键字的权重会被稀释，并且在模型训练期间难以利用。</p>
<p>Hierarchical neural networks层次神经网络</p>
<p>近年来，层次神经网络[15,38]被广泛用于文档分类。为了获取句子间的句法信息，Tang等[38]设计了一种分层架构，使用CNN和LSTM网络结合词嵌入学习文档表示，然后采用GRU网络对文档内的句法信息进行编码。Xu等人[39]提出了一种缓存LSTM模型，该模型应用了一组具有不同遗忘门的LSTM细胞。遗忘率高的门可以学习局部特征，遗忘率低的门可以捕捉全局特征。为了将自注意机制扩展为层次结构，Yang等人[15]提出了一个在句子和文档两个层次上都有注意机制的层次模型。Yin等[42]将任务作为理解问题，提出了一种分层交互的基于注意力的模型来构建文档表示。此外，对于产品评论，一些研究证明，将情感信息与额外的特征(如用户和产品消息)结合起来，对于最终的极性分类是有用的[43-45]。</p>
<p>Pretrained neural networks预训练神经网络</p>
<p>通过使用自关注机制，transformer[19]不能直接使用GRU和LSTM网络的顺序结构，但是允许模型并行训练。为了进一步改进transformer，Gong等[46]提出了多头注意力算法，并将分层结构引入自注意力机制。但是，转换器可能会忽略文本的本地依赖关系和时间关系。随着序列长度的增加，变压器的存储和计算复杂度迅速增加。</p>
<p>已经提出了几种用于文本分类的transformer预训练语言模型(plm)[16,47]。其基本思想是利用大量未标记的数据，通过无监督mask语言模型或下一句预测对语言模型进行预训练学习句法和语义信息，利用这种方法，Adhikari等[20]首先引入了BERT模型[16]，采用截断策略作为DocBERT进行文档分类，取得了良好的性能。Liu等[18]提出了RoBERTa，它使用快速微调的BERT训练程序，成功地使用分段预测进行文档分类，并显示出改进的结果,Lan等[17]提出了ALBERT模型，该模型引入了分解嵌入参数化和跨层参数共享两种参数约简技术，降低了内存消耗，提高了训练速度。</p>
<p>对于文档分类，现有的plm受到输入长度的限制。使用截断策略时，模型会丢失一部分用于分类的信息，当重要的内容落在被截断的部分时，会产生深远的影响，降低文档分类模型的性能。另一个问题是，基于bert的模型的预训练和微调都会产生相当大的计算资源成本。随着输入长度的增加，消耗的资源急剧增加，注意力权重被稀释。</p>
<p><img src="https://s1.ax1x.com/2023/07/29/pPSq6yV.png"></p>
<h2 id="Hierarchical-BERT-with-adaptive-fine-tuning"><a href="#Hierarchical-BERT-with-adaptive-fine-tuning" class="headerlink" title="Hierarchical BERT with adaptive fine-tuning"></a>Hierarchical BERT with adaptive fine-tuning</h2><p>具有自适应微调的分层BERT</p>
<p>它由两个主要部分组成，以分层方式对文档表示进行建模，<strong>包括本地和全局的编码器，输入文档首先被分成几个容器。在每个容器中，基于bert的模型被微调以提取高质量的局部特征。以连续的局部特征为输入，采用基于注意力的门控记忆网络作为全局编码器，学习容器间的长期依赖关系。</strong>提出的HAdaBERT模型可以有效地捕获局部和全局信息用于文档分类。</p>
<p>微调BERT应用在局部编码，adaptive fine-tuning自适应调整BERT。</p>
<p><img src="https://s1.ax1x.com/2023/07/29/pPSqdoQ.png"></p>
<h3 id="local-encoder"><a href="#local-encoder" class="headerlink" title="local encoder"></a>local encoder</h3><p>对于每个给定的文档，将文档划分为v个容器，表示为D&#x3D; [r1,r2, . . . ,rv]。每个容器又由一系列的token组成，<br>$$<br>r_{i} &#x3D; [x_{i1},x_{i2},…,x_{ic}]<br>$$<br>其中c是容器的容量。在直观的区域划分策略中，将文档中的每个单独的句子作为一个区域。例如，由三个句子组成的文档有三个区域。这个简单的策略是非常不平衡的，因为一个大的句子长度边距，很长和很短的句子都出现在文档中。另一种简单的方法是将文档划分为固定长度的区域。这种策略破坏了文档中的语法关系，可能导致性能下降。</p>
<p>容器策略：几个固定容量c的容器基于容器尽可能多的装句子的想法装载句子。我们依次将句子放入容器中，直到文本长度超过容量c。不够的用0值填充到c。值得注意的是，我们在每个相邻的容器之间建立了一个重叠句子。也就是说，前一个容器的最后一句话和下一个容器的第一句话是相同的。这可以有效地链接这两个容器，使它们不是相互独立的，并且保留了语法依赖性。</p>
<p>为了提取每个容器中的局部特征，我们使用了预训练的语言模型BERT[16]。它在各种NLP任务中取得了令人印象深刻的表现。BERT由多层双向transformer编码器组成[19]，通过无监督学习进行预训练，使用屏蔽语言模型(屏蔽率为15%)或下一句预测。特别地，我们使用了<a href="https://github.com/huggingface/transformers">uncase BERT-based1</a>模型，它包含12层transformers，隐藏大小为768。在每个容器中，首先在容器ri的开始和结束处分别添加两个特殊符号[CLS]和[SEP]。然后，我们将每个容器送入BERT模型以获得局部表示ti。<br>$$<br>t_{i}\in\mathbb{R}^{dt}<br>$$</p>
<p>$$<br>t_{i}&#x3D;f_{BERT}([x_{i1},x_{i2},…,x_{ic}]:\theta _{BERT})<br>$$</p>
<p>其中xi1, xi2，。， xic是第i个容器r中令牌的输入序列。θBERT是BERT模型的可训练参数，为所有容器共享，然后在模型训练时进行微调;dt&#x3D;768是局部表示的维数。</p>
<h3 id="Global-encoder"><a href="#Global-encoder" class="headerlink" title="Global encoder"></a>Global encoder</h3><p>为了将所有局部特征顺序编码为文档表示，使用了基于注意力的门控记忆网络来捕获跨容器的远程依赖关系并对全局信息建模。[t1, t2, . . . , tv] as input，首先使用双向LSTM (BiLSTM)网络将局部表示映射到隐藏状态，表示为<br>$$<br>\underset{h_{i}}{\rightarrow} &#x3D; LSTM(\underset{h_{i-1}}{\rightarrow},t_{i})<br>$$</p>
<p>$$<br>\underset{h_{i}}{\leftarrow} &#x3D; LSTM(\underset{h_{i+1}}{\leftarrow},t_{i})<br>$$</p>
<p>$$<br>h_{i}&#x3D;[\underset{h_{i}}{\rightarrow} ,\underset{h_{i}}{\leftarrow}]<br>$$</p>
<p>为了增强每个局部表示的信息，我们在BiLSTM的输入和输出之间添加残差连接，记为<br>$$<br>k_{i} &#x3D; h_{i}\oplus t_{i}<br>$$<br>ki表示局部特征，\oplus 表示相加。</p>
<p>attention-based gated memory network （AGM）层。考虑到并非所有单词和句子对最终分类的贡献都是相同的，我们使用AGM层依次选择重要信息并将其整合到记忆中，以获得远距离关系并保留上下文信息。为了自动选择重要信息，我们使用自注意机制来学习每个局部表示ki的权重，其计算为<br>$$<br>e_{i} &#x3D; tanh(W_{e}k_{i}+b_{i})<br>$$</p>
<p>$$<br>\alpha  &#x3D;\frac{exp(e_{i})}{\sum_{j&#x3D;1}^{|D|}exp(e_{j})}<br>$$</p>
<p>其中，We和be分别表示与注意层相关的权重和偏差，αi是分配给第i个局部表示的权重。AGM层具有循环架构，这有点类似于内存网络。它使用记忆向量m∈R dm来记录局部表示中的重要信息，并使用门g来控制训练过程中需要保留或忘记的相关信息。AGM层的计算如下:<br>$$<br>g_{i}&#x3D;\sigma (W_{i}k_{i}+U_{g}m_{i-1})<br>$$</p>
<p>$$<br>\hat{m}&#x3D;tanh(W_{h}k_{i}+g_{i}\odot U_{h}m_{i-1})<br>$$</p>
<p>$$<br>m_{i}&#x3D;(1-\alpha_{i}\odot m_{i-1}+\alpha_{i}\odot m_{i})<br>$$<br>权重αi用来控制保留多少过去的信息和吸收多少新的信息。</p>
<p>为了实现，我们应用了两个独立的AGM层对每一步序列的前向和后向信息进行建模。最后的记忆向量是AGM的两个方向的连接，它能够保存过去和未来的信息。我们将前向的最后一个记忆向量和后向的第一个记忆向量连接起来，生成用于最终分类的文档表示o。<br>$$<br>o&#x3D; [\underset{m_{v}}{\rightarrow},\underset{m_{1}}{\leftarrow}]<br>$$<br>给定训练数据集{Dn, yn}，分类是一个带有softmax函数的单层MLP。损失函数具有分类交叉熵</p>
<h3 id="Adaptive-fine-tuning-strategy"><a href="#Adaptive-fine-tuning-strategy" class="headerlink" title="Adaptive fine-tuning strategy"></a>Adaptive fine-tuning strategy</h3><p>自适应微调策略</p>
<p>对BERT中的所有层进行微调不一定会产生最佳性能。因此，我们使用policy network 选择BERT中需要在训练期间微调或冻结的层。等式1中BERT模型由L层transformer组成。<br>$$<br>f_{BERT}&#x3D;[T1,T2,…,TL]<br>$$<br>该policy network表示如下：<br>$$<br>policy(r)&#x3D;\left{s_{1},s_{2},…,s_{L}\right}, s_{i}\in \left{0,1 \right}<br>$$<br>如果si&#x3D;1则对第i层微调，si&#x3D;0则对第i层冻结。我们冻结了BERT中的原始的Ti，创建了一个新的可训练的层$$ \hat{Ti} $$。第i层的输出计算如下:<br>$$<br>d_{i} &#x3D;s_{i}\hat{T_{i}(d_{i-1})}+(1-s_{i}T_{i}(d_{i-1})),d_{i}表示第i个BERT层的输出<br>$$<br>policy network由三层transformer组成，容器r的embedding表示作为输入，s的计算如下：<br>$$<br>e_{i} &#x3D; Transformer(r),e_{i}只有两个元素<br>$$</p>
<p>$$<br>s_{i}&#x3D;argmax(e_{i})<br>$$</p>
<p>ei是logit分布，si是离散分布，离散数据导数不适用很难反向传播。于是用的Gumbel-Softmax 。</p>
<p>Gumbel-Softmax是一种从离散数据中采样的方法一种允许定义离散分布的可微的近似抽样的形式的分布。GumbelSoftmax将离散值转换为连续值，从而在端到端反向传播时实现梯度计算和策略网络优化。具体的Gumbel-Softmax实现如下:<br>$$<br>s_{i}&#x3D;softmax(\frac{log(e_{i}+G_{i})}{\iota })，\iota 越小s_{i}就越接近onehot向量<br>$$</p>
<p>$$<br>G_{i}&#x3D;-log(log(u_{i}))<br>$$</p>
<p>Gi是一个随机变量服从独立的均匀分布。ui服从均匀分布U(0,1)</p>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>数据集</p>
<p><img src="https://s1.ax1x.com/2023/07/29/pPSOKCd.png"></p>
<p>Dev是开发集也称为验证集，从训练集中分出一部分作为开发集，目的是用来选择模型，调整参数评估性能。</p>
<p>几个Baseline模型：</p>
<p><img src="https://s1.ax1x.com/2023/07/29/pPSORPJ.png"></p>
<p>局部编码中容器容量c的影响：</p>
<p><img src="https://s1.ax1x.com/2023/07/29/pPSOoqK.png"></p>
<p>等实验说明了该模型的优越性。</p>
<h2 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h2><p>未来的工作将探索更有效的局部编码器，并引入强化学习来研究更好的微调策略。</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态大模型</title>
    <url>/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B.html</url>
    <content><![CDATA[<h1 id="多模态大模型"><a href="#多模态大模型" class="headerlink" title="多模态大模型"></a>多模态大模型</h1><h2 id="CLIP-连接文本和图像的桥梁"><a href="#CLIP-连接文本和图像的桥梁" class="headerlink" title="CLIP: 连接文本和图像的桥梁"></a>CLIP: 连接文本和图像的桥梁</h2><p>CLIP的英文全称是<strong>Contrastive Language-Image Pre-training</strong>，即<strong>一种基于对比文本-图像对的预训练方法或者模型</strong>。CLIP是一种基于对比学习的多模态模型。CLIP的训练数据是文本-图像对：一张图像和它对应的文本描述，这里希望通过对比学习，模型能够学习到文本-图像对的匹配关系。有两个 encoder，一个对应图片，一个对应文本，图像和文本经过各自的 encoder 后，通过简单的点乘来代表不同模态的交互（相似性）。</p>
<p><a href="https://imgse.com/i/piGg0qH"><img src="https://z1.ax1x.com/2023/11/12/piGg0qH.png" alt="piGg0qH.png"></a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># image_encoder - ResNet or Vision Transformer</span></span><br><span class="line"><span class="comment"># text_encoder - CBOW or Text Transformer</span></span><br><span class="line"><span class="comment"># I[n, h, w, c] - minibatch of aligned images</span></span><br><span class="line"><span class="comment"># T[n, l] - minibatch of aligned texts</span></span><br><span class="line"><span class="comment"># W_i[d_i, d_e] - learned proj of image to embed</span></span><br><span class="line"><span class="comment"># W_t[d_t, d_e] - learned proj of text to embed</span></span><br><span class="line"><span class="comment"># t - learned temperature parameter</span></span><br><span class="line"><span class="comment"># extract feature representations of each modality</span></span><br><span class="line">I_f = image_encoder(I) <span class="comment">#[n, d_i]</span></span><br><span class="line">T_f = text_encoder(T) <span class="comment">#[n, d_t]</span></span><br><span class="line"><span class="comment"># joint multimodal embedding [n, d_e]</span></span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis=<span class="number">1</span>)</span><br><span class="line">T_e = l2_normalize(np.dot(T_f, W_t), axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># scaled pairwise cosine similarities [n, n]</span></span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)</span><br><span class="line"><span class="comment"># symmetric loss function</span></span><br><span class="line">labels = np.arange(n)</span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, axis=<span class="number">0</span>)</span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, axis=<span class="number">1</span>)</span><br><span class="line">loss = (loss_i + loss_t)/<span class="number">2</span></span><br></pre></td></tr></table></figure>



<h2 id="ALBEF：先对齐后融合"><a href="#ALBEF：先对齐后融合" class="headerlink" title="ALBEF：先对齐后融合"></a>ALBEF：先对齐后融合</h2><p>ALBEF 可以说是结合了单流模型与双流模型，其模型由图像编码器（image encoder）、文本编码器（text encoder）和 多模态编码器（multimodal encoder）组成，其中图像编码器采用的是VIT模型，而文本编码器、多模态编码器采用是一个12层的bert模型，其前6层作为文本编码器，后6层作为多模态编码器。图像编码器和文本编码器分别提到的特征可以用对比损失函数进行特征对齐，而后将图像特征和文本特征统一输入到多模态编码器，可以利用常用的MLM和ITM来进行预训练。在 ALBEF 之前，多模态方法通常使用 transformer 的多模态编码器来同时编码视觉和文本特征，由于目标检测器是提前训练好的，因此视觉和文本特征并不是对齐的。图像和文本特征可能距离很远，这使得多模态编码器难以学习到它们之间的交互。为了解决这个问题，ALBEF 通过一个对比损失（也<strong>就是 CLIP 中的 ITC 损失</strong>）在进行多模态交互之前对齐图像和文本数据。</p>
<p>ITC（Image-Text Contrastive）损失函数的核心思想是，模型应该学会将图像和对应的描述性文本映射到特征空间中的相近点，同时将不相匹配的图像和文本映射到远离的点。这通常通过一个对比损失函数来实现，最常用的是InfoNCE损失，它是由一个softmax函数定义的。</p>
<p>在CLIP模型中，一个batch中的每个图像都会和每个文本描述计算一个相似度分数。这些分数被组织成一个相似度矩阵。然后，对于每个图像，其与正确文本描述的相似度分数（即正样本）应该比与任何错误描述的分数（即负样本）都要高。</p>
<p>以下是计算过程：</p>
<p><a href="https://imgse.com/i/piGgDZd"><img src="https://z1.ax1x.com/2023/11/12/piGgDZd.md.png" alt="piGgDZd.md.png"></a></p>
<p><strong>ALBEF预训练任务</strong>分为图文对比（Image-Text Contrastive Learning）、.掩码建模（Masked Language Modeling）、.图文匹配（Image-Text Matching）三个任务。Masked Language Modeling 同时利用图像和上下文文本来预测mask词</p>
<p><a href="https://imgse.com/i/piGgrdA"><img src="https://z1.ax1x.com/2023/11/12/piGgrdA.png" alt="piGgrdA.png"></a></p>
<ul>
<li>下面红色框其实就<strong>类似于 CLIP</strong>，双塔各自编码图像和文本，然后取 CLS 进行对比学习；</li>
<li>上面蓝色框就是为了加强不同模态交互用的编码器（前面提到过 CLIP 内积的方式太简单了，这里就是<strong>加强多模态融合</strong>以适配更难的任务）；</li>
<li>图像编码器 12 层，文本编码器 6 层，多模态编码器 6 层；其实右侧是将一个 12 层的文本编码器拆成了两部分，这是因为一些研究工作发现<strong>在多模态中需要更强的图像编码器</strong>，进行这样的拆分一定程度上保证了强图像 encoder 和弱文本 encoder，且保证了模型参数不过多的情况下融合图像和文本的信息。</li>
</ul>
<p>ALBEF总的训练目标就是这三个损失：L_{ITC}+ L_{MLM}+L_{ITM}</p>
<p><strong>动量蒸馏</strong>的目的是通过在训练过程中引入一个额外的模型，即动量编码器，来增强模型学习到的特征对齐的稳定性和一致性。这个动量编码器是一个慢慢更新的模型版本，它提供了一个更加平滑和稳定的特征表示目标，帮助主模型更好地学习对齐特征。</p>
<p><strong>动量 (Momentum)</strong></p>
<p>在这个上下文中，“动量”通常指的是模型参数更新的一种方法，该方法在更新参数时结合了过去的参数。具体来说，在动量方法中，模型的参数更新不仅取决于当前梯度，还取决于之前梯度的累积。这种方法可以看作是物理中动量的概念的应用，有助于模型参数在优化过程中更平滑地移动，从而减少震荡并加速收敛。</p>
<p>在ALBEF的架构中，动量更新通常应用于动量模型（Momentum Model），该模型是主模型的一个影子副本。动量模型的参数是通过应用动量系数（�<em>β</em>）对主模型参数的指数加权移动平均得到的。这意味着动量模型的更新慢于主模型，因此可以提供更稳定的表示供主模型在训练过程中学习。</p>
<p>在提供的图中，动量更新部分对应于图中右侧的“momentum update”箭头，它指向动量模型（Momentum Model）。</p>
<p><strong>蒸馏 (Distillation)</strong></p>
<p>“蒸馏”在机器学习中通常指知识蒸馏（Knowledge Distillation），这是一种模型压缩技术，其中一个较大或较复杂的模型（称为教师模型）的知识被转移到一个较小或较简单的模型（称为学生模型）。在ALBEF模型的上下文中，蒸馏被用来将动量模型的平滑和稳定的表示传递给主模型，以提高训练的质量和稳定性。</p>
<p>在蒸馏过程中，主模型被训练以模仿动量模型的输出。这样做的原因是动量模型的输出更加平滑和一致，因此它可以作为一个好的目标，引导主模型在特征空间中正确对齐图像和文本。</p>
<p>ALBEF的使用：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载预训练的ALBEF模型</span></span><br><span class="line">model = load_pretrained_albef_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对图像进行预处理</span></span><br><span class="line">preprocessed_images = preprocess_images(raw_images)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对文本进行预处理</span></span><br><span class="line">preprocessed_texts = preprocess_texts(raw_texts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取图像和文本的特征表示</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    image_features = model.image_encoder(preprocessed_images)</span><br><span class="line">    text_features = model.text_encoder(preprocessed_texts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于需要融合特征的任务，可以进一步处理</span></span><br><span class="line">multimodal_features = model.multimodal_encoder(image_features, text_features)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用提取的特征进行下游任务</span></span><br><span class="line"><span class="keyword">for</span> task_data <span class="keyword">in</span> downstream_task_dataset:</span><br><span class="line">    features = extract_features(task_data, model)  <span class="comment"># 根据任务提取相应的特征</span></span><br><span class="line">    predictions = downstream_model(features)  <span class="comment"># 可能需要一个额外的下游模型</span></span><br><span class="line">    <span class="comment"># 进行任务相关的处理，例如计算损失，进行反向传播等</span></span><br></pre></td></tr></table></figure>

<h2 id="BLIP：统一理解和生成的自举多模态模型"><a href="#BLIP：统一理解和生成的自举多模态模型" class="headerlink" title="BLIP：统一理解和生成的自举多模态模型"></a>BLIP：统一理解和生成的自举多模态模型</h2><p><a href="https://imgse.com/i/piGgsII"><img src="https://z1.ax1x.com/2023/11/12/piGgsII.png" alt="piGgsII.png"></a></p>
<p>虽然有三个模型，但是大部分参数都是共享的。</p>
<ul>
<li>左一为 Image Encoder（图像编码器）：该组件使用 Vision Transformer（ViT）对图像进行编码，将全局图像特征表示为一个额外的[CLS]标记。</li>
<li>左二为 Text Encoder，采用了 BERT 的结构，提取文本特征用于与视觉特征计算 ITC loss。Text Encoder 不与视觉特征计算交叉注意力。</li>
<li>左三为 Image-grounded Text Encoder（基于图像的文本编码器），该组件通过在每个 Transformer 块的自注意力（Self-Attention）层和前馈神经网络（Feed Forward Network）之间插入一个交叉注意力（Cross-Attention）层，将视觉信息注入到文本编码中，提取文本特征用于计算 ITM 损失。</li>
<li>左四为 Imagegrounded Text Decoder（基于图像的文本解码器），用于进行 LM 语言建模训练（<strong>这里不再是用 MLM 了</strong>），生成与图像相关的文本描述。</li>
<li>三个文本编解码器分别为在文本前添加 [CLS]、[Encode]、[Decode] token</li>
<li>与 ALBEF 一样，同样采用动量模型为 ITC 生成伪标签；使用 ITC 为 ITM 进行难负例挖掘。</li>
</ul>
<p>BLIP 的训练流程</p>
<p><a href="https://imgse.com/i/piGggRf"><img src="https://z1.ax1x.com/2023/11/12/piGggRf.md.png" alt="piGggRf.md.png"></a></p>
<p><strong>字幕器 Captioner：</strong>给一张网络图片，生成字幕。它是一个视觉文本解码器，在 COCO 数据集上使用 LM 目标函数微调。给定网络图片  ，Captioner 生成字幕 。</p>
<p><strong>过滤器 Filter：</strong>过滤掉噪声图文对。它是一个视觉文本编码器，看文本是否与图像匹配，在 COCO 数据集上使用 ITC 和 ITM 目标函数微调。Filter 删除原始 Web 文本 和合成文本 中的嘈杂文本，如果 ITM 头将其预测为与图像不匹配，则认为文本有噪声。</p>
<p>最后，将过滤后的图像-文本对与人工注释对相结合，形成一个新的数据集，作者用它来预训练一个新的模型。以此来过滤掉噪声信息。</p>
<h2 id="CoCa（Contrastive-Captioners）视觉-语言联合表示"><a href="#CoCa（Contrastive-Captioners）视觉-语言联合表示" class="headerlink" title="CoCa（Contrastive Captioners）视觉-语言联合表示"></a>CoCa（Contrastive Captioners）视觉-语言联合表示</h2><ol>
<li><strong>模型架构</strong>： CoCa模型通常包括一个图像编码器和一个文本编码器，这两个编码器可以是基于Transformer的架构，如Vision Transformer (ViT) 用于图像编码，BERT或GPT用于文本编码。</li>
<li><strong>多模态学习</strong>： 在预训练阶段，CoCa模型使用大量的图像-文本配对数据来学习这两种模态之间的相互关系。通过对比学习和自回归语言建模相结合的方式，模型被训练来理解图像内容和相应的文本描述。</li>
<li><strong>对比学习</strong>： CoCa模型使用对比学习来确保图像和相应的文本在特征空间中被拉近，而不匹配的图像和文本被推远。这通常涉及到计算正负样本对之间的相似性，并通过对比损失函数来优化。</li>
<li><strong>自回归语言建模</strong>： 为了更好地理解和生成文本，CoCa模型还包括一个自回归语言模型组件，它预测文本序列中的下一个词，以学习文本的内部结构。</li>
</ol>
<p><a href="https://imgse.com/i/piGg2z8"><img src="https://z1.ax1x.com/2023/11/12/piGg2z8.md.png" alt="piGg2z8.md.png"></a></p>
<p>使用coca获取多模态表示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> CoCaModel, CoCaTokenizer</span><br><span class="line"></span><br><span class="line">model = CoCaModel.from_pretrained(<span class="string">&#x27;coca-base&#x27;</span>)</span><br><span class="line">tokenizer = CoCaTokenizer.from_pretrained(<span class="string">&#x27;coca-base&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设你有一个图像处理函数和文本处理函数</span></span><br><span class="line">processed_images = image_preprocessing(your_images)</span><br><span class="line">processed_texts = tokenizer(your_texts, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取多模态表示</span></span><br><span class="line">outputs = model(input_ids=processed_texts[<span class="string">&#x27;input_ids&#x27;</span>], pixel_values=processed_images)</span><br><span class="line">multimodal_representation = outputs.pooler_output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用多模态表示进行下游任务</span></span><br><span class="line">downstream_model = SomeDownstreamTaskModel()</span><br><span class="line">predictions = downstream_model(multimodal_representation)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 微调模型</span></span><br><span class="line">outputs = model(input_ids=processed_texts[<span class="string">&#x27;input_ids&#x27;</span>], pixel_values=processed_images, labels=your_labels)</span><br><span class="line">loss = outputs.loss</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>它是使用<strong>对比损失</strong>和<strong>文本生成损失</strong>进行训练，也就是使用了 ITC 和 LM loss；这里没有使用 ITM loss，<strong>减少了模型参数每次迭代所需前向传播的次数</strong>，从而降低了训练时间。</p>
]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>多模态相关综述</title>
    <url>/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E7%BB%BC%E8%BF%B0.html</url>
    <content><![CDATA[<h1 id="多模态相关综述"><a href="#多模态相关综述" class="headerlink" title="多模态相关综述"></a>多模态相关综述</h1><p>多模态信息处理技术打破计算机视觉、语音与声学、自然语言处理等学科间的壁垒，是典型的多学科交叉技术。</p>
<p>多模态核心技术又分为：多模态表示，多模态融合（Ｆｕｓｉｏｎ）、多模态转换（Ｔｒａｎｓｌａｔｉｏｎ）、多 模 态 对 齐 （Ａｌｉｇｎｍｅｎｔ）和 模 态 协 同 学 习（Ｃｏ-ｌｅａｒｎｉｎｇ）类。</p>
<p>从自然语言处理的角度出发，2022年—2020年左右，在国际自然语言领域的顶刊顶会上，关度较高的几个多模态应用如下：</p>
<p><img src="https://picdm.sunbangyan.cn/2023/08/31/f4esvi.png"></p>
<p>视觉语言生成是给定一个图像生成一段语言描述，或者给定一段话生成一幅图，也包括视频描述任务等</p>
<p>视觉问答典型的例子是在商品检索中如图:</p>
<p><img src="https://picdm.sunbangyan.cn/2023/08/31/f54eso.png"></p>
<p>多模态摘要又分为视频会议摘要、教学视频摘要、多模态商品摘要、多模态新闻摘要。</p>
<p>多模态对齐研究多个模态不同颗粒度元素间的对齐关系。比如，在大规模图像－词汇对齐的多模态语料库上训练的预训练语言模型可增强其对自然语言的理解能力。</p>
<p><img src="https://picdm.sunbangyan.cn/2023/08/31/f5kvya.png"></p>
<p>等应用这里不再多讲，感兴趣可以去知网查看[1]吴友政,李浩然,姚霆等.多模态信息处理前沿综述：应用、融合和预训练[J].中文信息学报,2022,36(05):1-20.以上内容均来源于此。</p>
<h2 id="用transformer多模态学习的综述"><a href="#用transformer多模态学习的综述" class="headerlink" title="用transformer多模态学习的综述"></a>用transformer多模态学习的综述</h2><p>人工智能（AI）的最初灵感是模仿人类的感知，例如看到、听到、触摸、嗅闻等。通常，一个模式通常与特定的传感器相关联，并创建独特的通信通道，例如视觉和语言 [1]本质上，多模态AI系统需要摄取、解释和理解多模态信息源才能实现与人类水平相当的感知能力。多模态学习（MML）是一种构建可以从多模态数据中提取和关联信息的AI模型的通用方法 [1]。</p>
<p>本调查重点关注使用Transformer进行多模态学习（如图1所示），并受到其固有优势和可扩展性（例如，语言，视觉，听觉）建模不同模态（例如，语言翻译，图像识别，语音识别）和任务（例如，语言翻译，图像识别，语音识别）的启发。</p>
<p><img src="https://picst.sunbangyan.cn/2023/08/31/f633zf.png"></p>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>MML[1]，[60]，[61]是近几十年来重要的研究领域;早期的多模态应用——视听语音识别在20世纪80年代进行了研究[62]。MML是人类社会的关键。我们人类生活的世界是一个多模态环境，因此我们的观察和行为都是多模态的[63]。例如，AI导航机器人需要多模态传感器来感知现实环境[64]，[65]，[66]，如摄像头，LiDAR，雷达，超声波，GNSS, HD Map，里程表。此外，人类的行为、情绪、事件、动作和幽默都是多模态的，因此各种以人为中心的MML任务被广泛研究，包括多模态情绪识别[67]、多模态事件表示[68]、理解多模态幽默[69]、基于脸-身体-声音的视频人聚类[70]等。</p>
<p>感谢互联网的发展和近年来智能设备的大规模应用，越来越多的多模态数据正在通过互联网传输，因此出现了越来越多的多模态应用场景。在现代生活中，我们可以看到许多多模态应用，包括商业服务（例如电子商务&#x2F;商品检索[71]，视觉和语言导航(VLN) [72]，[73]，[74]，[75]，[76]）、通信（例如唇读[77]，手语翻译[28]，[29]）、人类-计算机交互[78]、医疗AI[79]、监控AI[81]等。</p>
<p>此外，在深度学习的时代，深度神经网络极大地促进了多模态学习（MML）的发展，Transformer架构是一个具有竞争力的架构家族，为MML带来了新的挑战和机遇。特别是，最近大型语言模型的成功和它们的跨模态衍生模型（例如[82]，[83]，[84]，[85]，[86]）进一步证明了Transformer在多模态基础模型中的潜力。</p>
<p><strong>里程碑</strong></p>
<p>受到Transformer的成功启发，VideoBERT [7]是一项突破性的工作，是第一个将Transformer扩展到多模态任务的研究。VideoBERT证明了Transformer在多模态背景下的巨大潜力。在VideoBERT之后，许多基于Transformer的多模态预训练模型（例如ViLBERT [102]，LXMERT [103]，VisualBERT [104]，VL-BERT [105]，UNITER [106]，CBT [107]，Unicoder-VL [108]，B2T2 [109]，VLP [110]，12-in-1 [111]，Oscar [112]，Pixel-BERT [113]，ActBERT [114]，ImageBERT [115]，HERO [116]，UniVL [117]）已经成为机器学习领域的研究热点。</p>
<p>在2021年，<strong>CLIP [9]被提出。它是一个新的里程碑</strong>，通过将多模态预训练应用于分类，将其转化为一个检索任务，使得预训练模型能够解决zero shot识别。因此，CLIP是一个成功的实践，充分利用了大型多模态预训练，实现了zero shot学习。最近，CLIP的概念 further研究，例如基于CLIP的zero shot语义分割 [118]，CLIP-TD [119]，ALBEF [121]和CoCa [122]。</p>
<p>数据集</p>
<p>多模态数据集的新趋势;</p>
<p>（1）数据规模更大。各种最近发布的 datasets 包括 Product1M、Conceptual12M、RUC-CAS-WenLan（30M）、HowToVQA69M、HowTo100M、ALT200M 和 LAION-400M 等，数据规模都在百万级别。</p>
<p>（2）视觉、文本和音频等多模态数据集正在不断涌现，包括更多的多样模态，例如：Pano-AVQA：第一个大型空间和音频视觉问题回答数据集，适用于360度视频，YouTube-360（YT-360）[145]（360度视频），AIST++[146]（一个新的多模态数据集，包括3D舞蹈动作和音乐），Artemis [147]（用于视觉艺术的情感语言），MultiBench [148]（包括10种模态的数据集）。</p>
<p>（3）更多场景。除了常见的字幕和问答数据集外，还研究了更多应用场景，例如：CIRR [149]（现实图片），Product1M [137]（产品1M），Bed and Breakfast（BnB）[150]（视觉-语言导航），M3A [151]（金融数据），X-World [152]（自动驾驶）。</p>
<p>（4）任务更具挑战性。除了简单的任务之外，还提出了更多抽象的多模态任务，例如：MultiMET（一种多模态数据集，用于隐喻理解），Hateful Memes（带有仇恨言论的多模态数据集）。</p>
<p>（5）指令式视频变得越来越流行，例如：烹饪视频 YouCookII [155]。将指令与某人执行任务的视频对齐是一个强大的预训练前缀任务[7]，[156]。预训练任务是在解决它们的基础上设计的，以迫使模型学习表示。</p>
<p>类似于其他深度神经网络架构，Transformer 也具有数据需求大的特点。因此，其高容量模型和多模态大数据基础共同推动了基于多模态的机器学习的发展。例如，大数据使 VLP Transformer 模型具有零散学习能力。</p>
<h3 id="multimodal-transformer"><a href="#multimodal-transformer" class="headerlink" title="multimodal transformer"></a>multimodal transformer</h3><p>tansformer的基础架构不再多讲，直接看多模态。</p>
<p>给定一个任意模态的输入，用户只需要执行两个主要步骤：1）对输入进行标记，2）选择一个表示标记的嵌入空间，然后将数据输入到Transformer中。在实践中，标记输入和选择嵌入空间对于Transformer来说至关重要，但具有很多灵活性。例如，对于图像，标记和嵌入的解决方案不是唯一的。用户可以在多个粒度级别上进行标记和嵌入选择——粗粒度（coarse-grained）和细粒度（fine-grained）。</p>
<p>这里标记是tokenizing，”Tokenizing input”是将输入文本分割成单个的标记或词语的过程。这可以通过使用空格、标点符号或其他规则来实现。例如，将句子”Hello, how are you?”分割成标记[“Hello”, “,”, “how”, “are”, “you”, “?”]。”Embedding”是将这些标记转换为向量表示的过程。向量表示可以捕捉到标记之间的语义和关系。常见的方法是使用预训练的词嵌入模型，如Word2Vec、GloVe或BERT，将每个标记映射到一个固定长度的向量。</p>
<p>在多模态Transformer中,跨模态交互(例如融合、对齐等)本质上是由自注意力和其变体处理的。因此,在本节中,我们将从自注意力的设计角度回顾Transformer的主要多模态建模实践,包括(1)早期的求和(词级别,加权),(2)早期的连接(跨模态连接),(3)层次注意力(多流到一流),(4)层次注意力(一流到多流),(5)跨模态注意力(跨模态关注),和(6)跨模态注意力的连接。请参阅表2和图2</p>
<p><img src="https://picst.sunbangyan.cn/2023/08/31/f6aj0r.png"></p>
<p>上述所有多模态交互的自关注变体都是模态通用的，可以应用于灵活的策略和多粒度任务。具体来说，这些交互可以灵活地组合和嵌套。例如，在两流解耦模型[191]中，多个交叉注意流用于分层注意(一流到多流)，Eq. 11中的tf2和tf3通过Eq. 12中定义的交叉注意实现。此外，它们可以扩展到多个(≥3)模式。TriBERT[183]是视觉、姿势和音频的三模态交叉注意(共注意)，其中给定查询嵌入，其键和值嵌入是来自其他模态的连接。在[189]中，交叉注意串联被应用于三种模式(即语言、视频和音频)。</p>
<h3 id="Transformers-for-Multimodal-Pretraining"><a href="#Transformers-for-Multimodal-Pretraining" class="headerlink" title="Transformers for Multimodal Pretraining"></a>Transformers for Multimodal Pretraining</h3><p>Transformer也被广泛用于多模态预训练。最近的研究表明，如果在基于大规模多模态语料库Transformer的模型上进行预训练[7]，[102]，[103]，[104]，[105]，[106]，[110]，在大范围的多模态下游任务中明显优于其他竞争对手，并且实现了零样本泛化能力。这些优势使得基于transformer的多模态预训练成为一个热门话题，主要有两个方向，即<strong>针对不可知性下游任务的一般性预训练</strong>(章节4.1.1)和<strong>针对特定下游任务的目标导向预训练</strong>(章节4.1.2)。</p>
<p>我们关注这些关键点:(1)正在出现哪些趋势?(2)在预训练过程中，跨模态交互在哪里&#x2F;如何发生?(3)如何梳理和理解预训练托词目标?他们如何使用transformer学习跨模态交互?</p>
<p>在基于Transformer的多模态预训练中，预训练任务&#x2F;目标通常也被称为预训练任务&#x2F;目标。到目前为止，已经研究了许多预训练任务，例如：</p>
<ol>
<li><p>遮蔽语言建模（MLM）[137]</p>
</li>
<li><p>遮蔽图像区域预测&#x2F;分类（也称为遮蔽对象分类，MOC）[137]，[190]</p>
</li>
<li><p>遮蔽区域回归（MRR）[115]</p>
</li>
<li><p>视觉-语言匹配（VLM）(例如，图像-文本匹配(ITM) [188]，图像文本匹配(ITM)，短语区域对齐(PRA) [204]，词区域对齐(WRA) [106]，视频字幕匹配(VSM) [116]</p>
</li>
<li><p>遮蔽帧建模（MFM）[116]，帧序建模（FOM）[116]，下一句预测（NSP）[4]，[102]，[190]，遮蔽句子生成(MSG) [191]，遮蔽组建模(MGM) [188]，前缀语言建模(PrefixLM) [199]，视频有条件遮蔽语言模型(也称为视频受控遮蔽语言模型)[117]，有条件文本遮蔽图像模型(也称为有条件图像遮蔽语言模型)[117]，视觉翻译语言建模(VTLM) [206]，以及图像有条件遮蔽语言建模(也称为图像关注遮蔽语言建模)[207]。这些下游任务无关的预训练预处理可以是可选的，而下游任务目标可以直接训练，这在第4.1.2节中将会讨论。表3提供了基于Transformer的多模态预训练中常见的预训练任务。</p>
</li>
</ol>
<p>在多模态变压器的实践中，上述与下游任务无关的预训练是可选的，不是必须的，针对下游任务的预训练也被广泛研究[150]，[190]，[208]，[211]。主要原因包括:(1)<strong>受现有技术的限制，很难设计出一套高度通用的网络架构</strong>、借口任务和语料库，<strong>适用于所有不同的下游应用</strong>。(2)各种下游应用之间存在不可忽略的差距，如任务逻辑、数据形式等，使得<strong>从预训练到下游应用的转移变得困难</strong>，因此，大量的下游任务仍然需要量身定制的预训练来提高性能。</p>
<h3 id="挑战与设计"><a href="#挑战与设计" class="headerlink" title="挑战与设计"></a>挑战与设计</h3><h4 id="融合"><a href="#融合" class="headerlink" title="融合"></a>融合</h4><p>一般来说，MML transformer主要在三个级别融合跨多种模式的信息:输入、中间表示、预测。</p>
<p>我们注意到简单的基于预测的后期融合[247]，[248]在多模态 transformer中较少采用。考虑到学习更强的多模态上下文表示的动机和计算能力的巨大进步，这是有道理的。为了增强和解释MML的融合，探索模式之间的相互作用和测量融合[249]将是一个有趣的探索方向。</p>
<p><strong>对齐</strong></p>
<p><strong>可转移性</strong></p>
<p>可迁移性是Transformer基于多模态学习的一个主要挑战,涉及如何将模型在不同的数据集和应用中进行转移。数据增强和对抗扰动策略有助于提高多模态Transformer的泛化能力。VILLA是一种两阶段策略(任务无关对抗预训练,然后针对任务的对抗微调),可以提高VLP Transformer。</p>
<p>在实践中,训练数据和实际数据的分布差异是显着的。例如,监督数据样本(良好标注、对齐)在实际应用中成本很高。因此,如何将预训练的多模态Transformer迁移到弱对齐的测试平台上是一个具有挑战性的问题[137]。CLIP是一种鼓舞人心的解决方案,通过学习共享的多模态嵌入空间,将知识从一个模态迁移到另一个模态,实现零散转移。CLIP的主要灵感是,预训练的多模态(图像和文本)知识可以通过使用提示模板“一张{标签的照片}”来将在训练和测试数据之间传递分布差距。</p>
<p>过拟合是一个向量转移的主要障碍。多模态Transformer在训练过程中可能会过度拟合数据集,由于其建模能力很大。一些最近的实践探索了如何将或acle模型在无噪声数据集上训练的数据迁移到真实数据集。例如,Kervadec等人[272,273]研究了VQA中的可迁移推理模式,并表明对于LXMERT[103]&#x2F;BERT-like推理模式,可以从理想数据集中部分转移到真实数据集中。</p>
<p>跨任务差距是另一个向量转移的主要障碍。根据[208],[274],由于不同的推理和输入-输出工作流程,例如如何将多模态数据集用于语言预训练模型的微调,是一个具有挑战性的问题。在实际应用中,有时需要处理未映射的单模态数据,这通常是由于缺失模态而导致的。一种解决方案是使用知识蒸馏,例如,在Transformer中从多模态到单模态注意力[275],从多个单模态Transformer教师到共享Transformer编码器[276]。在多模态任务和生成任务之间存在巨大的差距。正如[208]中所讨论的,基于BERT的编码器- only多模态Transformer(例如,VideoBERT [7], CBT [107])需要分别对生成任务训练解码器。这可能导致预训练-微调差异不利于泛化。最近,越来越多的研究探讨了这个问题,例如,GilBERT是一种用于有监督任务的生成VLP模型。</p>
<p>跨语言差距也应该考虑,以确保Transformer基于多模态学习的可转移性,例如,英语到非英语多模态上下文下的通用跨语言通用学习[206],[277]。</p>
<h4 id="效率"><a href="#效率" class="headerlink" title="效率"></a>效率</h4><p>多模态Transformer有两个主要效率问题: (1) 由于具有较大的模型参数容量,它们对数据量有很高的需求,因此依赖于大规模训练数据集。 (2) 由于自注意力机制,它们的计算复杂度随输入序列长度的增长而呈指数级增长,这会导致在多模态环境中计算爆炸。这些问题是相互依存的,应该一起考虑。</p>
<p>为提高多模态Transformer的训练和推理效率,近年来提出了各种解决方案,以使用更少的训练数据和&#x2F;或参数。主要想法可以总结为以下几点:</p>
<p>(1) 知识蒸馏。将训练的大型Transformer模型中的知识蒸馏到较小的Transformer模型中[93]。Miech等人[278]从慢模型(基于早期连接的Transformer)到快模型(基于独立 dual branch 的Transformer)进行了蒸馏。</p>
<p>(2) 简化和压缩模型。去除组件以简化模型管道。以VLP Transformer模型为例,使用对象检测模型进行简化会花费很多代价,因此可以使用视觉输入的无约束方式,例如,E2E-VLP[271]和ViLT[192]。DropToken通过随机丢弃输入序列的一部分视频和音频token来降低训练复杂度。DropToken可以被视为一种实现dropout或对抗训练的方法。权重共享也是常见的多模态Transformer模型简化的方法之一。Wen等人[279]提出了一种基于视觉和文本编码器的权重共享Transformer,以对齐文本和图像。Lee等人[280]提出了一种新的参数共享方案,基于低秩近似。</p>
<p>(3) 不对称网络结构。为不同的模块分配不同的模型容量和计算复杂度,以节省参数。参考文献[192]中的图2。</p>
<p>(4) 提高训练样本的利用率。Liu等人[281]通过充分利用较少的样本数据来训练简化LXMERT模型。Li等人[282]使用更少的数据来训练CLIP模型,通过充分利用模型的潜在自监督信号,来自模型的距离较近的相似对之间使用最近邻监督。</p>
<p>(5) 压缩和剪枝模型。搜索多模态Transformer模型的最优子结构&#x2F;网络,例如,使用VLP Transformer模型进行彩票抽奖[283]、Lottery Tickets策略。</p>
<p>(6) 优化自注意力。Transformer模型在输入序列长度上需要大量的时间和内存,一个可能的解决方案是优化O(N2)的复杂度,例如,Child等人[286]提出的稀疏注意力矩阵的稀疏分解。Transformer LS[287]是既高效又高效的Transformer模型,具有线性计算和内存复杂度。</p>
<p>(7) 优化基于多模态交互&#x2F;融合的自注意力。Nagrani等人[175]提出了Fusion via Attention Bottlenecks(FSN)来提高多模态交互&#x2F;融合的性能。FSN通过少数 bottleneck latent 传递消息,因此模型需要对每个模态进行最必要的信息提取。这种策略利用了 bottleneck 作为桥梁,不仅提高了融合性能,而且降低了计算成本。</p>
<p>(8) 优化其他策略。使用最优策略执行常见的Transformer基于多模态交互。考虑到自注意力的平方复杂度,使用基于早期连接的多模态交互来同步融合多个模态的输入是昂贵的。Yan等人[288]提出了一种有效的解决方案,即在序列长度升序顺序中,逐个将两个相邻视图的信息融合起来。这是一种贪心策略。</p>
<h4 id="多样性"><a href="#多样性" class="headerlink" title="多样性"></a>多样性</h4><p>由于多模态学习任务的多样性和模态数量,通用性对于多模态Transformer模型来说是一个重要的问题。在实践中,<strong>大量的最新尝试都试图尽可能地统一各种模态和任务,以便处理各种任务和数据</strong>。理想情况下,统一的多模态<strong>Transformer模型应该可以兼容各种数据</strong>(例如,对齐和未对齐的,单模态和多模态的)<strong>和任务</strong>(例如,监督和无监督,单模态和多模态,有监督和无监督,推理和生成)。同时,这<strong>些模型应该具有能够在 小样本或甚至零样本情况下进行一般化的能力</strong>。因此,<strong>目前为了解决通用性问题,采取的临时解决方案只是初步的探索</strong>。</p>
<p>目前,统一模型的尝试主要包括以下两种:</p>
<p>(1)统一输入&#x2F;任务的管道。正如第5.3节所述,在实际场景中,由于缺失模态,多模态Transformer模型需要处理单模态数据。将多模态知识蒸馏到适应单模态数据和任务的模型中是一种成功的方法[275],[276]。</p>
<p>(2)统一理解和生成管道。通常情况下,理解和生成任务都需要Transformer编码器,而生成&#x2F;生成任务还需要Transformer解码器。现有尝试使用多任务学习来将理解和生成任务合并进行训练,其中两种类型的工作流程共同训练。从模型结构上看,这通常包括:</p>
<p>(a)编码器+解码器,例如E2E-VLP。</p>
<p>(b)分离的编码器+跨编码器+解码器,例如UniVL和CBT。</p>
<p>(c)单解码器&#x2F;联合编码器,例如VLP。</p>
<p>(d)双流解码器设计,例如两个流解码器。</p>
<p>虽然上述尝试提供了一些初步的探索,但也存在一些明显的问题和限制,至少包括:</p>
<p>(1)由于模态和任务之间的差距,通用模型应该考虑泛化能力和成本之间的平衡。统一模型通常会导致更大的或更复杂的模型配置,而针对特定模态或任务,一些组件可能是冗余的。</p>
<p>(2)多任务损失函数会增加训练的复杂度。如何正确地共同训练多个目标以及有效地优化它们是一个具有挑战性的问题,因为不同的目标通常应该在不同的策略上进行优化。</p>
<h3 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h3><p>设计一个通用的MML模型,在所有单模态和多模态下游任务中同时具有不同的特征是一个非常大的挑战，Transformer模型(如[9]、[199]、[263]等)在特定MML任务上表现优异,但它们仅被设计为针对特定任务的模型(如[137]、[142]、[212]、[249]、[260]、[261]、[265]、[266]等)。令人鼓舞的是,一些最近的研究关注于在模态无关网络设计方面实现通用模态学习( modality-agnostic network design )[3]和更通用架构设计[307]、[308]、[309],并期望这会引发更多的研究调查。因此,我们不应对模型的设计空间进行深入探索,而是寻求对MML模型的行为进行深入理解和解释,即使不同模态之间的交互和协同效应本质上是复杂和可能不一致的[249]。</p>
<p>对于更细粒度的MML,发现跨模态的潜在语义对齐对于模型的成功至关重要。一种直观的策略是利用预提取的语义部分(如物体)来支持MML[103]、[104]、[105]、[106]、[112]、[204]、[310]。然而,这不仅复杂且容易出错,而且计算代价昂贵[207]。最近,提出了一些解决方法,包括随机采样[113]、学习概念词典[203]、联合学习区域检测器[271]和掩码预测前的表示对齐[263]。考虑到MML训练数据的规模,探索这一方向需要极大的计算成本,而且据富有的研究团队来说,更加划算。理想的方法是让MML在模态之间自动产生细粒度的语义对齐,这值得未来仔细研究。</p>
<p>随着学习规模的指数扩展,训练数据变得不可避免地嘈杂和异质化[9]、[199]、[263]。最近,已经证明解决噪声问题非常重要[263]、[309]。另一个相关的问题是训练策略,例如,训练阶段数量是否优于常见的单阶段策略[115]。此外,由于多模态数据的输入更长,Transformer的平方复杂度变得更为尖锐。尽管对高效变体进行了大量研究[49],但为MML进行专门性的效率研究仍然是不足的,并需要更多的调查。</p>
<p>以下是Transformers在多模态机器学习方面的优势的概述:</p>
<p>(1) Transformers可以编码隐含知识[32]。</p>
<p>(2) <strong>多头带来了多个建模子空间</strong>,可以进一步增强模型的表现能力。理想情况下,训练后多个头都是好的,并且不同。<strong>这是集成学习的良好实践</strong>。</p>
<p>(3) <strong>Transformers固有的全局聚合特性感知非局部模式</strong>。</p>
<p>(4) 由于大型模型的能力,Transformer模型通过在大型语料库上进行有效的预训练来处理具有挑战性的领域缺口,例如语言和视觉[294]。</p>
<p>(5) Transformers可以表示输入作为一个图,与更多的模态兼容,例如表格和SQL。</p>
<p>(6) 对于建模序列和序列模式(如时间序列),Transformer模型在训练和&#x2F;或推理中的效率比基于RNN的模型更好,得益于它们在训练和&#x2F;或推理中的并行计算。Transformers天生对平移变换不变,因此是点云学习的理想工具[164]。</p>
<p>(7) 分词使得Transformers灵活地组织多模态输入,正如第3.1.1节中所述。</p>
<p>论文选自Multimodal Learning with Transformers:A Survey</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>安装CLIP库及数据集下载网站</title>
    <url>/%E5%AE%89%E8%A3%85CLIP.html</url>
    <content><![CDATA[<h1 id="安装CLIP及数据集下载网站"><a href="#安装CLIP及数据集下载网站" class="headerlink" title="安装CLIP及数据集下载网站"></a>安装CLIP及数据集下载网站</h1><p>安装pip install clip失败</p>
<p>用pip install openai-clip</p>
<h2 id="数据集下载网站"><a href="#数据集下载网站" class="headerlink" title="数据集下载网站"></a>数据集下载网站</h2><p>Google Dataset Search：<a href="https://datasetsearch.research.google.com/">https://datasetsearch.research.google.com/</a></p>
<p>kaggle: <a href="https://www.kaggle.com/datasets">https://www.kaggle.com/datasets</a></p>
<p>数据堂：<a href="https://www.datatang.com/data">https://www.datatang.com/data</a></p>
<p>竞赛数据集：<a href="https://www.datafountain.cn/">https://www.datafountain.cn/</a></p>
<p>数据之家：<a href="http://www.escience.cn/people/data/index.html">http://www.escience.cn/people/data/index.html</a></p>
<p>数据集市场：<a href="https://www.datamarket.com/">https://www.datamarket.com/</a></p>
<p>数据集搜索引擎：<a href="https://www.data.gov/">https://www.data.gov/</a></p>
<p>数据集大全：<a href="https://www.dataquest.io/blog/free-datasets-for-projects/">https://www.dataquest.io/blog/free-datasets-for-projects/</a></p>
<p>数据集网：<a href="https://www.dataset.net.cn/">https://www.dataset.net.cn/</a></p>
<p>openlab:<a href="https://opendatalab.com/">https://opendatalab.com/</a></p>
]]></content>
      <categories>
        <category>学编程</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>安装pytorch环境(GPU版本)</title>
    <url>/%E5%AE%89%E8%A3%85pytorch%E7%8E%AF%E5%A2%83-GPU%E7%89%88%E6%9C%AC.html</url>
    <content><![CDATA[<h1 id="安装pytorch环境-GPU版本"><a href="#安装pytorch环境-GPU版本" class="headerlink" title="安装pytorch环境(GPU版本)"></a>安装pytorch环境(GPU版本)</h1><p>离线安装比较简单</p>
<p>根据代码的需求进行配置环境。一般来说python&#x3D;3.7版本的就已经可以了。</p>
<p><strong>第一步：查看电脑对应显卡cuda版本</strong></p>
<p>win+r打开运行，输入cmd打开命令行，输入nvidia-smi，查看cuda版本。</p>
<p><a href="https://imgse.com/i/piECF9x"><img src="https://z1.ax1x.com/2023/10/24/piECF9x.png" alt="piECF9x.png"></a></p>
<p>说明我可以下载cuda12.0以下版本，cuda向下兼容。</p>
<p>CUDA版本与PyTorch版本之间的兼容性通常不是一一对应的，而是根据PyTorch的发布周期和支持策略来确定的。一般来说，PyTorch的不同版本会添加对不同CUDA版本的支持，但并不是每个PyTorch版本都与每个CUDA版本完全兼容。一般情况下，较新的CUDA版本通常可以兼容较旧的PyTorch版本。</p>
<p>例如，如果你安装了最新版本的CUDA，并且你选择一个较旧的PyTorch版本，通常情况下是可以正常工作的，因为较新的CUDA通常包含对较旧CUDA API的支持。然而，要注意的是，较旧的PyTorch版本可能不会利用较新CUDA版本的新特性和性能优化。</p>
<p>但是，反过来并不总是成立。较新的PyTorch版本可能会依赖于新的CUDA特性或API，因此可能不兼容较旧的CUDA版本。</p>
<p>总之，PyTorch和CUDA之间的兼容性通常是向后兼容的。</p>
<table>
<thead>
<tr>
<th align="left"><strong>CUDA版本</strong></th>
<th align="left"><strong>PyTorch版本</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left">11.3</td>
<td align="left">1.7.1</td>
</tr>
<tr>
<td align="left">11.4</td>
<td align="left">1.8.0</td>
</tr>
<tr>
<td align="left">11.4</td>
<td align="left">1.9.0</td>
</tr>
<tr>
<td align="left">11.4</td>
<td align="left">1.9.1</td>
</tr>
<tr>
<td align="left">11.4</td>
<td align="left">1.10.0</td>
</tr>
</tbody></table>
<p><strong>第二步：在下面网站中找到对应的torch和torchvision，下载whl文件</strong></p>
<p>下载网站：<a href="https://download.pytorch.org/whl/torch_stable.html">https://download.pytorch.org/whl/torch_stable.html</a></p>
<p>在这里可以查看torch,torchversion的对应关系<a href="https://gitcode.net/mirrors/pytorch/vision?utm_source=csdn_github_accelerator">mirrors &#x2F; pytorch &#x2F; vision · GitCode</a></p>
<p>或者在这里：<a href="https://pytorch.org/get-started/previous-versions/">以前的 PyTorch 版本 |PyTorch</a></p>
<p><a href="https://imgse.com/i/piEC3gf"><img src="https://z1.ax1x.com/2023/10/24/piEC3gf.png" alt="piEC3gf.png"></a></p>
<p>这里出来的最新的版本对应关系是cuda11.8的，我们12.0的也完全够用。</p>
<p>由上图，我们来下载torch&#x3D;2.0的，torchvision&#x3D;0.15.0，torchaudio&#x3D;&#x3D;2.0.0，我选择了python&#x3D;3.9的，因为怕3.10以上的出问题。</p>
<p><a href="https://imgse.com/i/piEClCt"><img src="https://z1.ax1x.com/2023/10/24/piEClCt.png" alt="piEClCt.png"></a></p>
<p>cu113表示cuda版本是11.3<br>cp37 表示python版本3.7<br>win-amd64 表示windows64位</p>
<p>下载完安装包后进行第三步</p>
<p><strong>第三步：打开anaconda prompt执行以下命令</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda create -n torch2python39 python=<span class="number">3.9</span></span><br></pre></td></tr></table></figure>

<p><code>torch2python39</code>是自己命名的环境。</p>
<p><a href="https://imgse.com/i/piECZuD"><img src="https://z1.ax1x.com/2023/10/24/piECZuD.png" alt="piECZuD.png"></a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conda activate torch2python39</span><br><span class="line">cd D:\Anaconda\安装包     <span class="comment">#安装包文件夹</span></span><br><span class="line">pip install torchvision-<span class="number">0.15</span><span class="number">.0</span>+cu118-cp39-cp39-win_amd64.whl  <span class="comment">#先安装了torchvision</span></span><br><span class="line">pip install torchaudio-<span class="number">2.0</span><span class="number">.0</span>+cu118-cp39-cp39-win_amd64.whl</span><br><span class="line">pip install torchaudio-<span class="number">2.0</span><span class="number">.0</span>+cu118-cp39-cp39-win_amd64.whl</span><br></pre></td></tr></table></figure>

<p>最后激活python环境，输入<code>import torch</code>，<code>print(torch.cuda.is_available())</code>得到True说明torch环境安装成功。</p>
<p><a href="https://imgse.com/i/piECM4I"><img src="https://z1.ax1x.com/2023/10/24/piECM4I.png" alt="piECM4I.png"></a></p>
]]></content>
      <categories>
        <category>学编程</category>
      </categories>
      <tags>
        <tag>混技能</tag>
      </tags>
  </entry>
  <entry>
    <title>文本分类综述论文阅读笔记</title>
    <url>/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E7%BB%BC%E8%BF%B0%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0.html</url>
    <content><![CDATA[<h1 id="A-Survey-on-Text-Classification-From-Traditional-to-Deep-Learning论文阅读笔记"><a href="#A-Survey-on-Text-Classification-From-Traditional-to-Deep-Learning论文阅读笔记" class="headerlink" title="A Survey on Text Classification: From Traditional to Deep Learning论文阅读笔记"></a>A Survey on Text Classification: From Traditional to Deep Learning论文阅读笔记</h1><p>论文地址：</p>
<p>[<a href="https://dl.acm.org/doi/pdf/10.1145/3495162]">https://dl.acm.org/doi/pdf/10.1145/3495162]</a>: </p>
<p>中科院三区</p>
<p><img src="https://s3.bmp.ovh/imgs/2023/07/23/87d039e4216656ce.png" alt="image-20230723102300673"></p>
<p>文本分类过程流程图。第一个重要步骤是为模型预处理文本数据。</p>
<h2 id="传统方法中的文本表示（特征提取）"><a href="#传统方法中的文本表示（特征提取）" class="headerlink" title="传统方法中的文本表示（特征提取）"></a>传统方法中的文本表示（特征提取）</h2><p><strong>BOW</strong>意味着语料库中的所有单词都形成一个映射数组。根据映射数组，句子可以表示为一个向量。向量中的第i个元素表示句子映射数组中第i个单词的频率。向量是句子的BOW。BOW的核心是用字典大小的向量表示每个文本。向量的单个值表示与其在文本中的固有位置相对应的词频。</p>
<p><strong>N-gram</strong>考虑相邻单词的信息，并通过考虑相邻单词来构建字典。它用于计算句子的概率模型。句子的概率表示为句子中每个单词的联合概率。给定第(N−1)个单词的序列，可以通过预测第N个单词的概率来计算句子的概率。为了简化计算，N-gram模型采用马尔可夫假设。一个单词只与它前面的单词有关。因此，N-gram模型执行大小为n的滑动窗口。通过计数和记录所有片段的出现频率，可以使用记录中相关片段的频率计算句子的概率。</p>
<p><strong>TF-IDF</strong>使用词频和逆文档频率对文本进行建模。TF是一个词在特定文章中的词频，IDF是包含该词的文章占语料库中文章总数的比例的倒数。TF-IDF是两者的乘积。TF-IDF评估一个词对一组文件或语料库中的一个文档的重要性。一个词的重要性随着它在文档中出现的次数成比例地增加。然而，它在整个语料库中的频率呈反比下降。</p>
<p><strong>word2vec</strong>利用本地上下文信息获取词向量，词向量是指一个固定长度的实值向量，指定为语料库中任何词的词向量。word2vec使用两个基本模型:CBOW和Skip-gram。前者是在已知当前单词的上下文的前提下预测当前单词。后者是在已知当前单词时预测上下文。</p>
<p><strong>GloVe</strong>同时具有局部上下文和全局统计特征，对词-词共现矩阵中的非零元素进行训练，它使词向量能够包含尽可能多的语义和语法信息。词向量的构建方法是:首先基于语料库构建词的共现矩阵，然后基于共现矩阵和GloVe模型学习词向量。最后，根据选择的特征将表示的文本输入到分类器中。</p>
<h2 id="传统分类器"><a href="#传统分类器" class="headerlink" title="传统分类器"></a>传统分类器</h2><p><strong>PGM-based方法</strong>。概率图模型(Probabilistic Graphical Models, PGMs)表达图中特征之间的条件依赖关系，如贝叶斯网络[25]。它是概率论和图论的结合。Naïve贝叶斯(NB)：以先验计算后验。朴素贝叶斯公式</p>
<p><strong>KNN-based</strong>。KNN (k近邻)算法[9]的核心是通过在k个最近的样本上找到样本最多的类别来对未标记的样本进行分类。它是一个简单的分类器，不需要建立模型，并且可以通过快速获得k个最近邻来降低复杂性。</p>
<p>**支持向量机(SVM)**。</p>
<p><strong>决策树(DT)</strong>[49]是一种有监督的树结构学习方法，反映了分而治之的思想，并且是递归构建的。该算法学习析取表达式，对含有噪声的文本具有鲁棒性。</p>
<p><strong>Integration-based Methods集成的方法</strong>。传统的集成算法有自举聚合(bootstrap aggregation)，如RF[14]，增强(boosting)，如Adaptive boosting (AdaBoost)[56]和XGBoost[15]，以及叠加。</p>
<h2 id="深度学习模型"><a href="#深度学习模型" class="headerlink" title="深度学习模型"></a>深度学习模型</h2><p>一些任务：情感分析(SA)、话题标注(TL)、新闻分类(NC)、问答(QA)、对话行为分类(DAC)、自然语言推理(NLI)和关系分类(RC)</p>
<p>递归神经网络<strong>ReNN</strong></p>
<p><strong>MLP</strong>多层感知机</p>
<p>循环神经网络<strong>RNN</strong></p>
<p>自然语言推理(<strong>NLI</strong>)。[181]通过测量每对句子之间的语义相似性来预测一个文本的意义是否可以从另一个文本中推断出来。</p>
<p><strong>CNN-based</strong>方法。对于文本分类，需要将文本表示为类似于图像表示的向量，并且可以从多个角度过滤文本特征，如图7所示。首先，将输入文本的词向量拼接成一个矩阵。然后将矩阵送入卷积层，该层包含多个不同维数的滤波器。最后，卷积层的结果经过池化层，并将池化结果连接起来，得到文本的最终向量表示。类别由最终向量预测。为了尝试使用CNN进行文本分类任务，Kim引入了一种无偏卷积神经网络模型，称为<strong>TextCNN</strong>[17]</p>
<p>Attention-based Methods。层次注意网络(Hierarchical Attention Network, <strong>HAN</strong>)，通过利用文本中极具信息量的成分来获得更好的可视化效果，如图8所示。HAN包括两个编码器和两个注意层。注意机制让模型对特定的输入给予不同的注意。它首先将关键词聚合成句子向量，然后将重要句子向量聚合成文本向量。基于关注的模型可以了解每个单词和句子对分类判断的贡献程度，通过两个关注层次，有利于应用和分析。<strong>HAPN</strong>[124]用于少镜头文本分类。</p>
<p><strong>Self-attention</strong>通过在句子中构造K、Q和V矩阵来捕获句子中单词的权重分布，这些矩阵可以捕获对文本分类的长期依赖关系。所有的输出向量都可以并行计算。Lin等[114]在句子表示任务中使用源标记自注意来探索每个标记对整个句子的权重。为了捕获远程依赖关系，双向块自关注网络(<strong>Bi-BloSAN</strong>)[120]对按顺序分割的每个块使用一个块内自关注网络(SAN)，并对输出使用一个块间SAN。</p>
<p>预训练的语言模型[198]可以有效地学习全局语义表示，并显著提高NLP任务，包括文本分类。它通常采用无监督的方法自动挖掘语义知识，然后构建预训练目标，使机器能够学习理解语义。<strong>OpenAI GPT</strong> [199], and <strong>BERT</strong> [19]. <strong>ELMo</strong> [118]，<strong>RoBERTa</strong>[140]，<strong>XLNet</strong>[138]</p>
<p><strong>图神经网络GNN</strong>-based Methods，文本T &#x3D; [T1,T2,T3,T4]和文本中的单词X &#x3D; [x1, x2, x3, x4, x5, x6]，定义为节点，构建成图结构。图节点由粗体黑色边连接，黑色边表示文档-单词边和单词-单词边。每个词-词边的权重通常表示它们在语料库中的共现频率。然后，通过隐藏层表示单词和文本。最后，通过图来预测所有输入文本的标签。<strong>DGCNN</strong>[153]是一种将文本转换为词图的graph-CNN，具有使用CNN模型学习不同层次语义的优势。<strong>TextGCN</strong>为整个数据集构建异构词文本图，并捕获全局词共现信息。<strong>图注意网络(Graph ATtention network, GAT)</strong>[212]通过关注其邻居而采用掩膜自注意层。因此，提出了一些基于gat的模型来计算每个节点的隐藏表示。异构图注意网络(Heterogeneous Graph ATtention networks, <strong>HGAT</strong>)[213]采用双级注意机制，学习当前节点中不同相邻节点和节点类型的重要性。该模型在图上传播信息并捕获关系，以解决半监督短文本分类的语义稀疏性问题。</p>
<p>其他网络：孪生神经网络(twin NN)，虚拟对抗训练(VAT)，强化学习(RL)。</p>
<p>总结：</p>
<p>RNN按顺序计算，不能并行计算。RNN的缺点使其在模型趋于更深入、参数更多的当前趋势下难以成为主流。</p>
<p>CNN通过卷积核从文本向量中提取特征。卷积核捕获的特征的数量与其大小有关，从理论上讲，CNN的深度足以捕捉远距离的特征。由于深层网络参数优化方法的不足，以及池化层造成的位置信息的丢失，深层网络并没有带来明显的改善。与RNN相比，CNN具有并行计算能力，改进后的CNN可以有效地保留位置信息。但是，它对远距离的特征捕获能力较弱。</p>
<p>GNN为文本构建图形。当设计出有效的图结构时，学习到的表示可以更好地捕获结构信息。</p>
<p>Transformer将输入文本视为一个完全连接的图，在边缘上具有注意评分权重。该算法具有并行计算能力，能够高效地通过自注意提取不同单词之间的特征，解决短时记忆问题。然而，Transformer中的注意力机制计算量很大，特别是在处理长序列时。最近提出了一些用于Transformer计算复杂度的改进模型[146,225]。总的来说，Transformer是文本分类的更好选择。</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>这里只取新闻分类的数据集。20<br>Newsgroups (20NG) [34], AG News (AG) [93, 234], R8 [235], R52 [235], Sogou News (Sogou)<br>[136], and so on.</p>
<p>20NG是一个新闻组文本数据集。它有20个类别，每个类别的数量相同，包括18,846个文本。</p>
<p>AG News是一个搜索学术界新闻的搜索引擎，选择了四个最大的课程。它使用每个新闻的标题和描述字段。AG包含120,000个培训文本和7,600个测试文本。</p>
<p>R8和R52是两个子集，它们是Reuters的子集[252]。R8有8个类别，分为2189个测试文件和5485个培训课程。R52有52个类别，分为6532个培训文件和2568个测试文件。</p>
<p>搜狗结合了两个数据集，包括搜狗新闻集和搜狗新闻集。每个文本的标签是URL中的域名。</p>
<p>在评价文本分类模型方面，准确率和F1分数是评价文本分类方法最常用的指标。</p>
<p>在新闻分类任务中<strong>BLSTM-2DCNN</strong>[77]的精确度最高。将双向LSTM (BiLSTM)与二维最大池化相结合。它使用二维卷积来采样矩阵中更有意义的信息，并通过BiLSTM更好地理解上下文。此外，Xue等[189]提出了结合BiLSTM和CNN层的MTNA来解决方面类别分类和方面术语提取任务。</p>
<h2 id="未来研究挑战"><a href="#未来研究挑战" class="headerlink" title="未来研究挑战"></a>未来研究挑战</h2><p>对于文本分类任务，无论是传统方法还是深度学习方法，数据都是模型性能的关键。本文研究的文本数据主要包括多章节、短文本、跨语言、多标签、少样本文本等。针对这些数据的特点，目前存在的技术挑战如下:</p>
<p>外部知识。众所周知，深度神经网络中输入的有益信息越多，其性能就越好。例如，一个包含常识性知识的问答系统可以回答关于现实世界的问题，并帮助解决信息不完整的问题。因此，增加外部知识(知识库或知识图)[293,294]是提高模型性能的有效途径。现有知识包括概念信息[100,127,204]、常识知识[223]、知识库信息[295,296]、通用知识图[170]等，增强了文本的语义表示。然而，由于输入规模的限制，对于不同的任务，如何以及添加什么仍然是一个挑战。</p>
<p>现有的模型大多是监督模型，过度依赖于大量的标记数据。当样本量过小或出现零样本时，模型的性能将受到显著影响。新的数据集注释需要花费大量的时间。因此，无监督学习和半监督学习具有很大的潜力。此外，特定领域的文本[297,298]，如金融和医学文本，包含许多特定单词或领域专家可理解的俚语，缩写等，这使得现有的预训练单词向量难以处理。</p>
<p>文本表示。在文本预处理阶段，基于向量空间模型的文本表示方法简单有效。但是，该方法会丢失文本的语义信息，因此限制了基于该方法的应用性能。本文提出的基于语义的文本表示方法耗时太长。因此，高效的基于语义的文本表示方法还需要进一步研究。在基于深度学习的文本分类的文本表示中，词嵌入是主要概念，不同语言对表示单元的描述不同。然后，通过模型学习映射规则，将单词表示为向量的形式。因此，如何设计自适应的数据表示方法更有利于深度学习与具体分类任务的结合。</p>
<p><strong>模型集成</strong>。大多数传统和深度学习模型的结构都被用于文本分类，包括集成方法。RNN需要逐步递归得到全局信息。CNN可以获取局部信息，通过多层叠加可以增加传感场，捕获更全面的上下文信息。注意机制学习句子中单词之间的整体依赖关系。转换器模型依赖于注意机制来建立输入和输出之间的全局依赖关系的深度。因此，设计一个集成模型是值得尝试利用这些模型的。</p>
<p>模型的效率。基于深度学习的文本分类模型非常有效，如cnn、rnn、gnn等。但是，存在许多技术上的限制，如网络层深度、正则化问题、网络学习率等。因此，优化算法，提高模型训练速度还有更广阔的发展空间。</p>
]]></content>
      <categories>
        <category>阅读笔记</category>
      </categories>
      <tags>
        <tag>学习记录</tag>
      </tags>
  </entry>
  <entry>
    <title>科研工具</title>
    <url>/%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90.html</url>
    <content><![CDATA[<h1 id="科研工具"><a href="#科研工具" class="headerlink" title="科研工具"></a>科研工具</h1><p>大文件快速传输工具：<a href="https://cowtransfer.com/login">奶牛快传</a></p>
<p>论文代码寻找：<a href="https://paperswithcode.com/">Papers with code</a></p>
<p>论文写作：<a href="https://www.overleaf.com/">网页版latex</a></p>
<p>公式代码转换：<a href="https://www.mathcha.io/editor">matcha</a>可以转换为latex代码</p>
<p>期刊会议查询：<a href="https://ccf.atom.im/">https://ccf.atom.im/</a></p>
<p>公益学术平台：<a href="https://pubscholar.cn/">https://pubscholar.cn/</a></p>
]]></content>
      <categories>
        <category>学编程</category>
      </categories>
      <tags>
        <tag>混技能</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 教程导航</title>
    <url>/guide-how-to-build-site-0.html</url>
    <content><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>互联网时代，大家都想在浩瀚的网络世界留下点印记。</p>
<p>虽然有微信朋友圈，QQ空间，微博等可以记录点点滴滴，但他们要么是没法扩大圈子，要么是加以各种限制，到头来这些数据产权还都属于马家，更不用谈某天实现增值获取收益，寄人篱下终究不如自己做主：建个自己掌控的网站！</p>
<p>本教程旨在试图引导小白从零开始，免费或者低成本建个自己的小站。</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/hugo-hexo.png"></p>
<h2 id="教程目录"><a href="#教程目录" class="headerlink" title="教程目录"></a>教程目录</h2><ol>
<li><a href="/guide-how-to-build-site-1.html" title="从零开始建个小站 - 前置知识">从零开始建个小站 - 前置知识</a></li>
<li><a href="/guide-how-to-build-site-2.html" title="从零开始建个小站 - 建站方案选择">从零开始建个小站 - 建站方案选择</a></li>
<li><a href="/guide-how-to-build-site-3.html" title="从零开始建个小站 - 本地Git配置">从零开始建个小站 - 本地Git配置</a></li>
<li><a href="/guide-how-to-build-site-4.html" title="从零开始建个小站 - GitHub设置">从零开始建个小站 - GitHub设置</a></li>
<li><a href="/guide-how-to-build-site-5.html" title="从零开始建个小站 - 配置SSH密钥">从零开始建个小站 - 配置SSH密钥</a></li>
<li><a href="/guide-how-to-build-site-6.html" title="从零开始建个小站 - 实操：准备存储仓库">从零开始建个小站 - 实操：准备存储仓库</a></li>
<li><a href="/guide-how-to-build-site-7.html" title="从零开始建个小站 - 实操：打通发布流程">从零开始建个小站 - 实操：打通发布流程</a></li>
<li><a href="/guide-how-to-build-site-8.html" title="从零开始建个小站 - 实操：代码拉到本地">从零开始建个小站 - 实操：代码拉到本地</a></li>
<li><a href="/guide-how-to-build-site-9.html" title="从零开始建个小站 - 实操：本地测试预览">从零开始建个小站 - 实操：本地测试预览</a></li>
<li><a href="/guide-how-to-build-site-10.html" title="从零开始建个小站 - 实操：个性设置">从零开始建个小站 - 实操：个性设置</a></li>
<li><a href="/guide-how-to-build-site-11.html" title="从零开始建个小站 - 实操：内容增&#x2F;删&#x2F;改">从零开始建个小站 - 实操：内容增&#x2F;删&#x2F;改</a></li>
<li><a href="/guide-how-to-build-site-12.html" title="从零开始建个小站 - 其他问题">从零开始建个小站 - 其他问题</a></li>
</ol>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 前置知识</title>
    <url>/guide-how-to-build-site-1.html</url>
    <content><![CDATA[<h2 id="建站须知"><a href="#建站须知" class="headerlink" title="建站须知"></a>建站须知</h2><ol>
<li>虽然说是零基础建站，但一些互联网及计算机基本知识技能还是不能少的，如怎么安装软件，怎么敲命令，怎么解析域名……</li>
<li>建站就需要文件托管服务，如上传到GitHub仓库，自己买的云服务器，虚拟主机等</li>
<li>网站对外需要有IP或者域名（一般都不会直接IP对外服务），所以要么用GitHub提供免费的二级域名，要么自行购买域名并解析到文件托管服务器</li>
<li>建站时会涉及各种配置设置，而且各程序，各主题都不尽相同，都需要根据实际对象依照文档进行配置，所以需要具备阅读文档的能力</li>
</ol>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><table>
<thead>
<tr>
<th>名词</th>
<th>解释说明</th>
</tr>
</thead>
<tbody><tr>
<td>git</td>
<td>大名鼎鼎的分布式版本管理工具，每个版本改了什么一目了然</td>
</tr>
<tr>
<td>GitHub</td>
<td>版本管理托管商，全球最大的男性交友社区</td>
</tr>
<tr>
<td>action</td>
<td>GitHub提供的在线执行环境，类似于一个虚拟机</td>
</tr>
<tr>
<td>pages</td>
<td>GitHub提供的网页托管访问服务，每用户一个免费二级域名</td>
</tr>
<tr>
<td>npm</td>
<td>依赖包管理工具，各种套娃</td>
</tr>
<tr>
<td>MarkDown</td>
<td>轻量标记语言，写文档必备技能</td>
</tr>
<tr>
<td>服务器&#x2F;云主机</td>
<td>存放文件24小时在线提供网络访问服务的计算机</td>
</tr>
<tr>
<td>域名</td>
<td>互联网上便于人类识别记忆的访问地址</td>
</tr>
<tr>
<td>ICP备案</td>
<td>大陆境内服务器需要，有问题方便FBI请喝茶或上门送温暖</td>
</tr>
<tr>
<td>主题&#x2F;模板</td>
<td>套用后实展现相应的界面外观及功能</td>
</tr>
</tbody></table>
<h2 id="网站程序选型"><a href="#网站程序选型" class="headerlink" title="网站程序选型"></a>网站程序选型</h2><p>网站程序选型主要依据环境依赖程度和维护难度，以及网络上免费资源可持续性考虑，对大多数普通用户，建议：</p>
<ul>
<li>首选 <code>hugo/hexo</code>：HTML静态页渲染框架，速度快，可免费托管到GitHub仓库，MarkDown文档维护，主题多可满足大部分需求。<strong>大部分用户建议选择 hugo 程序</strong>，无需安装麻烦的依赖，而且有将近400套各式主题可选。</li>
<li>其次 <code>WordPress</code>：需自备服务器，没有免费资源可用，但有后台界面，网络上用户多，插件多，文档教程多</li>
</ul>
<p>市面上网站程序比较多，罗列了几个比较主流的框架，更多可以自行通过搜索引擎查找对应文档。</p>
<table>
<thead>
<tr>
<th>程序框架</th>
<th>环境依赖</th>
<th>维护难度</th>
<th>推荐度</th>
<th>常见用途</th>
</tr>
</thead>
<tbody><tr>
<td>hugo</td>
<td>&#x2F;</td>
<td>★</td>
<td>★★★★★</td>
<td>个人网站，企业官网，在线文档，求职简历</td>
</tr>
<tr>
<td>hexo</td>
<td>nodejs</td>
<td>★★</td>
<td>★★★★☆</td>
<td>个人网站，企业官网，在线文档，求职简历</td>
</tr>
<tr>
<td>gitbook</td>
<td>nodejs</td>
<td>★★★</td>
<td>★★</td>
<td>在线文档</td>
</tr>
<tr>
<td>vuepress</td>
<td>nodejs</td>
<td>★★</td>
<td>★★★</td>
<td>个人网站，在线文档</td>
</tr>
<tr>
<td>docsy</td>
<td>nodejs</td>
<td>★★★</td>
<td>★★★</td>
<td>在线文档</td>
</tr>
<tr>
<td>WordPress</td>
<td>MySQL，PHP</td>
<td>★★</td>
<td>★★★★</td>
<td>个人网站，企业官网</td>
</tr>
<tr>
<td>Typecho</td>
<td>MySQL，PHP</td>
<td>★★☆</td>
<td>★★★☆</td>
<td>个人网站，企业官网</td>
</tr>
<tr>
<td>Zblog</td>
<td>MySQL&#x2F;SQLite，PHP</td>
<td>★★</td>
<td>★★★</td>
<td>个人网站，企业官网</td>
</tr>
</tbody></table>
<blockquote>
<p>PS：维护难度和推荐度都是主观意见，推荐度高主要是基于部署简单，可选主题多，互联网免费资源多，对最终实现的功能需求未做考虑，大部分情况根据自己实际需求考量。</p>
</blockquote>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 实操：个性设置</title>
    <url>/guide-how-to-build-site-10.html</url>
    <content><![CDATA[<p>项目仓库克隆下来，网站的各项设置都是默认的，一些标题，作者之类的需要根据自己的实际情况进行修改，个性设置主要是网站根目录的框架配置和主题配置。好在 <code>hugo</code> 和 <code>hexo</code> 配置结构大同小异，而且都支持将配置文件放在网站根目录下，只需要修改配置，今后主题更新只需要同步配置其他也互不影响。</p>
<blockquote>
<p><strong>每套用一个主题，渲染出来的网站界面和功能都有所不同，所以除了基础配置，各个主题设计的配置项都可能不一样，所以一定要依照主题模板文档去配置！！！</strong></p>
</blockquote>
<blockquote>
<p><strong>一定要依照主题模板文档去配置！！！</strong></p>
</blockquote>
<blockquote>
<p><strong>一定要依照主题模板文档去配置！！！</strong></p>
</blockquote>
<h2 id="Hugo"><a href="#Hugo" class="headerlink" title="Hugo"></a>Hugo</h2><p>Hugo只有一个配置文件，默认的配置功能非常少，只包含网站标题，主页地址和语言，其他功能都依赖主题模板实现。</p>
<p>主题到 <a href="https://themes.gohugo.io/" title="Hugo官方主题展示页">官网主题页</a> 去选自己喜欢的，然后依照主题文档去操作，这就是前面要强调三遍的<strong>依照主题文档去配置！</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/hugo-themes.png" alt="Hugo官网主题页"></p>
<p><strong>以 <code>Ananke</code> 主题为例：</strong></p>
<ol>
<li><p>在 <a href="https://themes.gohugo.io/" title="Hugo官方主题展示页">官网主题页</a> 点击 <code>Ananke</code> 主题预览图或标题后，会被导航到主题说明页：<a href="https://themes.gohugo.io/themes/gohugo-theme-ananke/">https://themes.gohugo.io/themes/gohugo-theme-ananke/</a></p>
</li>
<li><p>该页面有主题预览及功能说明等，当然也包括该主题怎么安装，怎么配置，以下也就是搬运主题文档演示一遍</p>
</li>
<li><p>按文档说明安装该主题:</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke</span><br><span class="line"># 作为子模块安装到themes/ananke，后期项目仓库部署时会从主题仓库更新</span><br></pre></td></tr></table></figure></li>
<li><p>配置 <code>config.toml</code>，以下仅是演示，详细规则可参阅 <a href="https://gohugo.io/getting-started/configuration/" title="Hugo官方配置说明">Hugo官方配置说明</a></p>
<p> 在主题目录下有个 <code>exampleSite</code> 文件夹，相当于就是一个完整的站点演示了，直接把该目录下的 <code>config.toml</code> 复制替换到项目仓库根目录下，或者复制里面的内容移到已有的 <code>config.toml</code> 里也是一样的，最后配置出来是这样的：</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">title = &quot;网站标题&quot;</span><br><span class="line">baseURL = &quot;https://yiwangmeng.cn&quot;</span><br><span class="line">uglyurls = true # true or false, &#x27;Pretty URLs&#x27; VS &#x27;Ugly URLs&#x27;: https://gohugo.io/content-management/urls/#pretty-urls</span><br><span class="line">languageCode = &quot;zh-cn&quot; # &quot;en-us&quot; default</span><br><span class="line">theme = &quot;ananke&quot;  # 指定主题</span><br><span class="line">resourceDir = &quot;../resources&quot;</span><br><span class="line"></span><br><span class="line">DefaultContentLanguage = &quot;zh&quot; # 默认展示语言，和[languages]配置对应</span><br><span class="line">SectionPagesMenu = &quot;main&quot;</span><br><span class="line">Paginate = 9 # this is set low for demonstrating with dummy content. Set to a higher number</span><br><span class="line">googleAnalytics = &quot;</span><br><span class="line">enableRobotsTXT = true</span><br><span class="line"></span><br><span class="line">[languages]</span><br><span class="line">  [languages.zh]</span><br><span class="line">    title = &quot;Ananke&quot;</span><br><span class="line">    weight = 1</span><br><span class="line">    contentDir = &quot;content/zh&quot; # 该语言内容存贮目录</span><br><span class="line">    # languageDirection = &#x27;rtl&#x27; for Right-To-Left languages</span><br><span class="line">  [languages.en]</span><br><span class="line">    title = &quot;Ananke English&quot;</span><br><span class="line">    weight = 2</span><br><span class="line">    contentDir = &quot;content/en&quot;</span><br><span class="line"></span><br><span class="line">[sitemap]</span><br><span class="line">  changefreq = &quot;monthly&quot;</span><br><span class="line">  priority = 0.5</span><br><span class="line">  filename = &quot;sitemap.xml&quot;</span><br><span class="line"></span><br><span class="line">[params]</span><br><span class="line">  text_color = &quot;&quot;</span><br><span class="line">  author = &quot;&quot;</span><br><span class="line">  favicon = &quot;&quot;</span><br><span class="line">  site_logo = &quot;&quot;</span><br><span class="line">  description = &quot;The last theme you&#x27;ll ever need. Maybe.&quot;</span><br><span class="line">  # choose a background color from any on this page: http://tachyons.io/docs/themes/skins/ and preface it with &quot;bg-&quot;</span><br><span class="line">  background_color_class = &quot;bg-purple&quot;</span><br><span class="line">  recent_posts_number = 3</span><br><span class="line"></span><br><span class="line">[[params.ananke_socials]]</span><br><span class="line">name = &quot;twitter&quot;</span><br><span class="line">url = &quot;https://twitter.com/GoHugoIO&quot;</span><br></pre></td></tr></table></figure></li>
<li><p>填充内容</p>
<p> 直接把主题 <code>exampleSite</code> 的 <code>static</code> 和 <code>content</code> 拷贝到项目网站根目录，然后启动本地环境预览下： <code>hugo server</code> ，除了自己修改过的个性化信息，其他跟主题演示没区别，然后依葫芦画瓢修改或者新增自己要的内容就可以了，关键还是要依照主题文档操作！</p>
</li>
</ol>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>和Hugo一样，Hexo内容个性化也是靠配置文件完成，展示个性化根据主题而定。Hexo主题可以到 <a href="https://hexo.io/themes/" title="Hexo官方主题展示页">官网主题页</a> 去挑选：</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/hexo-themes.png" alt="Hexo官网主题页"></p>
<p>配置文件包含根目录下的 <code>_config.yml</code> 和主题目录下的 <code>_config.yml</code> ，在新版中这俩配置可以合而为一，也可以将主题目录下的 <code>_config.yml</code> 移到根目录下命名为： <code>_config.主题名称.yml</code> ，如  <code>_config.maupassant.yml</code> 表示主题 <code>maupassant</code> 的配置，详见 <a href="https://hexo.io/zh-cn/docs/configuration#%E4%BD%BF%E7%94%A8%E4%BB%A3%E6%9B%BF%E4%B8%BB%E9%A2%98%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6" title="使用代替主题配置文件">Hexo主题配置说明</a>。</p>
<p>配置优先级为：项目网站根目录下的 <code>_config.yml</code> 》 <code>_config.maupassant.yml</code> 》主题目录下的 <code>_config.yml</code> ，<strong>建议使用 <code>_config.主题名称.yml</code> 方式存储主题配置</strong>。</p>
<p>Hexo和Hugo一样，基础配置较少，剩下的<strong>请参照主题文档配置！请参照主题文档配置！请参照主题文档配置！</strong></p>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 实操：内容增/删/改</title>
    <url>/guide-how-to-build-site-11.html</url>
    <content><![CDATA[<ul>
<li>增：新增文章、页面、图片等</li>
<li>删：删除文章、页面、图片等</li>
<li>改：对已有的文章、页面等进行修改</li>
</ul>
<p><strong>所有的增删改都需要提交到线上仓库才能看到改变</strong>。使用本站提供的项目仓库，提交源代码后，会自动触发渲染发布，然后静态上端网络缓存更新后才能看到最新结果。</p>
<h3 id="注意格式"><a href="#注意格式" class="headerlink" title="注意格式"></a>注意格式</h3><p>不管是Hugo还是Hexo，他们都只是一种渲染框架，所以MarkDown源代码都需要特定的 <code>Front-matter</code> 标记，也就是两行 <code>---</code> 中间的那段。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#x27;网页模板 pug 基本语法&#x27;</span><br><span class="line">categories:</span><br><span class="line">  - 学编程</span><br><span class="line">tags:</span><br><span class="line">  - 博客建站</span><br><span class="line">date: 2021-12-10 15:22:57</span><br><span class="line">updated: 2021-12-10 15:22:51</span><br><span class="line">toc: true</span><br><span class="line">comments: true</span><br><span class="line">keywords: &#x27;&#x27;</span><br><span class="line">description: &#x27;pug原名jade，因版权问题更名为pug，即哈巴狗。与hexo默认模块ejs一样，pug也是一个模板引擎，可用于快速的网站开发，当然也可以用于静态博客网站的设计。本站点现时所用主题manupassant也使用了pug。&#x27;</span><br><span class="line">top:</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>以上 <code>Front-matter</code> 是 Hexo 程序的，其中设置项也需要对应的主题支持，如果不是 Hexo 基础 <code>Front-matter</code> ，具体需要添加什么根据主题文档来。</p>
<p><code>Front-matter</code> 基础配置项可见：</p>
<ol>
<li><a href="https://gohugo.io/content-management/front-matter/" title="Front Matter Formats">Hugo-Front-Matter</a></li>
<li><a href="https://hexo.io/zh-cn/docs/front-matter">Hexo-Front-matter</a></li>
</ol>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 其他问题</title>
    <url>/guide-how-to-build-site-12.html</url>
    <content><![CDATA[<p>如有问题，请留言。</p>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 建站方案选择</title>
    <url>/guide-how-to-build-site-2.html</url>
    <content><![CDATA[<p>既然这是篇小白零基础建站教程，那么就不会涉及带门槛的方案，只是简单罗列了适合新手的案例，其他同等方案或者更复杂方案等熟悉了可以再自行研究。</p>
<h2 id="方案对比"><a href="#方案对比" class="headerlink" title="方案对比"></a>方案对比</h2><ol>
<li>免费：<strong>hugo&#x2F;hexo + GitHub + GitHub免费二级域名&#x2F;自备域名</strong><pre class="mermaid">    flowchart LR;
   本地维护MarkDown内容 -- hugo/hexo渲染 -->本地效果预览
   GitHub私有仓库 -- 绑定自备域名 --> 公开pages服务
   本地维护MarkDown内容 <-- git同步 --> GitHub私有仓库 -- 触发action自动渲染 --> 公开pages服务</pre>
<ul>
<li>优点：有免费资源，静态页速度快，网站源文件通过git版本管理安全可靠</li>
<li>缺点：需要点MarkDown语法知识，缺界面化管理后台</li>
</ul>
</li>
<li>付费：<strong>WordPress&#x2F;Typecho&#x2F;Zblog + 自备服务器 + 自备域名</strong><pre class="mermaid">    flowchart LR;
   自备域名 -- DNS解析 --> 自备服务器 --> 网站对外服务
   网站界面后台维护内容 --> 自备服务器 -- 大陆区服务器 --> ICP备案 --> 网站对外服务</pre>
<ul>
<li>优点：功能强大几乎能满足所有需求，装好后带后台，纯界面操作</li>
<li>缺点：需要自己购买服务器和域名，度对服务器要求高，响应速度相对慢点</li>
</ul>
</li>
</ol>
<h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><pre class="mermaid">flowchart TB;
免费方案 --必须--> 注册GitHub账号 & 安装Git客户端
注册GitHub账号 --> 创建仓库 & 配置访问令牌
安装Git客户端 --编辑MarkDown源码--> 发布到GitHub
免费方案 --可选--> 安装本地环境 & 装个趁手的编辑器 & 购买域名
装个趁手的编辑器</pre>
<ul>
<li><strong>免费方案</strong>：<ol>
<li><strong>GitHub账号</strong>：要使用免费的资源，不得注册个账号绑定才能找得到么？虽然国内Gitee也有，但绑定自己的域名要收费，而且内容要审核，所以还是直接用GitHub吧。当然，你有自己服务器和域名也可以用来替代。</li>
<li><strong>Git客户端</strong>：用来同步管理源代码，改了什么一目了然</li>
<li><strong>MarkDown 编辑器</strong>：纯手工敲代码是不可能的，借助编辑器事半功倍，而且还能和Git结合，大大降低难度</li>
<li><strong>域名「可选」</strong>：花点小钱占个自己的域名赏心悦目，也好打响自己的品牌，万一哪天走了张<a href="/" title="微博在2010年耗资800万收购 weibo.com">伟波</a>的运呢？</li>
</ol>
</li>
</ul>
<pre class="mermaid">flowchart LR;
付费方案 --必须--> 购买域名 & 购买服务器
购买服务器 --大陆区服务器--> ICP备案
购买服务器 --> 安装环境并部署网站 & 后台发布内容</pre>
<ul>
<li><strong>付费方案</strong>：<ol>
<li><strong>域名</strong>：虽然也有免费的，但还是建议花钱买，每年几十元</li>
<li><strong>服务器&#x2F;云主机&#x2F;虚拟主机</strong>：需要带数据库，支持PHP及安装扩展</li>
<li><strong>ICP备案</strong>：如果用大陆区服务器，必须先工信部ICP备案后才可用，大约需耗时6周</li>
</ol>
</li>
</ul>
<script type="text/javascript" async
  src="https://cdn.staticfile.org/mermaid/9.1.1/mermaid.min.js">
</script>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 本地Git配置</title>
    <url>/guide-how-to-build-site-3.html</url>
    <content><![CDATA[<p>如果你选择的是自备服务器的付费方案，那么直接在服务器上安装环境部署网站程序即可，本文不做详细演示，下文只针对免费方案进行详细说明。</p>
<h2 id="本地-Git-设置"><a href="#本地-Git-设置" class="headerlink" title="本地 Git 设置"></a>本地 Git 设置</h2><h3 id="安装Git"><a href="#安装Git" class="headerlink" title="安装Git"></a>安装Git</h3><p>到 <a href="https://git-scm.com/downloads">Git官网</a> 下载自己操作系统对应的安装包或者按对应命令安装即可。</p>
<h4 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a><strong>Windows</strong></h4><p>安装的时候一路选默认 <code>next</code> 到底就行，最后会在文件夹右键菜单中出现 <code>Git Bash Here</code> 方便使用。</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/git_menu_gitbashhere.png" alt="Git右键菜单"></p>
<h4 id="macOS"><a href="#macOS" class="headerlink" title="macOS"></a><strong>macOS</strong></h4><p>Install <a href="https://brew.sh/">homebrew</a> if you don’t already have it, then:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install git</span><br></pre></td></tr></table></figure>

<h4 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a><strong>Linux</strong></h4><p><strong>Debian&#x2F;Ubuntu</strong><br>For the latest stable version for your release of Debian&#x2F;Ubuntu</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apt install git</span><br></pre></td></tr></table></figure>

<p><strong>CentOS&#x2F;Fedora</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install git</span><br></pre></td></tr></table></figure>

<h3 id="配置Git用户信息"><a href="#配置Git用户信息" class="headerlink" title="配置Git用户信息"></a>配置Git用户信息</h3><p>如前一步图示，随便在哪个文件夹里：点 <code>右键</code> 菜单》点击 <code>Git Bash Here</code> 》启动 <code>Git Bash</code> 「macOS&#x2F;Linux系统打开 <code>Terminal（终端）</code>」，复制粘贴如下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 设置Git用户信息</span><br><span class="line">git config --global user.name &quot;Your_Name&quot;</span><br><span class="line">git config --global user.email &quot;Your_Email&quot;</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：请将命令中邮箱及用户名替换为自己实际信息</p>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - GitHub设置</title>
    <url>/guide-how-to-build-site-4.html</url>
    <content><![CDATA[<h2 id="注册GitHub账号"><a href="#注册GitHub账号" class="headerlink" title="注册GitHub账号"></a>注册GitHub账号</h2><p>如果已有账号则跳过此步骤，直接登录设置即可。如果还没有账号，请访问 <a href="https://github.com/">https://github.com</a> ，完成注册和邮箱认证，一般用户选择免费套餐就足够用了：</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/github.com_join_recommended_plan.png" alt="免费套餐额度"></p>
<h2 id="生成-Personal-access-token"><a href="#生成-Personal-access-token" class="headerlink" title="生成 Personal access token"></a>生成 <code>Personal access token</code></h2><p>取消了用户密码认证后，<code>PAT</code>「<code>Personal access token</code>」成了 GitHub 官方默认的HTTPS认证方式，比SSH密钥安全性差点，但配置简单点。</p>
<ol>
<li><p>登录后，在任何页面的右上角，单击右上角个人资料照片，然后单击 <code>Settings（设置）</code></p>
</li>
<li><p>在左侧栏中，单击  <code>&lt;&gt;开发者设置</code>》<code>Personal access tokens（个人访问令牌）</code></p>
<p> <img src="https://docs.github.com/assets/cb-7169/images/help/settings/personal_access_tokens_tab.png" alt="Personal access tokens"></p>
</li>
<li><p>单击 <code>Generate new token（生成新令牌）</code>，如需密码验证输密码验证即可。</p>
<p> <code>Note</code> 行里随便填，写给自己看的，过期时间建议选择 <code>No Expiration（永不过期）</code></p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/personal_access_token.png" alt="Generate new token"></p>
 <div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #8a6d3b;; background-color: #fcf8e3; border-color: #faebcc;">作为安全防范措施，GitHub 会自动删除一年内未使用的个人访问令牌。 </div>
</li>
<li><p>如下勾选相关权限</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/personal_access_token_scopes.png" alt="repo"><br> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/personal_access_token_scopes1.png" alt="admin/user"></p>
</li>
<li><p>最后点击 <code>Generate token</code> 生成个人访问令牌。</p>
<p> <img src="https://docs.github.com/assets/cb-10912/images/help/settings/generate_token.png" alt="Generate token"></p>
</li>
</ol>
<p>添加完成后，会显示刚添加的令牌，该令牌明文只会显示一次，所以请 <font color=red>务必复制保存下来备用</font>否则就需要删除重新生成，后面项目仓库和本地访问认证都能用得到该令牌。</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/personal_access_tokens.png" alt="令牌明文内容"></p>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 配置SSH密钥</title>
    <url>/guide-how-to-build-site-5.html</url>
    <content><![CDATA[<p>相对于前文提到的 <a href="/guide-how-to-build-site-4.html" title="从零开始建个小站 - GitHub设置">GitHub设置 - Personal access token</a>，使用 SSH 密钥是另一种更安全的方式。</p>
<h2 id="生成SSH密钥"><a href="#生成SSH密钥" class="headerlink" title="生成SSH密钥"></a>生成SSH密钥</h2><div style="padding: 15px; border: 1px solid transparent; border-color: transparent; margin-bottom: 20px; border-radius: 4px; color: #8a6d3b;; background-color: #fcf8e3; border-color: #faebcc;">
<strong>注意：</strong> 
<p>2021年8月14号开始，GitHub弃用账密验证Git操作，改用token或SSH密钥</p>
<p>GitHub 在 2022 年 3 月 15 日通过删除较旧的不安全密钥类型提高了安全性，不再支持 DSA 密钥 (<code>ssh-dss</code>)。</p>
<p>在 2021 年 11 月 2 日之前 <code>valid_after</code> 的 RSA 密钥 (<code>ssh-rsa</code>) 可以继续使用任何签名算法。 在该日期之后生成的 RSA 密钥必须使用 SHA-2 签名算法。 某些较旧的客户端可能需要升级才能使用 SHA-2 签名。</p></div>

<p>当前就相当于强制用户使用超长随机串密码，安全加强是好事，遵循规则使用 <code>SHA-2</code> 签名规则密钥即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 生成密钥对，一路回车默认即可</span><br><span class="line"># 如已有其他密钥对在用，自己改下生成的文件名以防覆盖</span><br><span class="line">ssh-keygen -t ed25519 -C &quot;Your_Email&quot;</span><br></pre></td></tr></table></figure>

<p>如果您使用的是不支持 <code>ed25519</code> 算法的旧系统，请使用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;Your_Email&quot;</span><br></pre></td></tr></table></figure>
<p>更多密钥相关详细信息可参阅 [GitHub官方文档][new-SSH-key]</p>
<p>如果你是一路回车生成密钥对，那么生成的密钥对会保存在：<code>~/.ssh/</code> 目录下，<code>~</code> 表示用户目录，如操作系统登录用户名是 <code>xyz</code> ，那么在Windows下路径则为 <code>C:\Users\xyz\.ssh</code> ,macOS&#x2F;Linux下路径为 <code>/home/xyz/.ssh</code> ，其中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/.ssh/id_ed25519 //私钥，保存在本地</span><br><span class="line">~/.ssh/id_ed25519.pub //公钥，配置到异端</span><br></pre></td></tr></table></figure>

<p>到此，本地Git环境已准备妥当，下一步将公钥配置到GitHub中就能使用了。</p>
<h2 id="配置密钥"><a href="#配置密钥" class="headerlink" title="配置密钥"></a>配置密钥</h2><p>为了使用方便，给GitHub添加一个用户密钥，一个密钥可作用于整个账号的增删改查操作。</p>
<ol>
<li><p>将 SSH 公钥内容复制到剪贴板「假设都按前面的默认操作」</p>
 <details open><summary>Windows</summary>

<p> 打开 <code>Git Bash</code> ，复制粘贴如下命令</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">clip &lt; ~/.ssh/id_ed25519.pub</span><br><span class="line">//该命令自动将公钥存到剪贴板，直接用文本编辑器打开公钥再复制也是一样的</span><br></pre></td></tr></table></figure>

 </details>
 <details><summary>macOS/Linux</summary>

<p> 打开 Terminal（终端），复制粘贴如下命令：</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat ~/.ssh/id_ed25519.pub</span><br><span class="line">// 执行完将打印出来的公钥内容完整复制待用</span><br></pre></td></tr></table></figure>

 </details>
</li>
<li><p>登录GitHub账号后，在任何页面的右上角，单击右上角个人资料照片，然后单击弹出下拉中的 <code>Settings（设置）</code></p>
</li>
<li><p>选择左侧 <code>Access</code>》 点击 <code>SSH and GPG keys</code>，点击 <code>New SSH key（新 SSH 密钥）</code></p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/github_set_access_new_ssh.png" alt="Add New SSH key"></p>
</li>
<li><p>在 <code>Title</code>（标题）字段中，为新密钥添加描述性标签便于识别用途。 例如，如果您使用在个人Mac上，此密钥名称可能是 <code>Personal MacBook</code>。</p>
</li>
<li><p>将前面复制的公钥串粘贴到 <code>Key</code>（密钥）字段</p>
<p> <img src="https://docs.github.com/assets/cb-24796/images/help/settings/ssh-key-paste.png" alt="粘贴公钥串"></p>
</li>
<li><p>最后点击 <code>Add SSH key（添加 SSH 密钥）</code> 完成添加</p>
</li>
</ol>
</details>]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 实操：准备存储仓库</title>
    <url>/guide-how-to-build-site-6.html</url>
    <content><![CDATA[<p>本实操仅针对 <a href="/guide-how-to-build-site-2.html" title="从零开始建个小站 - 建站方案选择">建站方案选择</a> 中提及的免费方案：<strong>hugo&#x2F;hexo + GitHub + GitHub免费二级域名&#x2F;自备域名</strong>，另外的付费方案自带网站后台，界面化的一体操作没什么好演示的，如有需要可求助我们的战略合作伙伴Google和百度。</p>
<h2 id="建立存储仓库"><a href="#建立存储仓库" class="headerlink" title="建立存储仓库"></a>建立存储仓库</h2><p>虽然可以通过分支控制源文件和对外访问文件，但还是建议分仓库存储：</p>
<ol>
<li><strong>公开：GitHubPages仓库</strong>：页面文件对外访问</li>
<li><strong>私有：项目仓库</strong>：存储网站源文件，只有自己可见防止提交记录、网站配置等机密信息外泄</li>
</ol>
<h3 id="公开：GitHubPages仓库"><a href="#公开：GitHubPages仓库" class="headerlink" title="公开：GitHubPages仓库"></a><strong>公开：GitHubPages仓库</strong></h3><ol>
<li><p>登录GitHub，在任何页面的右上角，使用 <code>+</code> 下拉菜单选择 <code>New repository（新建仓库）</code></p>
<p> <img src="https://docs.github.com/assets/cb-11427/images/help/repository/repo-create.png" alt="新建GitHubPages仓库"></p>
</li>
<li><p>因为要对外访问，所以名称必须为：<code>&lt;owner&gt;.github.io</code>，且可见性必须为 <code>public(公开)</code>：</p>
<p> <img src="https://docs.github.com/assets/cb-34195/images/help/pages/create-repository-name-pages.png" alt="username.github.io"><br> <img src="https://docs.github.com/assets/cb-20877/images/help/repository/create-repository-public-private.png" alt="可见性选public(公开)"></p>
</li>
<li><p>此时只是个空仓库备用，等有提交了再来设置pages</p>
</li>
</ol>
<h3 id="私有：项目仓库"><a href="#私有：项目仓库" class="headerlink" title="私有：项目仓库"></a><strong>私有：项目仓库</strong></h3><p>项目仓库保存着网站的源代码，控制网站的输出内容和页面样式。这里用导入模板仓库的方法，快速生成具有与模板仓库相同的目录结构和文件的新仓库，该模板仓库实现功能：</p>
<ul>
<li>自动将源文件渲染并发布到GitHubPages仓库pages分支</li>
<li>自动判断配置的网站域名，并决定是否需要绑定 <code>CNAME</code></li>
<li>自动渲染发布到当前项目仓库pages分支，如果不设置为私有仓库可作为项目主页访问</li>
<li>pages分支只保留最后1次提交记录</li>
</ul>
<ol>
<li><p>打开 <a href="https://github.com/828767/" title="hugo/hexo框架模板">这个模板仓库</a> 主页面，根据自己的需求选择 <code>action-hugo</code> 或者 <code>action-hexo</code> 等仓库任选其一</p>
</li>
<li><p>在文件列表上方，单击 <code>Use this template（使用此模板）</code></p>
<p> <img src="https://docs.github.com/assets/cb-36544/images/help/repository/use-this-template-button.png" alt="使用模板"></p>
</li>
<li><p>输入你想要的仓库名称和描述（可选），网站源码仓库可见性建议选择 <code>Private（私有）</code></p>
<p> <img src="https://docs.github.com/assets/cb-25139/images/help/repository/create-repository-name.png" alt="项目仓库名称"></p>
</li>
<li><p>（可选）要包括模板中所有分支的目录结构和文件，而不仅仅是默认分支，请勾选 <code>Include all branches（包括所有分支）</code></p>
</li>
<li><p>最后点击 <code>Create repository from template（从模板创建仓库）</code></p>
</li>
</ol>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 实操：打通发布流程</title>
    <url>/guide-how-to-build-site-7.html</url>
    <content><![CDATA[<p>截止当前，我们已经准备好了建站需要的存储仓库，接着还需要配置相应的权限才能顺利对外发布。</p>
<h2 id="配置发布令牌"><a href="#配置发布令牌" class="headerlink" title="配置发布令牌"></a>配置发布令牌</h2><p>还记得 GitHub 设置中配置的 <code>Personal access token</code> 么，前面叮嘱复制保存下来，下面该派上用场了：</p>
<ol>
<li><p>导航到刚创建的项目仓库主页面，在仓库名称下，单击  <code>Settings（设置）</code></p>
<p> <img src="https://docs.github.com/assets/cb-21851/images/help/repository/repo-actions-settings.png" alt="Settings（设置）"></p>
</li>
<li><p>点击左侧的 <code>Secrets》Actions</code>，新建仓库机密</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/repo_set_repo_secret.png" alt="新建仓库机密"></p>
</li>
<li><p>在 <code>Name（名称）</code>输入框中键入机密的名称必须为：<code>ACTION_ACCESS_TOKEN</code> ，<code>Value</code> 框粘贴之前复制保存的那串值</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/repo_set_repo_secret1.png" alt="ADD ACTION_ACCESS_TOKEN"></p>
</li>
<li><p>最后单击 <code>Add secret（添加密码）</code> 保存完成</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/repo_set_repo_secret2.png" alt="ACTION_ACCESS_TOKEN"></p>
</li>
</ol>
<h2 id="小试牛刀"><a href="#小试牛刀" class="headerlink" title="小试牛刀"></a>小试牛刀</h2><p>经过之前的一番操作，服务器上一切都准备就绪了，可以试试好使与否，直接在项目仓库中触发个提交就行，比如点击 <code>config.toml</code> 或 <code>config.yml</code> 编辑里面的url，然后保存提交。</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/github_commit_first.png" alt="提交变更试效果"></p>
<p>项目仓库提交变更后，要不了一分钟会自动将源文件渲染并发布到pages仓库，到pages仓库中可见刚从项目仓库提交过来的分支，要对外访问则要设置为pages指定分支。</p>
<p><img src="https://cdn.jsdelivr.net/gh/828767/static/images/github_repo_new_branch.png" alt="自动提交的分支"></p>
<h2 id="设置pages分支"><a href="#设置pages分支" class="headerlink" title="设置pages分支"></a>设置pages分支</h2><p>前文已经提到pages分支了，用户pages仓库为：<code>&lt;owner&gt;.github.io</code>，其他则为项目仓库，设置方法都是一样的：</p>
<ol>
<li><p>导航到pages仓库主页，点击 <code>Settings（设置）</code>，点击左侧 <code>Pages</code> 标签，选择对应的分支</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/githubpages_select_branch.png" alt="Pages-branch"></p>
</li>
<li><p>点击保存后，大约5分钟，就可以通过页面上提示的地址对外访问了。</p>
<p> <img src="https://docs.github.com/assets/cb-27618/images/help/pages/click-pages-url-to-preview.png" alt="&lt;owner&gt;.github.io"></p>
</li>
</ol>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 实操：代码拉到本地</title>
    <url>/guide-how-to-build-site-8.html</url>
    <content><![CDATA[<p>工欲善其事必先利其器，Hexo&#x2F;Hugo虽然没后台，选用个好用的编辑器后甚至比WordPress之类的后台还方便。</p>
<h2 id="文档编辑器"><a href="#文档编辑器" class="headerlink" title="文档编辑器"></a>文档编辑器</h2><p>优秀的MarkDown编辑器不少，Typora、Atom、vscode等都是其中的佼佼者，推荐 <code>vscode</code>：</p>
<ul>
<li>微软主导开发，全平台开源免费</li>
<li>用户众多，各种功能插件一应俱全</li>
<li>支持目录树管理，所有文件操作都可以在一个界面内完成</li>
<li>支持分屏及实时预览</li>
<li>与Git终端集成，版本管理一目了然，支持 <code>pull</code> 与 <code>push</code> 等界面化操作</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/35271042/118224532-3842c400-b438-11eb-923d-a5f66fa6785a.png" alt="vscode"></p>
<p><strong>作为 MarkDown 编辑器，推荐安装以下扩展</strong></p>
<ol>
<li>Git History</li>
<li>GitLens supercharges</li>
<li>Markdown All in One</li>
<li>Markdown Preview Mermaid Support</li>
<li>Markdown Table</li>
<li>Markdown Shortcuts</li>
</ol>
<p>其他更多扩展根据自己需求去发觉安装，代码美化，自动填充，自动关闭标签等功能应有尽有。</p>
<h2 id="克隆仓库到本地"><a href="#克隆仓库到本地" class="headerlink" title="克隆仓库到本地"></a>克隆仓库到本地</h2><p>虽然项目仓库主页直接增删改文件都可以，但网页上只能一个一个文件操作，建议还是同步到本地使用，借助编辑器事半功倍，也相当于多了个源码本地备份。</p>
<p>前面已经准备好了 <code>vscode</code>，那么直接在 <code>vscode</code> 中操作。</p>
<ol>
<li><p>启动 <code>vscode</code> ，通过快捷 <code>CTRL+~</code> 或者菜单 <code>Terminal》New Terminal（新建终端）</code></p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/vscode_new_terminal.png" alt="新建终端"></p>
</li>
<li><p>在打开的终端中，通过 <code>git clone </code> 命令将项目仓库克隆到本地「也可以安装 <code>GitHub Explorer</code> 像下载工具一样界面化操作」</p>
 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 查看当前所处的目录，vscode打开文件夹后终端默认切到目录路径</span><br><span class="line">pwd</span><br><span class="line"># 为方便管理，切换到自己需要的目录，此示例是在D盘建了个git目录</span><br><span class="line">cd d:\git</span><br><span class="line"># 将仓库包括子项目保存到d:\git\REPOSITORY</span><br><span class="line">git clone --recurse-submodules https://github.com/USERNAME/REPOSITORY.git</span><br></pre></td></tr></table></figure>
<p> 请将仓库地址换成实际地址，获取方法：打开仓库主页》在文件列表右上方有个 <code>Code</code> ，点击下拉复制，如下图所示：</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/github_clone_https_url.png" alt="获取项目仓库地址"></p>
</li>
<li><p>克隆完成后，通过快捷方式 <code>Ctrl+K Ctrl+O</code> 或者菜单 <code>File（文件）》Open Folder（打开文件夹）</code> 打开刚克隆完的仓库目录。</p>
<p> <img src="https://cdn.jsdelivr.net/gh/828767/static/images/vscode_markdown_editor.png" alt="打开文件夹"></p>
</li>
</ol>
<p>至此，我们就可以在 <code>vscode</code> 中便捷地增删改网站源文件了。</p>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>从零开始建个小站 - 实操：本地测试预览</title>
    <url>/guide-how-to-build-site-9.html</url>
    <content><![CDATA[<p>如果你想在本地就直接看到渲染后的效果，那么还需要安装个本地环境。</p>
<h2 id="Hugo"><a href="#Hugo" class="headerlink" title="Hugo"></a>Hugo</h2><p>Hugo 是个golang开发的跨平台程序，无需外部依赖，直接将单程序安装部署在本地就行，此处以Windows操作系统为示例，其他操作系统请见 [Hugo官方安装说明][hogo-install]。</p>
<p>打开 <a href="https://github.com/gohugoio/hugo/releases">Hugo版本发布页</a>，下载 Windows 版本，建议下载 <a href="https://github.com/gohugoio/hugo/releases/download/v0.99.1/hugo_extended_0.99.1_Windows-64bit.zip">hugo_extended 版</a>，将程序 <code>hugo.exe</code> 解压到某目录，如 <code>C:\HUGO\</code> ，然后将此目录添加到系统变量中就可以在任何位置直接执行 <code>hugo</code> 命令，可直接打开命令终端使用 <code>set</code> 一键完成：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将 C:\HUGO\ 添加到系统 path 变量，请替换成自己的实际路径</span><br><span class="line">set path=%path%;C:\HUGO\</span><br></pre></td></tr></table></figure>
<p>如果习惯界面设置，可以百度搜索：<code>Windows 添加path变量</code> ，设置完成后任意路径下执行命令可见效果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hugo version</span><br><span class="line">hugo v0.99.1-d524067382e60ce2a2248c3133a1b3af206b6ef1+extended windows/amd64 BuildDate=2022-05-18T11:18:14Z VendorInfo=gohugoio</span><br></pre></td></tr></table></figure>

<p>切换到刚克隆下来的项目仓库「vscode打开文件夹后启动的终端会自动切到当前目录」，预览下网站效果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xxx@CVE MINGW64 /d/git/action-hugo (main) //当前所在路径，Git分支</span><br><span class="line">$ hugo server //运行本地服务端</span><br><span class="line">Start building sites … </span><br><span class="line">hugo v0.99.1-d524067382e60ce2a2248c3133a1b3af206b6ef1+extended windows/amd64 BuildDate=2022-05-18T11:18:14Z VendorInfo=gohugoio</span><br><span class="line"></span><br><span class="line">                   | ZH | EN  </span><br><span class="line">-------------------+----+-----</span><br><span class="line">  Pages            | 20 | 19</span><br><span class="line">  Paginator pages  |  0 |  0</span><br><span class="line">  Non-page files   |  0 |  0</span><br><span class="line">  Static files     |  6 |  6</span><br><span class="line">  Processed images |  0 |  0</span><br><span class="line">  Aliases          |  2 |  1</span><br><span class="line">  Sitemaps         |  2 |  1</span><br><span class="line">  Cleaned          |  0 |  0</span><br><span class="line"></span><br><span class="line">Built in 352 ms</span><br><span class="line">Watching for changes in D:\git\action-hugo\&#123;archetypes,content,data,layouts,static,themes&#125;</span><br><span class="line">Watching for config changes in D:\git\action-hugo\config.toml, D:\git\action-hugo\themes\ananke\config.yaml</span><br><span class="line">Environment: &quot;development&quot;</span><br><span class="line">Serving pages from memory</span><br><span class="line">Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender</span><br><span class="line">Web Server is available at http://localhost:1313/ (bind address 127.0.0.1)</span><br><span class="line">Press Ctrl+C to stop</span><br></pre></td></tr></table></figure>
<p>点击返回提示的url调用浏览器打开即能看到效果。</p>
<h2 id="Hexo"><a href="#Hexo" class="headerlink" title="Hexo"></a>Hexo</h2><p>Hexo 需要依赖 <code>npm</code> ，所以需要安装 <code>nodejs</code>，直接到 <a href="https://nodejs.org/">官网</a> 下载安装包一路默认安装，macOS及Linux按官网提示安装即可。安装完成 <code>npm version</code> 有相应提示。</p>
<p>因为要在本地运行查看效果，那么还需要安装 <code>hexo-cli</code> 和 <code>node_modules</code> 依赖：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xxx@CVE MINGW64 /d/git/action-hexo (main) //当前所在路径，Git分支</span><br><span class="line">$ npm install -g hexo-cli //全局安装hexo客户端</span><br><span class="line">$ npm install //在hexo仓库根目录下执行，会自动安装预设的模块</span><br></pre></td></tr></table></figure>
<p>安装完成后，执行 <code>hexo version</code> 可以查看效果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">xxx@CVE MINGW64 /d/git/action-hexo (main) //当前所在路径，Git分支</span><br><span class="line">$ hexo s</span><br><span class="line">INFO  Validating config</span><br><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http://localhost:4000/ . Press Ctrl+C to stop. </span><br></pre></td></tr></table></figure>
<p>点击返回提示的url调用浏览器打开即能看到效果。</p>
]]></content>
      <categories>
        <category>做网站</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
</search>
