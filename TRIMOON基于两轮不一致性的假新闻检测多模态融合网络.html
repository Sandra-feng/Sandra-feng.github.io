<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络 | Sandra_feng personal blog</title><meta name="keywords" content="学习记录"><meta name="author" content="Sandra_feng"><meta name="copyright" content="Sandra_feng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络然而，有时新闻文章的文本和图像之间存在不一致。因此，为了判断图像和文本的一致性，Xue等[16]提出了一种多模态一致性神经网络(multi-modal consistency neural network, MCNN)，其中包含相似度测量模块，使用余弦距离来测量图像和文本之间的一致性。本实验考虑了多模态数据的一致性，大大增强了对虚假新闻+图">
<meta property="og:type" content="article">
<meta property="og:title" content="TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络">
<meta property="og:url" content="https://sandra-feng.github.io/TRIMOON%E5%9F%BA%E4%BA%8E%E4%B8%A4%E8%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C.html">
<meta property="og:site_name" content="Sandra_feng personal blog">
<meta property="og:description" content="TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络然而，有时新闻文章的文本和图像之间存在不一致。因此，为了判断图像和文本的一致性，Xue等[16]提出了一种多模态一致性神经网络(multi-modal consistency neural network, MCNN)，其中包含相似度测量模块，使用余弦距离来测量图像和文本之间的一致性。本实验考虑了多模态数据的一致性，大大增强了对虚假新闻+图">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picdm.sunbangyan.cn/2023/08/31/fjavr4.jpg">
<meta property="article:published_time" content="2023-08-30T06:04:21.000Z">
<meta property="article:modified_time" content="2023-08-30T06:04:21.000Z">
<meta property="article:author" content="Sandra_feng">
<meta property="article:tag" content="学习记录">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picdm.sunbangyan.cn/2023/08/31/fjavr4.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://sandra-feng.github.io/TRIMOON%E5%9F%BA%E4%BA%8E%E4%B8%A4%E8%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Sandra_feng","link":"链接: ","source":"来源: Sandra_feng personal blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-30 14:04:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Sandra_feng personal blog" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s3.bmp.ovh/imgs/2023/07/22/d87b3c27f25f5e68.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picdm.sunbangyan.cn/2023/08/31/fjavr4.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Sandra_feng personal blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-30T06:04:21.000Z" title="发表于 2023-08-30 14:04:21">2023-08-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-30T06:04:21.000Z" title="更新于 2023-08-30 14:04:21">2023-08-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="TRIMOON-基于两轮不一致性的假新闻检测多模态融合网络"><a href="#TRIMOON-基于两轮不一致性的假新闻检测多模态融合网络" class="headerlink" title="TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络"></a>TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络</h1><p>然而，有时新闻文章的文本和图像之间存在不一致。因此，为了判断图像和文本的一致性，Xue等[16]提出了一种<strong>多模态一致性神经网络</strong>(multi-modal consistency neural network, MCNN)，其中包含相似度测量模块，使用余弦距离来测量图像和文本之间的一致性。本实验考虑了多模态数据的一致性，大大增强了对虚假新闻+图像不匹配情况的检测。在基于多模态的假新闻检测方面，该模型比其他基线模型更有效。</p>
<p>综上所述，虽然现有的研究主要集中在图文多模态融合和图文一致性检测两种方法上，也取得了较好的表现，但目前的方法仍然面临以下挑战:(1)多模态特征融合和图文一致性判别是独立进行的，导致最终的融合特征中存在噪声。(2)由于文本是新闻文章的主体，在现有的模式中，文本情态中的信息在表达信息中的主导作用还没有充分体现出来。因此，如何充分考虑图像和文本特征的融合，突出文本在新闻中的主导地位，同时兼顾图像和文本的一致性问题，还有待探索。</p>
<p>为了解决上述挑战，我们提出了一种考虑图像-文本不一致性的多模态融合模型，称为基于两轮不一致性的多模态融合网络(TRIMOON)。</p>
<p>首先，我们在一般的图像-文本共注意融合模块之前构建了语义一致性评分模块，目的是基于一致性程度来控制融合强度。其次，我们进行了文本形态的融合和图像-文本融合表示，以加强文本信息的主导地位。最后，在融合表示的基础上，利用双向长短期记忆(BiLSTM)对文档表示进行编码，并通过全连通层输出分类标签。</p>
<p>本文的主要贡献如下:</p>
<p>本文提出了一种基于图像-文本一致性的多模态融合模块用于假新闻检测（本人想法：还可以融合其他模态比如情感特征、上下文特征）抑制图像和文本不一致时融合表示产生的噪声。</p>
<p>我们为图像-文本信息融合的表征提供了一种二次融合机制，从而加强了文本模式在新闻媒体中的主导作用。</p>
<p>本文的后续章节组织如下。</p>
<p>第2节提供了相关工作的分析，并总结了我们提出的方法与现有方法之间的差异。第3节详细介绍了本文提出的TRIMOON模型。第4节提供了验证实验的设置和实验结果的观察和分析。第5节讨论了建模中需要解决的一些问题。最后一部分是结束语，指出了未来的研究方向。</p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><p><strong>Based on traditional machine learning</strong></p>
<p>Castillo等[19]从用户的传播行为角度出发，构建了内容、话题、传播、行为等特征集，并通过SVM[20]、J48[21]等机器学习算法进行验证，最终达到89%的分类准确率。实验验证了引入上述四类特征的有效性。</p>
<p>Ruchansky等[22]提出了一种自动假新闻检测器CSI (Capture, Score, and Integrate)。它由三个模块组成:捕获、评分和集成。检测器通过使用与传入新闻相关的三个特征来预测假新闻:文本、响应和来源。该模型由三个模块组成。第一个算法提取新闻文章的时间表示。第二个模块表示用户的行为并对其进行评分，最后一个模块使用前两个模块的输出并使用它们进行分类。他们的实验表明，CSI的准确性有所提高。Reis等人[23]针对该任务提出了一种新的特征集，并将其应用于现有的自动检测模型，并通过实验验证了新特征集的有效性。此外，假新闻的目的之一是操纵人们的观点，因此在一些工作中，情绪信息[24]也被认为是一个特征[25,26]。</p>
<p>显式特征很容易解释，但不一定是机器学习模型学习的最佳数据。最近，一些研究工作开始探索假新闻的隐含特征。Guo等[27]根据新闻数据，基于用户画像构建特征，纳入用户行为、可信度、可靠性等隐式特征。Wu等[28]提出了新闻话题类型和情感特征，结合消息传播间隔特征，使用随机行走[29]核函数的支持向量机算法进行分类，在微博数据集上取得了很好的效果。</p>
<p><strong>Based on deep learning and multi-modal</strong></p>
<p>随着新闻内容变得越来越复杂，仅仅依靠人工特征是不够的。此外，随着深度学习算法的普及，许多研究人员已经开始使用基于深度神经网络的模型来完成假新闻检测任务。挖掘出比传统机器学习中使用的人工特征更重要、更容易学习的特征。同时，通过深度神经网络将多模态信息引入到假新闻检测中。</p>
<p>Jin等人[32]提出了一种基于注意力的递归神经网络(att-RNN)，该网络融合了来自文本、视觉和社会背景的信息。Wang等[33]提出了一种事件对抗神经网络(Event Adversarial Neural Network, EANN)，将事件分类任务引入到对抗学习中，引导模型学习与事件无关的文本模态和图像模态特征，具有更好的泛化性能。Khatter等[34]提出了一种端到端的多模态变分自编码器(MVAE)网络，该网络由编码器、解码器和假新闻检测模块三个主要组成部分组成，利用编码器-解码器结构构建多模态新闻的特征表达。</p>
<p>以上方法在检测具有多模态信息的假新闻方面是有效的，但由于缺乏足够的事实知识，无法充分理解多模态新闻事件的深层语义。</p>
<p>为了解决这一问题，Zhang等[35]提出了一种新的多模态知识感知事件记忆网络(MKEMN)，该网络利用多模态知识感知网络(MKN)和事件记忆网络(EMN)作为社交媒体谣言检测的构建模块。从外部知识图谱中提取文本实体对应的概念知识，并将其集成到多模态表示中，以获得更高的语义理解能力。</p>
<p>Wang等[36]提出了一种新的知识驱动的多模态图卷积网络(KMGCN)，该网络通过对文本信息的联合建模来建模语义表示，并将知识概念和视觉信息集成到统一的假新闻检测框架中。事实上，图像的可用性也是多模态融合模型中需要考虑的问题。</p>
<p>一些工作考虑将文本与图像中出现的实体对齐，以区分图像和文本之间的不一致，从而提高检测性能[37,38]。随后，Li等人提出了一个以实体为中心的多模态学习框架，该框架通过实体对齐和以实体为中心的特征聚合两个模块学习新的特征表示来训练分类器[39]。Chen等人提出了一种跨模态歧义学习模型，用于单模态和多模态特征的动态融合，歧义大时以单模态特征为主，歧义小时以跨模态特征为主[40]。</p>
<p>本文从图像和文本一致性的角度提出了一种新的多模态融合方法。与实体级一致性不同[37,38]，我们考虑图像与新闻文本的整体语义一致性[16,40]。在我们的方案中，我们突出文本模态作为新闻的主导信息，同时基于不一致性适当融合图像模态信息，而[16]直接将一致性与类标签对齐，[40]从数据集整体层面学习图像和文本模态的一致性表示并在此基础上进行加权融合。在我们的模型中，无论图像信息与文本内容是否一致，都不会取代文本模态特征作为分类的主导特征，这也符合我们人类阅读和判断新闻真假的习惯。</p>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>给定一个集合𝐷&#x3D;{(𝑥𝑖,𝑦𝑖),𝑖&#x3D; 1,…,𝑁}，𝑁新闻条目,每个新闻𝑥𝑖有标签𝑦𝑖∈{0,1}，𝑥𝑖包含𝑥𝑇𝑖和𝑥𝑉𝑖,哪里𝑥𝑇𝑖新闻中的文本,𝑥𝑉𝑖新闻图片。</p>
<p>我们提出的模型将利用训练实例学习一个从特征空间𝑋到标签空间𝑌的映射函数∶𝑋→𝑌，然后利用其特征向量来预测实例的标签向量。我们模型的输入是每个新闻条目的文本和图像。使用BERT和VGG (Visual Geometry Group)网络分别学习文本特征和图像特征。</p>
<p>在我们的工作中，我们认为在检测假新闻时，文本模型是基础，图像信息是辅助。</p>
<p>同时，图像-文本不一致是双模融合中必须考虑的问题。因此，在我们提出的方法中，在每次融合之前，图像信息将经过一个门结构进行信息选择。在多模态特征融合之前，对VGG-19馈送的图像特征进行第一次不一致性度量。然后，我们使用共同关注来捕捉文本特征和过滤后的图像特征之间的关系。在第二次融合中，我们通过另一个不一致性测量门来控制第一次融合后的结果，然后与文本信息重新融合。最后，通过具有全连接层的BiLSTM网络获得预测结果。输出是该新闻的标记(true或false)。所提出的模型整体结构如图2所示。该模型包括: (1)多模态特征提取模块; (2)多模态特征融合模块; (3)分类模块。</p>
<p><strong>The multi-modal feature extraction module</strong></p>
<p>我们使用BERT作为文本编码器。BERT模型的初始输入是一组句子𝑆&#x3D;{𝑠1，𝑠2，…，𝑠𝑚}，𝑠𝑚表示𝑚th句子，其中𝑚∈𝑀;句子𝑠可以表示为一组字符𝑠&#x3D;{𝑤1，𝑤2，…，𝑤N}，𝑤𝑛表示句子中的𝑛th字符。在我们的任务中，𝑆&#x3D;𝑥𝑇𝑖，即𝑖th新闻的文本部分。BERT输入向量由词嵌入向量、段嵌入向量和位置编码向量组成。</p>
<p>词嵌入向量是每个词的向量表示，BERT可以以句子对的形式进行训练，并使用分割的嵌入向量来识别句子。在位置编码向量中，BERT使用学习到的位置编码来识别每个单词的位置信息。然后，BERT模型使用Transformer[44]编码器构建多层双向网络，该网络由多层Transformer编码器堆叠。编码器的每一层由多头自关注子层和前馈神经网络子层组成。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picss.sunbangyan.cn/2023/08/31/f9m8ap.png"></p>
<p>𝑇𝑜𝑘𝑒𝑛𝐵𝑒𝑟𝑡是BERT模型的token-level（标记）输出序列。𝑆𝑒𝑛𝑡B𝑒𝑟𝑡为BERT模型的句子级输出; 𝑚𝑡是输出文本特征。</p>
<p>对于新闻分集，提取图像特征的过程可以用方程表示。(4) -(6)。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdl.sunbangyan.cn/2023/08/31/f9ubuz.png"></p>
<p> The inconsistency measurement module不一致性测量模块</p>
<p>该模块通过测量文本和图像之间的语义相似度来评估文本和图像的不一致性。与那些在实体层面衡量一致性的作品不同[37,38]，我们从整体一致性的角度进行思考。</p>
<p>在上一模块中，我们使用BERT和VGG-19学习了文本和图像的特征表示。然后我们在线性层上应用sigmoid函数，其中我们将特征表示连接为输入，以测量它们之间的不一致性。然后，我们采用乘法门来获得加权图像模态表示。在这里，该模块旨在衡量同一新闻的图像和文本的语义一致性，并通过以下门机制进一步控制可以融合的信息程度。可以使用多种方法来度量语义一致性。通过实验比较，我们发现对于我们的数据集，一个简单的线性层是一个更好的选择。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdm.sunbangyan.cn/2023/08/31/fabg5m.png"></p>
<p><strong>特征融合</strong></p>
<p>我们的多模态特征融合主要由两个组件完成:一个由两个并行的共同注意块组成的共同注意层[46]和一个基于门的融合模块。图3给出了共注意块的结构，在Co-Attention块中，它的查询和键(&#x3D;value)来自不同的地方，即，如果查询来自文本，则键(&#x3D;value)来自图像，反之亦然。</p>
<p>对于图像模态，计算过程如下:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdl.sunbangyan.cn/2023/08/31/fasty9.png"></p>
<p>对于文本模态，通过相同的计算过程，我们可以得到文本模态特征。通过将共同注意块A和共同注意块B并行排列，并将它们组合成一个共同注意层。共同关注块A使用文本特征作为查询和图像特征为键，共同关注块B使用图像特征作为查询，文本特征作为键。这样就实现了文本和图像之间信息的交互学习。</p>
<p>基于门的融合模块是第二融合。与已有工作中的共关注叠加分量[47]不同，我们的第二次融合再次基于门机制对特征信息流进行控制，以获得更可靠的特征表示。Wu等[47]在多模态信息重要性相等的前提下，使用了特征信息的迭代融合。但是，我们认为图像模态(及其融合特征)只是辅助信息，其权重需要通过逐步向前融合时的一致性程度来衡量。</p>
<p>融合过程如式所示。(13) -(16)。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fb1xhg.png"></p>
<p>结论与讨论</p>
<p>通过检测文本模态与图像模态的不一致性，使我们的模型在融合多模态信息时能够学习到更合理的特征表示，从而提高检测性能。此外，在我们的融合模型中，文本形态的主导地位并没有被图像特征所掩盖，就像文本信息是一般新闻的主导信息表示一样。</p>
<p>事实上，当图片与文字不一致时，发布者有可能使用不准确的(挪用的，历史的)图片作为伪造的证据来支持新闻文本中的结论。这是基于不一致信息构造特征融合表示的原因之一。然而，通过对上述实验结果的分析，我们也发现我们的模型对于图像-文本一致性检测仍然处于粗粒度水平，受限于缺乏对图像的语义理解。因此，细粒度图像理解和图像-文本一致性检测仍然是一个挑战。此外，当图像与文本高度一致时，特征失去了多样性，如何更有效地利用或增强文本模态的特征是另一个具有挑战性的问题。</p>
<p>本文提出了一种新的多模态融合方法——基于图像-文本不一致性的两轮多模态融合方法来检测假新闻。首先，分别通过BERT和VGG预训练模型获得文本模态和图像模态的向量表示。然后通过不一致性测量方法计算检测任务的图像模态权重，并进行第一次图像-文本融合以获得融合特征。这些特征不直接输入到分类器中，而是与文本模态的主要特征再次融合，得到最终的特征表示，最后使用分类器进行分类和检测。与其他方法相比，我们的方法有两个明显的优点:(1)在初始融合之前，通过不一致权值对信息进行过滤，从而控制了不真实图像对内容的误导;(2)通过二次融合机制，加强文本模态特征的主导地位，同时兼顾图像模态信息，达到更好的检测性能</p>
<p>在今后的研究中，可以在以下几个方面开展进一步的工作。首先，设计基于视觉语言预训练语言模型的图像文本表示和细粒度一致性检测方案，其次，在标签表示、实体识别和事件识别等辅助方法的基础上，增强基于文本特征和不一致性的多模态融合学习能力。第三，考虑不同粒度的语义不一致度量方法。通过使用上述方法，可以更好地整合图像和文本内容，获得更好的融合特征，实现对假新闻的高效准确检测。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://sandra-feng.github.io">Sandra_feng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://sandra-feng.github.io/TRIMOON%E5%9F%BA%E4%BA%8E%E4%B8%A4%E8%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C.html">https://sandra-feng.github.io/TRIMOON%E5%9F%BA%E4%BA%8E%E4%B8%A4%E8%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://sandra-feng.github.io" target="_blank">Sandra_feng personal blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/">学习记录</a></div><div class="post_share"><div class="social-share" data-image="https://picdm.sunbangyan.cn/2023/08/31/fjavr4.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/ShareJS/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/ShareJS/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%E5%AE%89%E8%A3%85pytorch%E7%8E%AF%E5%A2%83-GPU%E7%89%88%E6%9C%AC.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fjawga.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">安装pytorch环境(GPU版本)</div></div></a></div><div class="next-post pull-right"><a href="/%E5%A4%9A%E6%A8%A1%E6%80%81%E7%9B%B8%E5%85%B3%E7%BB%BC%E8%BF%B0.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fmo5nx.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">多模态相关综述</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/Bert%E5%BE%AE%E8%B0%83%E5%8F%8ABERT%E5%8F%98%E4%BD%93.html" title="Bert微调及BERT变体"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdm.sunbangyan.cn/2023/08/31/fjavr4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-01</div><div class="title">Bert微调及BERT变体</div></div></a></div><div><a href="/HAN-Hierarchy-Attention-Network-%E6%A8%A1%E5%9E%8B.html" title="HAN(Hierarchy Attention Network)模型及实现"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdm.sunbangyan.cn/2023/08/31/fjaqfl.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-23</div><div class="title">HAN(Hierarchy Attention Network)模型及实现</div></div></a></div><div><a href="/Revisiting-Transformer-based-Models-for-Long-Document-Classification%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB.html" title="Transformer-based Models for Long Document Classification论文阅读"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdl.sunbangyan.cn/2023/08/31/fmo2dy.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-28</div><div class="title">Transformer-based Models for Long Document Classification论文阅读</div></div></a></div><div><a href="/bert%E5%90%84%E5%B1%82%E8%BE%93%E5%87%BA.html" title="bert各层输出"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fijsmq.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-30</div><div class="title">bert各层输出</div></div></a></div><div><a href="/%E5%85%B7%E6%9C%89%E8%87%AA%E9%80%82%E5%BA%94%E5%BE%AE%E8%B0%83%E7%AD%96%E7%95%A5%E7%9A%84%E5%88%86%E5%B1%82BERT%EF%BC%8C%E7%94%A8%E4%BA%8E%E6%96%87%E6%A1%A3%E5%88%86%E7%B1%BB.html" title="具有自适应微调策略的分层BERT，用于文档分类"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fijsmq.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-29</div><div class="title">具有自适应微调策略的分层BERT，用于文档分类</div></div></a></div><div><a href="/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" title="多模态大模型"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fmo90y.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-12</div><div class="title">多模态大模型</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s3.bmp.ovh/imgs/2023/07/22/d87b3c27f25f5e68.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Sandra_feng</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">29</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Sandra-feng"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这是个静态网站演示</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#TRIMOON-%E5%9F%BA%E4%BA%8E%E4%B8%A4%E8%BD%AE%E4%B8%8D%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C"><span class="toc-number">1.</span> <span class="toc-text">TRIMOON:基于两轮不一致性的假新闻检测多模态融合网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.1.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">方法</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/hello-world.html" title="Hello World"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdl.sunbangyan.cn/2023/08/31/fijnc2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/hello-world.html" title="Hello World">Hello World</a><time datetime="2024-01-18T12:01:14.142Z" title="发表于 2024-01-18 20:01:14">2024-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90.html" title="科研工具"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picdm.sunbangyan.cn/2023/08/31/fjavr4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="科研工具"/></a><div class="content"><a class="title" href="/%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90.html" title="科研工具">科研工具</a><time datetime="2024-01-18T06:04:21.000Z" title="发表于 2024-01-18 14:04:21">2024-01-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" title="多模态大模型"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fmo90y.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多模态大模型"/></a><div class="content"><a class="title" href="/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B.html" title="多模态大模型">多模态大模型</a><time datetime="2023-11-12T06:04:21.000Z" title="发表于 2023-11-12 14:04:21">2023-11-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/bert%E5%90%84%E5%B1%82%E8%BE%93%E5%87%BA.html" title="bert各层输出"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picst.sunbangyan.cn/2023/08/31/fijsmq.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="bert各层输出"/></a><div class="content"><a class="title" href="/bert%E5%90%84%E5%B1%82%E8%BE%93%E5%87%BA.html" title="bert各层输出">bert各层输出</a><time datetime="2023-10-30T06:04:21.000Z" title="发表于 2023-10-30 14:04:21">2023-10-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E5%AE%89%E8%A3%85CLIP.html" title="安装CLIP库及数据集下载网站"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picss.sunbangyan.cn/2023/08/31/fjazzb.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="安装CLIP库及数据集下载网站"/></a><div class="content"><a class="title" href="/%E5%AE%89%E8%A3%85CLIP.html" title="安装CLIP库及数据集下载网站">安装CLIP库及数据集下载网站</a><time datetime="2023-10-30T06:04:21.000Z" title="发表于 2023-10-30 14:04:21">2023-10-30</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Sandra_feng</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>